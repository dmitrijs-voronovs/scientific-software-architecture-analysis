id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/20:1379,deployability,build,build,1379,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1402,deployability,fail,failed,1402,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1461,deployability,FAIL,FAILED,1461,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1469,deployability,Build,Build,1469,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1564,deployability,build,build,1564,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:982,energy efficiency,Current,Current,982,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1144,energy efficiency,load,load,1144,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1394,energy efficiency,Load,Loading,1394,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1518,energy efficiency,load,loaded,1518,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1509,modifiability,pac,packages,1509,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1021,performance,ERROR,ERROR,1021,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1144,performance,load,load,1144,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1308,performance,ERROR,ERROR,1308,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1394,performance,Load,Loading,1394,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1435,performance,time,time,1435,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1518,performance,load,loaded,1518,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1538,performance,ERROR,ERROR,1538,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:12,reliability,doe,does,12,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1371,reliability,fail,failed,1371,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1402,reliability,fail,failed,1402,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1461,reliability,FAIL,FAILED,1461,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:151,safety,test,test,151,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:881,safety,test,test,881,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1021,safety,ERROR,ERROR,1021,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1308,safety,ERROR,ERROR,1308,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1349,safety,test,testing,1349,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1483,safety,compl,complete,1483,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1538,safety,ERROR,ERROR,1538,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1585,safety,test,tests,1585,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1483,security,compl,complete,1483,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:151,testability,test,test,151,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:881,testability,test,test,881,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1349,testability,test,testing,1349,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1585,testability,test,tests,1585,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1021,usability,ERROR,ERROR,1021,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1308,usability,ERROR,ERROR,1308,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/20:1538,usability,ERROR,ERROR,1538,"deepvariant does not build from source; I am following the instructions under:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-build-test.md. 1. start GCE image : Ubuntu 16.04 with 100GB. git clone https://github.com/google/deepvariant. cd deepvariant. ./build-prereq.sh. ./build_and_test.sh. ```. ... ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/usr/bin/python. ++ PYTHON_BIN_PATH=/usr/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ DV_COPT_FLAGS='--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3'. ++ export DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. ++ DV_TENSORFLOW_GIT_SHA=ab0fcaceda001825654424bf18e8a8e0f8d39df2. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (17:54:59) INFO: Current date is 2017-12-22. (17:55:18) ERROR: /home/<mypath>/0fcc5a420905d68918d80793ee59fab4/external/com_goo. glesource_code_re2/BUILD:96:1: First argument of 'load' must be a label and start. with either '//', ':', or '@'. Us. e --incompatible_load_argument_is_label=false to temporarily disable this check. ... (17:55:26) ERROR: Analysis of target '//deepvariant/testing:gunit_extras' failed; build aborted: Loading failed. (17:55:26) INFO: Elapsed time: 27.289s. (17:55:26) FAILED: Build did NOT complete successfully (50 packages loaded). (17:55:26) ERROR: Couldn't start the build. Unable to run tests. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/20
https://github.com/google/deepvariant/issues/21:3488,availability,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2199,deployability,modul,module,2199,"1448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3341,deployability,api,apic,3341,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3488,deployability,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3869,deployability,pipelin,pipeline,3869,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:833,energy efficiency,CPU,CPU,833,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:903,energy efficiency,CPU,CPU,903,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1483,energy efficiency,core,core,1483,"y debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Ta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2100,energy efficiency,core,core,2100,"l/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2165,energy efficiency,load,loading,2165,"-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3213,energy efficiency,CPU,CPU,3213,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3289,energy efficiency,cpu,cpuinfo,3289,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3488,energy efficiency,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3785,energy efficiency,CPU,CPU,3785,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3341,integrability,api,apic,3341,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3869,integrability,pipelin,pipeline,3869,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:0,interoperability,Share,Shared,0,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:279,interoperability,format,formatted,279,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:572,interoperability,share,shared,572,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3341,interoperability,api,apic,3341,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2199,modifiability,modul,module,2199,"1448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:833,performance,CPU,CPU,833,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:903,performance,CPU,CPU,903,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2165,performance,load,loading,2165,"-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3213,performance,CPU,CPU,3213,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3289,performance,cpu,cpuinfo,3289,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3785,performance,CPU,CPU,3785,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3415,reliability,rdt,rdtscp,3415,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3488,reliability,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1121,safety,input,input,1121," [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. Af",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1181,safety,input,input,1181,"ob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1402,safety,input,input,1402,"dy.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1573,safety,input,input,1573,"ed libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../..",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1738,safety,input,input,1738,"binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007fff",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1798,safety,input,input,1798,"ght have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2019,safety,input,input,2019,"TH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2199,safety,modul,module,2199,"1448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3488,safety,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2391,security,sign,signal,2391,"e-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3488,testability,monitor,monitor,3488,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:54,usability,support,support,54,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:73,usability,user,users,73,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:525,usability,help,help,525,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:771,usability,support,support,771,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:810,usability,support,support,810,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:892,usability,minim,minimum,892,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:954,usability,user,users,954,"Shared library from the Exome Case Study requires AVX support -- not all users might have this; Hi,. I was going through the [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/pau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1121,usability,input,input,1121," [Exome Case Study](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. Af",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1181,usability,input,input,1181,"ob/r0.4/docs/deepvariant-exome-case-study.md), and noticed that I was not getting any TFRecord formatted files from the [`Run make_examples`](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1402,usability,input,input,1402,"dy.md#run-make_examples) step. I then proceeded to dig deeper, and I'm listing my debugging steps here in case it might help others. The gist of it is that the common shared libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1573,usability,input,input,1573,"ed libraries that are part of the zip files (from the [Google Storage location](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-exome-case-study.md#binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../..",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1738,usability,input,input,1738,"binaries)) are built with AVX-support, which not everyone might have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007fff",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:1798,usability,input,input,1798,"ght have support for with their CPU. It would be great if they were compiled with the bare-minimum of CPU qualities, to guarantee they will work on most users' machines. In any case, below is my analysis:. ```. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:2019,usability,input,input,2019,"TH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. $ mkdir make-examples && cd make-examples. $ cd unzip ~/exome-case-study/input/bin/make_examples.zip. $ cd runfiles/genomics. $. $ PYTHONPATH=. /usr/bin/python deepvariant/make_examples.py --mode calling --ref /home/paul/exome-case-study/input/data/hs37d5.fa.gz --reads /home/paul/exome-case-study/input/data/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3572,usability,confirm,confirmed,3572,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3611,usability,support,support,3611,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3700,usability,user,users,3700,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3709,usability,learn,learn,3709,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3774,usability,minim,minimum,3774,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/21:3844,usability,user,users,3844,".markDup.bam --examples /home/paul/exome-case-study/output/HG002.examples.tfrecord@1.gz --regions /home/paul/exome-case-study/input/data/refseq.coding_exons.b37.extended50.bed --task 0. Illegal instruction (core dumped). $. ```. After digging a bit deeper, I noticed that loading the `pileup_image_native` module was causing this issue. I was curious and looked at the assembly instructions:. ```. $ gdb -ex r --args python -c ""from deepvariant.python import pileup_image_native"". Program received signal SIGILL, Illegal instruction. 0x00007ffff5d308b4 in google::protobuf::DescriptorPool::Tables::Tables() (). from /home/paul/make-examples/runfiles/genomics/deepvariant/python/../../_solib_k8/libexternal_Sprotobuf_Uarchive_Slibprotobuf.so. (gdb) disassemble $pc,$pc+32. Dump of assembler code from 0x7ffff5d308b4 to 0x7ffff5d308d4:. => 0x00007ffff5d308b4 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+676>: vpxor %xmm0,%xmm0,%xmm0. 0x00007ffff5d308b8 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+680>: lea 0x1b0(%rbx),%rax. 0x00007ffff5d308bf <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+687>: movl $0x0,0x1b0(%rbx). 0x00007ffff5d308c9 <_ZN6google8protobuf14DescriptorPool6TablesC2Ev+697>: movq $0x0,0x1b8(%rbx). End of assembler dump. (gdb). ```. I noticed the `vpxor` instruction, which made me wonder if my CPU is enabled for AVX, so I proceeded as follows:. ```. $ grep flags /proc/cpuinfo. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc pni pclmulqdq monitor ssse3 cx16 sse4_1 sse4_2 x2apic popcnt aes hypervisor lahf_lm. $. ```. This confirmed for me that I don't have AVX support. So it would be great for the examples that will drive usage and be used by many users to learn from, if the provided libraries are compiled with the bare-minimum of CPU qualities. I think it'll make it a bit easier for many users to adopt this nice pipeline. Thanks,. Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/21
https://github.com/google/deepvariant/issues/22:7,availability,error,error,7,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:66,availability,error,error,66,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:166,deployability,version,version,166,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:166,integrability,version,version,166,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:166,modifiability,version,version,166,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:7,performance,error,error,7,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:66,performance,error,error,66,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:7,safety,error,error,7,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:66,safety,error,error,66,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:7,usability,error,error,7,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/22:66,usability,error,error,66,"import error for GLIBCXX_3.4.21; When I run make-example.zip, the error shows up... Please fix it for me ;- ). ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /tmp/Bazel.runfiles_YSzuwd/runfiles/protobuf_archive/python/google/protob. uf/pyext/_message.so)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/22
https://github.com/google/deepvariant/issues/23:75,energy efficiency,model,model,75,"Question about channels; Hi. I have some ideals about the channels in your model, but i don't know which files to modify, could you give me some advice?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/23
https://github.com/google/deepvariant/issues/23:75,security,model,model,75,"Question about channels; Hi. I have some ideals about the channels in your model, but i don't know which files to modify, could you give me some advice?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/23
https://github.com/google/deepvariant/issues/23:114,security,modif,modify,114,"Question about channels; Hi. I have some ideals about the channels in your model, but i don't know which files to modify, could you give me some advice?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/23
https://github.com/google/deepvariant/issues/24:14,availability,ERROR,ERROR,14,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:166,availability,error,error,166,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:14,performance,ERROR,ERROR,14,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:166,performance,error,error,166,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:14,safety,ERROR,ERROR,14,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:166,safety,error,error,166,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:14,usability,ERROR,ERROR,14,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:49,usability,user,user-images,49,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/24:166,usability,error,error,166,"make_examples ERROR; Hello ！. . ![image](https://user-images.githubusercontent.com/34881972/34375365-21791992-eb21-11e7-913e-5796551352d2.png). The picture shows the error,how can I solve this problem? Thank you !",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/24
https://github.com/google/deepvariant/issues/25:295,availability,error,error,295,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:85,deployability,instal,install,85,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:109,deployability,depend,dependencies,109,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:173,deployability,depend,dependencies,173,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:190,deployability,instal,installed,190,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:748,deployability,modul,module,748,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:798,deployability,modul,module,798,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:109,integrability,depend,dependencies,109,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:173,integrability,depend,dependencies,173,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:109,modifiability,depend,dependencies,109,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:173,modifiability,depend,dependencies,173,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:748,modifiability,modul,module,748,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:798,modifiability,modul,module,798,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:295,performance,error,error,295,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:109,safety,depend,dependencies,109,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:173,safety,depend,dependencies,173,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:295,safety,error,error,295,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:748,safety,modul,module,748,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:798,safety,modul,module,798,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:109,testability,depend,dependencies,109,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:173,testability,depend,dependencies,173,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:617,testability,Trace,Traceback,617,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/25:295,usability,error,error,295,"Unable to run make_examples.zip when using a virtual environment; I would rather not install the DeepVariant dependencies into my global python environment. When the python dependencies are installed into a virtual environment, make_examples.zip cannot find tensorflow. The steps below show the error. Any suggestions? ```. $ mkvirtualenv -p /usr/bin/python2.7 DeepVariant.2.7. (DeepVariant.2.7) $ cd bin; bash run-prereq.sh; cd -. (DeepVariant.2.7) $ python bin/make_examples.zip --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_r1oZvM/runfiles/genomics/deepvariant/make_examples.py"", line 38, in <module>. import tensorflow as tf. ImportError: No module named tensorflow. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/25
https://github.com/google/deepvariant/issues/26:0,usability,Document,Documentation,0,Documentation: Incorrect hyperlinks in deepvariant-docker.md; See this page:. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. Refer to the Setup section. The following links do not function as intended. The #fragments do not exist anymore. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#set_up_a_google_cloud_account. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#request_access_to_our_shared_cloud_storage_bucket. https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#install_the_google_cloud_sdk,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/26
https://github.com/google/deepvariant/issues/27:275,availability,error,error,275,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:11,deployability,fail,failed,11,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:27,deployability,fail,failed,27,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:281,deployability,log,logs,281,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:495,deployability,LOG,LOG,495,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:639,deployability,log,log,639,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:834,deployability,manag,managecases,834,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:667,energy efficiency,Cloud,Cloud,667,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:834,energy efficiency,manag,managecases,834,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:275,performance,error,error,275,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:11,reliability,fail,failed,11,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:27,reliability,fail,failed,27,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:275,safety,error,error,275,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:281,safety,log,logs,281,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:344,safety,test,test-shan,344,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:435,safety,test,test-shan,435,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:495,safety,LOG,LOG,495,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:540,safety,test,test-shan,540,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:639,safety,log,log,639,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:834,safety,manag,managecases,834,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:205,security,auth,authentification,205,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:281,security,log,logs,281,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:495,security,LOG,LOG,495,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:639,security,log,log,639,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:281,testability,log,logs,281,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:344,testability,test,test-shan,344,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:435,testability,test,test-shan,435,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:495,testability,LOG,LOG,495,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:540,testability,test,test-shan,540,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:639,testability,log,log,639,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:19,usability,command,command,19,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:275,usability,error,error,275,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:673,usability,support,support,673,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:820,usability,support,supportcenter,820,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/27:921,usability,help,help,921,"Docker run failed: command failed: /tmp/ggp-494856422: line 16: type: gsutil: not found\ndebconf; Dear All,. I am trying to run gcloud alpha genomics but have recurrently encountered the same issues about authentification and docker run. . The bash file for Deep Variant and error logs are below:. BASH file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepVariant.sh](url). YAML file [https://storage.googleapis.com/wgs-test-shan/test_samples/deepvariant_wes_pipeline.yaml](url). LOG file [https://storage.googleapis.com/wgs-test-shan/test_samples/runner_logs/ENjW7s2JLBjf3aql19nvyv8BIKeM6-b_FyoPcHJvZHVjdGlvblF1ZXVl-stderr.log](url). I have contacted Cloud support center and obtained suggestions as below. However this did not mend the problem. What is your suggestion? . [https://enterprise.google.com/supportcenter/managecases#Case/001f200001TaEgT/U-14552728. ](url). Thank you. I will appreciate your help. Best,. Shan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/27
https://github.com/google/deepvariant/issues/28:0,availability,error,error,0,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:128,availability,error,errors,128,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:724,availability,servic,service,724,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:101,deployability,contain,container,101,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:186,deployability,fail,fails,186,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:218,deployability,stack,stack,218,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:585,deployability,Log,Logging,585,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:724,deployability,servic,service,724,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1026,deployability,modul,module,1026,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:724,integrability,servic,service,724,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:843,integrability,pub,public,843,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1112,interoperability,platform,platform,1112,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1708,interoperability,format,format,1708,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:724,modifiability,servic,service,724,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1026,modifiability,modul,module,1026,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1085,modifiability,pac,packages,1085,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:0,performance,error,error,0,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:128,performance,error,errors,128,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:683,performance,Time,Timeout,683,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:186,reliability,fail,fails,186,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:0,safety,error,error,0,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:128,safety,error,errors,128,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:585,safety,Log,Logging,585,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:683,safety,Timeout,Timeout,683,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:1026,safety,modul,module,1026,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:585,security,Log,Logging,585,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:869,security,access,accessible,869,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:224,testability,trace,trace,224,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:585,testability,Log,Logging,585,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:893,testability,Trace,Traceback,893,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:0,usability,error,error,0,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/28:128,usability,error,errors,128,"error in make_examples extract_sample_name_from_reads; Running make_examples locally from the Docker container. It runs without errors on the NA12878_S1.chr20.10_10p1mb.bam dataset, but fails with my BAM file. See the stack trace below. My BAM file is too large to attach here. What do you recommend? Also what are the allowed values for --logging_level? Please advise. ```. # ./opt/deepvariant/bin/make_examples --logging_level DEBUG --mode calling --ref /dv2/reference/CFSAN000189.fasta --reads /dv2/samples/CFSAN000211/reads.sorted.bam --examples output.examples.tfrecord. WARNING: Logging before flag parsing goes to stderr. I1228 21:10:23.407845 140668049200896 client.py:1004] Timeout attempting to reach GCE metadata service. W1228 21:10:23.408325 140668049200896 htslib_gcp_oauth.py:88] GCP credentials not found; only local files and public gs:// URIs will be accessible from htslib. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 969, in main. options = default_options(add_flags=True, flags=FLAGS). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 207, in default_options. sample_name = extract_sample_name_from_reads(flags.reads). File ""/tmp/Bazel.runfiles_9tjOWl/runfiles/genomics/deepvariant/make_examples.py"", line 406, in extract_sample_name_from_reads. raise ValueError('Expected a single sample, found {}'.format(samples)). ValueError: Expected a single sample, found set([]). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/28
https://github.com/google/deepvariant/issues/29:477,deployability,build,build,477,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:574,deployability,build,build,574,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:830,deployability,patch,patch,830,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:854,deployability,build,build,854,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:972,deployability,build,build,972,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1212,deployability,build,building,1212,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1324,deployability,build,build,1324,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1363,deployability,build,build,1363,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1415,deployability,depend,dependency,1415,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1448,deployability,build,build,1448,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1560,deployability,instal,install,1560,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1586,deployability,build,build,1586,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:346,energy efficiency,Current,Currently,346,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:820,energy efficiency,current,currently,820,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:996,energy efficiency,current,currently,996,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1415,integrability,depend,dependency,1415,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:618,interoperability,compatib,compatibility,618,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1256,interoperability,compatib,compatible,1256,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:51,modifiability,pac,packages,51,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:119,modifiability,pac,package,119,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:268,modifiability,portab,portable,268,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:330,modifiability,portab,portability,330,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1415,modifiability,depend,dependency,1415,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1597,modifiability,portab,portable,1597,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:830,safety,patch,patch,830,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1415,safety,depend,dependency,1415,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:660,security,hardcod,hardcodes,660,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:830,security,patch,patch,830,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1415,testability,depend,dependency,1415,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:89,usability,help,help,89,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:230,usability,help,help,230,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:314,usability,help,helpfulness,314,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:562,usability,support,support,562,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/29:1706,usability,help,help,1706,"Improving pre-built DeepVariant binaries for conda packages; Hi all;. Thanks for all the help getting an initial conda package in place for DeepVariant (#9) through bioconda. I wanted to follow up with some suggestions that would help make the pre-built binaries more portable as part of this process, in order of helpfulness for portability:. - Currently the binaries need a recent kernel with GLIBC > 2.23 due to pre-built htslib and other libraries. Would it be possible to build the DeepVariant libraries on an older machine to allow a wider range of system support? We build on CentOS 6 in conda to provide wider compatibility. - main.py in the zip files hardcodes python to use `/usr/bin/python`. Would it be possible to generalize this by using the python that the zip file gets called with (`sys.executable`)? I currently patch this in the conda build: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/recipes/deepvariant/build.sh#L22. - This is currently built against numpy 1.13 and ideally we'd want to sync with CONDA_NPY (1.12: https://github.com/bioconda/bioconda-recipes/blob/0a2d467d63d011015efeef4b644e985297b6b271/scripts/env_matrix.yml#L9). I believe building against 1.12 would make it forward compatible. An alternative to points 1 and 3 is making it easier to build DeepVariant as part of the conda build process. The major blocker here is the `clif` dependency which is difficult to build and the pre-built binaries require unpacking into `/usr`. If we could make this relocatable and easier to install globally we could build with portable binaries and adjustable numpy as part of the bioconda preparation process. Thanks again for all the help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/29
https://github.com/google/deepvariant/issues/30:118,availability,error,error,118,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:164,availability,Error,Error,164,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:407,availability,Operat,Operation,407,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:709,availability,down,download,709,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:23,deployability,instal,installing,23,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:41,deployability,build,build,41,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:76,deployability,build,build-prereq,76,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:144,deployability,instal,install,144,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:184,deployability,Instal,Installing,184,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:671,deployability,instal,installing,671,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:867,deployability,instal,install,867,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1040,deployability,instal,installed,1040,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1062,deployability,build,build-prereq,1062,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1134,deployability,instal,installed,1134,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1196,deployability,version,version,1196,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1431,deployability,version,version,1431,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1440,deployability,Instal,Installed,1440,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:202,energy efficiency,Cloud,Cloud,202,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:217,energy efficiency,optim,optimized,217,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:227,energy efficiency,CPU,CPU-only,227,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:767,energy efficiency,cloud,cloud,767,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:170,integrability,messag,message,170,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:616,integrability,discover,discovered,616,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1196,integrability,version,version,1196,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1431,integrability,version,version,1431,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:170,interoperability,messag,message,170,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:208,interoperability,Platform,Platform,208,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:547,interoperability,platform,platform,547,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:616,interoperability,discover,discovered,616,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:279,modifiability,pac,packages,279,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:812,modifiability,pac,packages,812,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1031,modifiability,pac,packages,1031,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1117,modifiability,pac,packages,1117,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1196,modifiability,version,version,1196,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:1431,modifiability,version,version,1431,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:118,performance,error,error,118,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:164,performance,Error,Error,164,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:217,performance,optimiz,optimized,217,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:227,performance,CPU,CPU-only,227,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:118,safety,error,error,118,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:164,safety,Error,Error,164,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:417,safety,compl,completed,417,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:417,security,compl,completed,417,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:118,usability,error,error,118,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:164,usability,Error,Error,164,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:523,usability,support,supported,523,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/30:616,usability,discov,discovered,616,"Tensorflow .whl is not installing during build; ### Issue. When running the build-prereq shell script, I'm getting an error when the Tensorflow install begins. ### Error message. ```. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. Copying gs://deepvariant/packages/tensorflow/tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl... - [1 files][ 41.1 MiB/ 41.1 MiB] 1.0 MiB/s . Operation completed over 1 objects/41.1 MiB. . tensorflow-1.4.1.deepvariant_gcp-cp27-none-linux_x86_64.whl is not a supported wheel on this platform. ```. ### Debugging efforts. After browsing around a bit, I discovered that this issue was solved for some through installing the .whl separately. So, I download the whl from the [GCloud bucket](https://console.cloud.google.com/storage/browser/deepvariant/packages/tensorflow/) and executed `sudo python2.7 pip install <name of .whl file>` through the terminal. It ran, just to tell me “.dist-info directory not found”. I think this might be due to some inconsistency in the packages installed through the build-prereq.sh script, because I can see that all the packages that it installed (e.g. numpy) are for Python 3.5, but the Tensorflow version it's trying to get is for cp27 (Python 2.7). Not sure about where to go from here, would love some assistance :). ### System details. OS: Ubuntu 16.04 LTS. Python interpreters: Default with Ubuntu (2.7 and 3.5.2). Deep Variant version: Installed it today from the main repo, so probably r0.4.1. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/30
https://github.com/google/deepvariant/issues/31:207,availability,error,error,207,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:242,availability,error,error,242,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:430,availability,ERROR,ERROR,430,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:592,availability,error,error,592,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3045,availability,error,error,3045,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:8,deployability,build,build,8,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:66,deployability,build,build,66,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:109,deployability,fail,failed,109,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:403,deployability,stack,stack,403,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:480,deployability,BUILD,BUILD,480,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:563,deployability,fail,failed,563,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:584,deployability,fail,failed,584,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3111,deployability,modul,module,3111,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3199,deployability,modul,module,3199,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:170,energy efficiency,core,core,170,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:468,energy efficiency,core,core,468,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:532,energy efficiency,core,core,532,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:1304,energy efficiency,core,core,1304,ome investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-ou,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:1352,energy efficiency,core,core,1352,tible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_pyth,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:1430,energy efficiency,core,core,1430,ROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:1478,energy efficiency,core,core,1478,BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:2674,energy efficiency,core,core,2674,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:2741,energy efficiency,core,core,2741,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:2789,energy efficiency,core,core,2789,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:2859,energy efficiency,core,core,2859,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3009,energy efficiency,core,core,3009,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3148,energy efficiency,core,core,3148,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3222,energy efficiency,core,core,3222,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:347,interoperability,incompatib,incompatible,347,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:851,modifiability,pac,packages,851,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:1000,modifiability,paramet,parameter,1000,"it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3111,modifiability,modul,module,3111,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3199,modifiability,modul,module,3199,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:207,performance,error,error,207,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:242,performance,error,error,242,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:430,performance,ERROR,ERROR,430,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:592,performance,error,error,592,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:626,performance,cach,cache,626,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3045,performance,error,error,3045,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3273,performance,time,time,3273,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:0,reliability,Doe,Does,0,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:109,reliability,fail,failed,109,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:563,reliability,fail,failed,563,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:584,reliability,fail,failed,584,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:207,safety,error,error,207,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:242,safety,error,error,242,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:430,safety,ERROR,ERROR,430,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:592,safety,error,error,592,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3045,safety,error,error,3045,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3111,safety,modul,module,3111,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3199,safety,modul,module,3199,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:207,usability,error,error,207,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:242,usability,error,error,242,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:430,usability,ERROR,ERROR,430,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:592,usability,error,error,592,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:608,usability,command,command,608,"Does it build with Python3?; On Ubuntu 16.04 LTS, when I tried to build it from source with Python 3.6.2, it failed to compile `bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc`, and the error was `hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope`. After some investigations and it seems to be an incompatible issue with Python 3. . The relatively full stack is here:. (14:05:26) ERROR: xx/git/deepvariant/deepvariant/core/python/BUILD:174:1: C++ compilation of rule '//deepvariant/core/python:hts_verbose_cclib' failed (Exit 1): gcc failed: error executing command . (cd xx/.cache/bazel/xx/7e4d04a878642732d9b8bb40a634229e/execroot/genomics && \. exec env - \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=xx/anaconda/envs/Python36/bin/python \. PYTHON_LIB_PATH=xx/anaconda/envs/Python36/lib/python3.6/site-packages \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -Wno-maybe-uninitialized -Wno-unused-function -msse4.1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:2221,usability,tool,tools,2221,".1 -msse4.2 -mavx -O3 '-std=c++0x' -MD -MF bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/31:3045,usability,error,error,3045,"/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.d '-frandom-seed=bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o' -iquote . -iquote bazel-out/k8-py3-opt/genfiles -iquote external/htslib -iquote bazel-out/k8-py3-opt/genfiles/external/htslib -iquote external/bazel_tools -iquote bazel-out/k8-py3-opt/genfiles/external/bazel_tools -iquote external/clif -iquote bazel-out/k8-py3-opt/genfiles/external/clif -iquote external/local_config_python -iquote bazel-out/k8-py3-opt/genfiles/external/local_config_python -iquote external/protobuf_archive -iquote bazel-out/k8-py3-opt/genfiles/external/protobuf_archive -isystem external/htslib/htslib/htslib_1_6 -isystem bazel-out/k8-py3-opt/genfiles/external/htslib/htslib/htslib_1_6 -isystem external/htslib -isystem bazel-out/k8-py3-opt/genfiles/external/htslib -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/local_config_python/python_include -isystem bazel-out/k8-py3-opt/genfiles/external/local_config_python/python_include -isystem external/protobuf_archive/src -isystem bazel-out/k8-py3-opt/genfiles/external/protobuf_archive/src '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc -o bazel-out/k8-py3-opt/bin/deepvariant/core/python/_objs/hts_verbose_cclib/deepvariant/core/python/hts_verbose.o). bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc: In function 'PyObject* deepvariant_core_python_hts__verbose_clifwrap::Init()':. bazel-out/k8-py3-opt/genfiles/deepvariant/core/python/hts_verbose.cc:134:143: error: 'Py_InitModule3' was not declared in this scope. PyObject* module = Py_InitModule3(""deepvariant.core.python.hts_verbose"", Methods, ""CLIF-generated module for deepvariant/core/hts_verbose.h"");. ^. (14:05:26) INFO: Elapsed time: 4.048s, Critical Path: 1.26s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/31
https://github.com/google/deepvariant/issues/32:0,deployability,Build,Building,0,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:21,deployability,fail,failed,21,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:129,deployability,fail,failed,129,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:196,energy efficiency,core,core,196,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:348,energy efficiency,core,core,348,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:376,interoperability,standard,standard,376,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:21,reliability,fail,failed,21,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:129,reliability,fail,failed,129,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:28,safety,test,tests,28,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:140,safety,test,tests,140,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:28,testability,test,tests,28,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/32:140,testability,test,tests,140,"Building from source failed tests that import `random`; On Ubuntu 16.04 TLS, I built it with Python 2.7 and tensorflow 1.4.1. It failed all tests that import random (e.g. `deepvariant/deepvariant/core/cloud_utils_test.py`). It turned out that in `random.py`, it imports `math`, and it mistakingly imports the `math.py` in `/deepvariant/deepvariant/core/`, instead of from the standard library. Is there a fix?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/32
https://github.com/google/deepvariant/issues/33:125,deployability,configurat,configuration,125,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:84,energy efficiency,cloud,cloud,84,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:115,energy efficiency,optim,optimized,115,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:149,energy efficiency,cloud,cloud,149,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:125,integrability,configur,configuration,125,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:125,modifiability,configur,configuration,125,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:115,performance,optimiz,optimized,115,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/issues/33:125,security,configur,configuration,125,"Running DeepVariant for several alignment files; I am running DeepVariant on google cloud following the wiki (Cost-optimized configuration): https://cloud.google.com/genomics/deepvariant, and it works for one of our sample. . Now I have several bam files for several samples. I can run them one by one. But I wonder is there some options to set a list of bam files? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/33
https://github.com/google/deepvariant/pull/34:19,deployability,build,build-prereq,19,"fixed minor bug in build-prereq.sh; Changed undeclared $bazel_version variable to declared $bazel_ver variable. After implementing this fix, I was able to build all prerequisite packages.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/34
https://github.com/google/deepvariant/pull/34:155,deployability,build,build,155,"fixed minor bug in build-prereq.sh; Changed undeclared $bazel_version variable to declared $bazel_ver variable. After implementing this fix, I was able to build all prerequisite packages.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/34
https://github.com/google/deepvariant/pull/34:70,modifiability,variab,variable,70,"fixed minor bug in build-prereq.sh; Changed undeclared $bazel_version variable to declared $bazel_ver variable. After implementing this fix, I was able to build all prerequisite packages.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/34
https://github.com/google/deepvariant/pull/34:102,modifiability,variab,variable,102,"fixed minor bug in build-prereq.sh; Changed undeclared $bazel_version variable to declared $bazel_ver variable. After implementing this fix, I was able to build all prerequisite packages.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/34
https://github.com/google/deepvariant/pull/34:178,modifiability,pac,packages,178,"fixed minor bug in build-prereq.sh; Changed undeclared $bazel_version variable to declared $bazel_ver variable. After implementing this fix, I was able to build all prerequisite packages.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/34
https://github.com/google/deepvariant/issues/35:0,usability,Document,Documentation,0,"Documentation: BAM file requirements / recommendations; I may have missed it, but I could not find documentation describing recommended bam file processing prior to running DeepVariant. In particular:. 1. Should the bam file be sorted? 2. Should duplicate reads be marked? 3. Is local realignment around indels recommended?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/35
https://github.com/google/deepvariant/issues/35:99,usability,document,documentation,99,"Documentation: BAM file requirements / recommendations; I may have missed it, but I could not find documentation describing recommended bam file processing prior to running DeepVariant. In particular:. 1. Should the bam file be sorted? 2. Should duplicate reads be marked? 3. Is local realignment around indels recommended?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/35
https://github.com/google/deepvariant/issues/36:273,deployability,observ,observed,273,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:111,energy efficiency,current,current,111,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:747,energy efficiency,core,core,747,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:1116,modifiability,evolv,evolving,1116,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:587,performance,time,times,587,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:1012,reliability,doe,does,1012,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:1069,reliability,Doe,Does,1069,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:273,testability,observ,observed,273,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/36:1098,testability,understand,understanding,1098,"Why the software history was not kept?; Hi there,. I'm a researcher studying software evolution. As part of my current research, I'm studying the implications of open-sourcing a proprietary software, for instance, if the project succeed in attracting newcomers. However, I observed that some projects, like deepvariant, deleted the software history during the transition to open-source. https://github.com/google/deepvariant/commit/8b84eabcc3c7b1adff3dfa6951963527eb673c29. Knowing that software history is indispensable for developers (e.g., developers need to refer to history several times a day), I would like to ask deepvariant developers the following four brief questions:. 1. Why did you decide to not keep the software history? 2. Do the core developers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 3. Do the newcomers faced any kind of problems, when trying to refer to the old history? If so, how did they solve these problems? 4. How does the lack of history impacted on software evolution? Does it placed any burden in understanding and evolving the software? Thanks in advance for your collaboration,. Gustavo Pinto, PhD. http://www.gustavopinto.org",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/36
https://github.com/google/deepvariant/issues/38:20,reliability,Doe,Does,20,CRAM file support?; Does the deepvariant software also read cram files?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/38
https://github.com/google/deepvariant/issues/38:10,usability,support,support,10,CRAM file support?; Does the deepvariant software also read cram files?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/38
https://github.com/google/deepvariant/issues/39:430,availability,error,error,430,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:497,availability,down,downstream,497,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:590,availability,error,error,590,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:14,deployability,fail,fails,14,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:50,deployability,contain,container,50,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:284,deployability,contain,container,284,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:657,deployability,fail,fail,657,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:430,performance,error,error,430,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:590,performance,error,error,590,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:14,reliability,fail,fails,14,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:376,reliability,doe,does,376,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:411,reliability,doe,does,411,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:441,reliability,doe,does,441,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:657,reliability,fail,fail,657,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:315,safety,compl,complaints,315,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:430,safety,error,error,430,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:475,safety,input,input,475,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:590,safety,error,error,590,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:612,safety,input,input,612,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:315,security,compl,complaints,315,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:239,usability,indicat,indicated,239,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:430,usability,error,error,430,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:475,usability,input,input,475,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:508,usability,tool,tools,508,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:590,usability,error,error,590,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:612,usability,input,input,612,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/39:688,usability,help,help,688,"make_examples fails to process data within docker container; I've setup deepvariant via `gsutil` as described under https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-docker.md. When running the first step `make_examples` as indicated in the reference within the docker container, it runs without any complaints, and terminates after around a second. However it does not create an output file nor does it output any error, nor does it care if I provide invalid input file names. The downstream tools `call_variants` and `postprocess_variants` behave similar, they run without error, but accept any input arguments (including invalid ones) and fail to create any output. Any help would be appreciated.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/39
https://github.com/google/deepvariant/issues/40:0,modifiability,paramet,parameters,0,parameters for low-coverage WGS?; What are the recommended parameters for low-coverage WGS? E.g. 2.5x-5x coverage of the human genome.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/40
https://github.com/google/deepvariant/issues/40:59,modifiability,paramet,parameters,59,parameters for low-coverage WGS?; What are the recommended parameters for low-coverage WGS? E.g. 2.5x-5x coverage of the human genome.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/40
https://github.com/google/deepvariant/issues/40:19,testability,coverag,coverage,19,parameters for low-coverage WGS?; What are the recommended parameters for low-coverage WGS? E.g. 2.5x-5x coverage of the human genome.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/40
https://github.com/google/deepvariant/issues/40:78,testability,coverag,coverage,78,parameters for low-coverage WGS?; What are the recommended parameters for low-coverage WGS? E.g. 2.5x-5x coverage of the human genome.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/40
https://github.com/google/deepvariant/issues/40:105,testability,coverag,coverage,105,parameters for low-coverage WGS?; What are the recommended parameters for low-coverage WGS? E.g. 2.5x-5x coverage of the human genome.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/40
https://github.com/google/deepvariant/issues/41:46,availability,Down,Download,46,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:168,availability,down,download-binaries-models-and-test-data,168,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:442,availability,error,error,442,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:416,deployability,fail,failed,416,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:811,deployability,modul,module,811,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:956,deployability,modul,module,956,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:65,energy efficiency,model,models,65,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:186,energy efficiency,model,models-and-test-data,186,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:1058,interoperability,share,shared,1058,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:811,modifiability,modul,module,811,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:956,modifiability,modul,module,956,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:442,performance,error,error,442,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:416,reliability,fail,failed,416,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:77,safety,test,test,77,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:197,safety,test,test-data,197,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:407,safety,test,testdata,407,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:442,safety,error,error,442,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:811,safety,modul,module,811,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:956,safety,modul,module,956,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:65,security,model,models,65,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:186,security,model,models-and-test-data,186,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:77,testability,test,test,77,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:197,testability,test,test-data,197,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:407,testability,test,testdata,407,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:455,testability,Trace,Traceback,455,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:234,usability,guid,guide,234,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:442,usability,error,error,442,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/41:507,usability,tool,tools,507,"ImportError: libcrypto.so.1.0.0; The code in [Download binaries, models, and test data](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#download-binaries-models-and-test-data) the of the DV quick start guide ran successfully. However, running [make_examples](https://github.com/google/deepvariant/blob/r0.4/docs/deepvariant-quick-start.md#make_examples) using the quickstart-testdata failed with the following error:. ```. Traceback (most recent call last):. attila-ThinkS:~/tools/deepvariant$ python bin/make_examples.zip \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/make_examples.py"", line 45, in <module>. from deepvariant import variant_caller. File ""/tmp/Bazel.runfiles_pbJgd2/runfiles/genomics/deepvariant/variant_caller.py"", line 50, in <module>. from deepvariant.python import variant_calling. ImportError: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/41
https://github.com/google/deepvariant/issues/42:16,energy efficiency,CPU,CPUs,16,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:138,energy efficiency,CPU,CPU,138,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:142,energy efficiency,core,cores,142,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:345,energy efficiency,CPU,CPUs,345,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:16,performance,CPU,CPUs,16,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:138,performance,CPU,CPU,138,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:208,performance,time,time,208,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:345,performance,CPU,CPUs,345,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:179,safety,test,test,179,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/42:179,testability,test,test,179,Limit number of CPUs used by DeepVariant; I am using DeepVariant on a local machine with docker. When I start DeepVariant it uses all the CPU cores of my machine. Since I want to test DeepVariant without any time limitations and use the machine for other tasks I am curious whether it is possible to limit the number of threads or the number of CPUs used by DeepVariant.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/42
https://github.com/google/deepvariant/issues/43:45,availability,error,errors,45,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:292,availability,ERROR,ERROR,292,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:597,availability,ERROR,ERROR,597,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:794,availability,ERROR,ERROR,794,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:992,availability,ERROR,ERROR,992,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1190,availability,ERROR,ERROR,1190,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1388,availability,ERROR,ERROR,1388,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1586,availability,ERROR,ERROR,1586,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1784,availability,ERROR,ERROR,1784,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:18,deployability,fail,fails,18,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:405,deployability,BUILD,BUILD,405,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:710,deployability,BUILD,BUILD,710,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:907,deployability,BUILD,BUILD,907,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1105,deployability,BUILD,BUILD,1105,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1303,deployability,BUILD,BUILD,1303,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1501,deployability,BUILD,BUILD,1501,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1699,deployability,BUILD,BUILD,1699,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1897,deployability,BUILD,BUILD,1897,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:193,energy efficiency,Current,Current,193,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:232,energy efficiency,Load,Loading,232,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:253,energy efficiency,Load,Loading,253,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:273,energy efficiency,load,loaded,273,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:438,energy efficiency,load,load,438,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:264,modifiability,pac,packages,264,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:45,performance,error,errors,45,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:232,performance,Load,Loading,232,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:253,performance,Load,Loading,253,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:273,performance,load,loaded,273,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:292,performance,ERROR,ERROR,292,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:313,performance,cach,cache,313,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:438,performance,load,load,438,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:597,performance,ERROR,ERROR,597,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:618,performance,cach,cache,618,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:794,performance,ERROR,ERROR,794,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:815,performance,cach,cache,815,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:992,performance,ERROR,ERROR,992,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1013,performance,cach,cache,1013,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1190,performance,ERROR,ERROR,1190,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1211,performance,cach,cache,1211,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1388,performance,ERROR,ERROR,1388,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1409,performance,cach,cache,1409,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1586,performance,ERROR,ERROR,1586,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1607,performance,cach,cache,1607,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1784,performance,ERROR,ERROR,1784,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1805,performance,cach,cache,1805,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:18,reliability,fail,fails,18,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:45,safety,error,errors,45,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:92,safety,test,test,92,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:292,safety,ERROR,ERROR,292,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:597,safety,ERROR,ERROR,597,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:794,safety,ERROR,ERROR,794,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:992,safety,ERROR,ERROR,992,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1190,safety,ERROR,ERROR,1190,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1388,safety,ERROR,ERROR,1388,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1586,safety,ERROR,ERROR,1586,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1784,safety,ERROR,ERROR,1784,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:92,testability,test,test,92,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:45,usability,error,errors,45,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:292,usability,ERROR,ERROR,292,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:306,usability,user,user,306,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:597,usability,ERROR,ERROR,597,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:611,usability,user,user,611,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:794,usability,ERROR,ERROR,794,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:808,usability,user,user,808,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:992,usability,ERROR,ERROR,992,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1006,usability,user,user,1006,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1190,usability,ERROR,ERROR,1190,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1204,usability,user,user,1204,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1388,usability,ERROR,ERROR,1388,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1402,usability,user,user,1402,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1586,usability,ERROR,ERROR,1586,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1600,usability,user,user,1600,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1784,usability,ERROR,ERROR,1784,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/43:1798,usability,user,user,1798,"built_and_test.sh fails on ubuntu 16.04; The errors (part of them). + [[ 0 = \1 ]]. + bazel test -c opt --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 deepvariant/... (00:49:22) INFO: Current date is 2018-01-27. (00:49:22) Loading:. (00:49:22) Loading: 0 packages loaded. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:96:. 1: First argument of 'load' must be a label and start with either '//', ':', or '@'. Use --incompatible_load_argument_is_label=fals. e to temporarily disable this check. (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:98:. 1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:100. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:102. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:104. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:106. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:108. :1: name 're2_test' is not defined (did you mean 'ios_test'?). (00:49:22) ERROR: /home/<user>/.cache/bazel/_bazel_ravi/74e2f34442216df8489f404815744088/external/com_googlesource_code_re2/BUILD:110. :1: name 're2_test' is not defined (did you mean 'ios_test'?)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/43
https://github.com/google/deepvariant/issues/44:197,deployability,Stage,Stage,197,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:270,deployability,Stage,Stage,270,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:277,deployability,Updat,Update,277,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:130,energy efficiency,Load,Load,130,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:284,modifiability,pac,package,284,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:130,performance,Load,Load,130,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:277,safety,Updat,Update,277,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:277,security,Updat,Update,277,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:316,security,apt,apt-get,316,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:14,usability,guid,guide,14,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:66,usability,guid,guide,66,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/44:325,usability,command,command,325,"A quick start guide issue; I was trying to follow the quick start guide. While running the run-prereq.sh file, I got. `========== Load config settings.`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Misc setup' starting`. `========== [Sun Jan 28 13:47:50 EST 2018] Stage 'Update package list' starting`. `sudo: apt-get: command not found`. Then, I realize it is because I am running it on mac. Is there any quick fix to this problem?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/44
https://github.com/google/deepvariant/issues/45:17,usability,tool,tool,17,Joint genotyping tool; Is there a recommended tool for joint genotyping the gvcfs of a trio? Thanks,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/45
https://github.com/google/deepvariant/issues/45:46,usability,tool,tool,46,Joint genotyping tool; Is there a recommended tool for joint genotyping the gvcfs of a trio? Thanks,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/45
https://github.com/google/deepvariant/issues/46:144,deployability,resourc,resources,144,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:249,deployability,version,version,249,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:8,energy efficiency,model,model,8,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:140,energy efficiency,GPU,GPU,140,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:144,energy efficiency,resourc,resources,144,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:558,energy efficiency,model,models,558,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:249,integrability,version,version,249,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:249,modifiability,version,version,249,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:314,modifiability,paramet,parameter,314,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:140,performance,GPU,GPU,140,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:144,performance,resourc,resources,144,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:144,safety,resourc,resources,144,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:707,safety,compl,completely,707,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:8,security,model,model,8,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:233,security,modif,modified,233,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:558,security,model,models,558,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:707,security,compl,completely,707,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:144,testability,resourc,resources,144,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:696,testability,understand,understand,696,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:199,usability,guid,guide,199,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:332,usability,command,command,332,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:382,usability,USER,USER,382,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:567,usability,Guid,Guide,567,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/46:764,usability,help,help,764,"Retrain model on GCP; Hi,. I have some thoughts on the **creating-pileup-image** part and really want to try it out. Since I don't have the GPU resources, I followed the **Getting Started with GCP** guide. Q1: How could I retrain my modified forked version of deep variant using gcloud? . Should I change the last parameter in this command? `gcloud beta compute instances create ""${USER}-deepvariant-quickstart""`. Q2: How could I prepare the trianing data? . You mentioned running make_examples in training mode to get the data in the **Training DeepVariant models** Guide. How do I ""providing the --confident_regions and --truth_variants arguments""? These two terms are too biological for me to understand completely. . Really appreciated if you can provide some help. . Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/46
https://github.com/google/deepvariant/issues/47:0,deployability,Build,Build,0,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:69,deployability,build,build,69,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:107,deployability,build,build,107,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:483,deployability,modul,module,483,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:129,energy efficiency,gpu,gpu,129,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:249,energy efficiency,core,core,249,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:254,interoperability,platform,platform,254,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:569,interoperability,platform,platform,569,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:742,interoperability,platform,platform,742,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:483,modifiability,modul,module,483,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:542,modifiability,pac,packages,542,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:715,modifiability,pac,packages,715,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:129,performance,gpu,gpu,129,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:10,safety,test,test,10,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:138,safety,test,tests,138,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:483,safety,modul,module,483,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:10,testability,test,test,10,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:138,testability,test,tests,138,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/47:312,testability,Trace,Traceback,312,"Build and test works, binaries do not; I'm unfamiliar with the bazel build environment. After a successful build with tensorflow-gpu, all tests passed, but on attempting to run a binary from bazel-bin I see. 2018-02-05 11:14:37.628020: I tensorflow/core/platform/s3/aws_logging.cc:53] Initializing Curl library. Traceback (most recent call last):. File ""/home2/bradBuild/deepvariant/bazel-bin/deepvariant/make_examples.runfiles/genomics/deepvariant/make_examples.py"", line 1105, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 118, in run. argv = flags.FLAGS(_sys.argv if argv is None else argv, known_only=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/flags.py"", line 112, in __call__. return self.__dict__['__wrapped'].__call__(*args, **kwargs). TypeError: __call__() got an unexpected keyword argument 'known_only'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/47
https://github.com/google/deepvariant/issues/48:40,integrability,coupl,couple,40,"Deal with multiple samples; Hi,. I have couple dozens of samples (bam files) to do the phylogenetic analysis. Do I treat the sample individually and merge the VCF files afterward, or there is something like SAMtools mpile to merge bam files before feeding to deepvariant workflow? Thanks for answering this question",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/48
https://github.com/google/deepvariant/issues/48:40,modifiability,coupl,couple,40,"Deal with multiple samples; Hi,. I have couple dozens of samples (bam files) to do the phylogenetic analysis. Do I treat the sample individually and merge the VCF files afterward, or there is something like SAMtools mpile to merge bam files before feeding to deepvariant workflow? Thanks for answering this question",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/48
https://github.com/google/deepvariant/issues/48:40,testability,coupl,couple,40,"Deal with multiple samples; Hi,. I have couple dozens of samples (bam files) to do the phylogenetic analysis. Do I treat the sample individually and merge the VCF files afterward, or there is something like SAMtools mpile to merge bam files before feeding to deepvariant workflow? Thanks for answering this question",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/48
https://github.com/google/deepvariant/issues/48:271,usability,workflow,workflow,271,"Deal with multiple samples; Hi,. I have couple dozens of samples (bam files) to do the phylogenetic analysis. Do I treat the sample individually and merge the VCF files afterward, or there is something like SAMtools mpile to merge bam files before feeding to deepvariant workflow? Thanks for answering this question",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/48
https://github.com/google/deepvariant/issues/49:73,deployability,build,build,73,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:461,deployability,pipelin,pipeline,461,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:287,energy efficiency,load,load,287,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:318,energy efficiency,core,cores,318,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:404,energy efficiency,load,load,404,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:461,integrability,pipelin,pipeline,461,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:180,performance,parallel,parallel,180,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:287,performance,load,load,287,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:404,performance,load,load,404,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:862,reliability,doe,doesn,862,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:997,reliability,doe,doesn,997,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:810,safety,input,input,810,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:841,safety,input,inputFile,841,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:935,safety,input,input,935,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:985,safety,Input,InputFile,985,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1073,safety,input,input,1073,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1190,safety,input,input,1190,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:9,security,control,control,9,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:9,testability,control,control,9,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:552,testability,simpl,simple-SG,552,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:552,usability,simpl,simple-SG,552,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:810,usability,input,input,810,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:841,usability,input,inputFile,841,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:935,usability,input,input,935,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:985,usability,Input,InputFile,985,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1073,usability,input,input,1073,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1119,usability,command,command,1119,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1190,usability,input,input,1190,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/49:1598,usability,tool,tool,1598,"How do I control the number of threads for call_variants?; I'm trying to build a scatter gather implementation of make_calls -> call_variants -> post_processing, without using GNU parallel, and since multiple shards of call_variants, even with num_readers set to 1, increases the system load well beyond the number of cores, I'd like to try to limit this to a 1:1 ratio where one shard produces a system load of 1. Is this possible? This is essentially what my pipeline looks like today: https://github.com/oskarvid/wdl_deepvariant/blob/master/deepvar-simple-SG.wdl. I say essentially because I've made insignificant changes, like added --num_readers for example. . One way would be to try to combine all tfrecord files into one, because wdl cannot use your method of using all output files from make_calls as input files for call_variants, inputFile@#shards.gz doesn't compute for wdl, and using wdl's normal way of handling multiple input files, i.e ""--examples ${sep="" --examples "" InputFile}"" doesn't work either since call_variants only takes the last ""--examples"" as input when there are many ""--examples"" in the command. Regarding combining the tfrecord files before they're used as input for call_variants, I'm not familiar enough with tensorflow to know if it's at all possible, and a quick google search didn't return anything fruitful. Is it possible to combine many tfrecord files into one? Is it easier to try to limit the number of threads per process instead of trying to combine the tfrecord files? Or is there a third method that solves this problem better? And thanks for a great tool!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/49
https://github.com/google/deepvariant/issues/50:714,availability,avail,available,714,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:890,availability,consist,consistency,890,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1116,availability,sli,slight,1116,"e ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | |",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:45,deployability,version,versions,45,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1271,deployability,version,version,1271," is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2101,deployability,Build,Build,2101," to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByNam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6043,deployability,Build,Build,6043,"igned. | . --1.36%--ssw_init. | . --0.89%--qP_byte. 27.87% , 0.05% ,python ,libssw.so ,[.] ssw_align. | . --27.82%--ssw_align. | . |--14.65%--sw_sse2_word. | . |--8.32%--sw_sse2_byte. | . |--2.91%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7627,deployability,Build,Build,7627,":_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByNam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11557,deployability,Build,Build,11557,"igned. | . --1.38%--ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:377,energy efficiency,alloc,allocated,377,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:387,energy efficiency,CPU,CPUs,387,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:474,energy efficiency,CPU,CPU,474,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:515,energy efficiency,cloud,cloud,515,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:567,energy efficiency,cpu,cpu-platform,567,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:677,energy efficiency,cpu,cpu-platform,677,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:824,energy efficiency,alloc,allocated,824,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:949,energy efficiency,CPU,CPU,949,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1326,energy efficiency,cpu,cpu-clock,1326,"garding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2555,energy efficiency,alloc,allocator,2555,"ner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf::python::cmessage::MergeFrom. | | | . | | --0.57%--google::protobuf::Message::MergeFrom. | | | . | | --0.54%--google::protobuf::internal::ReflectionOps::Merge. | | . | --0.59%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | . |--1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6457,energy efficiency,alloc,allocator,6457,"n. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6852,energy efficiency,cpu,cpu-clock,6852,"e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:8081,energy efficiency,alloc,allocator,8081,"ner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.57%--google::protobuf::python::cmessage::DeepCopy. | | . | --0.56%--google::protobuf::python::cmessage::MergeFrom. | | . | --0.56%--google::protobuf::Message::MergeFrom. | | . | --0.52%--google::protobuf::internal::ReflectionOps::Merge. | . |--1.92%--0x903b4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11971,energy efficiency,alloc,allocator,11971,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12419,energy efficiency,CPU,CPUs,12419,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12436,energy efficiency,Cloud,Cloud,12436,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:45,integrability,version,versions,45,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:739,integrability,Bridg,Bridge,739,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1271,integrability,version,version,1271," is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1319,integrability,event,event,1319,"ssion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1340,integrability,Event,Event,1340,"first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:3372,integrability,Messag,Message,3372,"-learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf::python::cmessage::MergeFrom. | | | . | | --0.57%--google::protobuf::Message::MergeFrom. | | | . | | --0.54%--google::protobuf::internal::ReflectionOps::Merge. | | . | --0.59%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | . |--1.84%--0x903b40. | | . | --1.71%--PyEval_EvalFrameEx. | . |--1.06%--0x905d60. | | . | --1.06%--PyEval_EvalFrameEx. | . |--0.76%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.59%--0x905200. | | . | --0.59%--PyEval_EvalFrameEx. | . --0.51%--0x9060a0. | . --0.51%--PyEval_EvalFrameEx. 32.95% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.10%--PyEval_EvalFrameEx. | . --30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.34%--StripedSmithWaterman::Aligner::Align. | . |--27.87%--ssw_align. | | . | |--14.65%--sw_sse2_word. | | . | |--8.32%--sw_sse2_byte. | | . | |--2.91%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.36%--ssw_init. | . --0.89%--qP_byte. 30.81% , 0.07% ,python ,libssw_cclib.so ,[.] deepvariant_realigner_python_ssw_clifwr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:3541,integrability,wrap,wrapNext,3541,"d*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf::python::cmessage::MergeFrom. | | | . | | --0.57%--google::protobuf::Message::MergeFrom. | | | . | | --0.54%--google::protobuf::internal::ReflectionOps::Merge. | | . | --0.59%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | . |--1.84%--0x903b40. | | . | --1.71%--PyEval_EvalFrameEx. | . |--1.06%--0x905d60. | | . | --1.06%--PyEval_EvalFrameEx. | . |--0.76%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.59%--0x905200. | | . | --0.59%--PyEval_EvalFrameEx. | . --0.51%--0x9060a0. | . --0.51%--PyEval_EvalFrameEx. 32.95% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.10%--PyEval_EvalFrameEx. | . --30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.34%--StripedSmithWaterman::Aligner::Align. | . |--27.87%--ssw_align. | | . | |--14.65%--sw_sse2_word. | | . | |--8.32%--sw_sse2_byte. | | . | |--2.91%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.36%--ssw_init. | . --0.89%--qP_byte. 30.81% , 0.07% ,python ,libssw_cclib.so ,[.] deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.74%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.34%--StripedSmithWaterman::Aligner::A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6845,integrability,event,event,6845,"---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6866,integrability,Event,Event,6866,"66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:8806,integrability,wrap,wrapNext,8806,". | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.57%--google::protobuf::python::cmessage::DeepCopy. | | . | --0.56%--google::protobuf::python::cmessage::MergeFrom. | | . | --0.56%--google::protobuf::Message::MergeFrom. | | . | --0.52%--google::protobuf::internal::ReflectionOps::Merge. | . |--1.92%--0x903b40. | | . | --1.78%--PyEval_EvalFrameEx. | . |--1.09%--0x905d60. | | . | --1.09%--PyEval_EvalFrameEx. | . |--0.78%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.62%--0x905200. | | . | --0.62%--PyEval_EvalFrameEx. | . --0.54%--0x9060a0. | . --0.54%--PyEval_EvalFrameEx. 33.23% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.46%--PyEval_EvalFrameEx. | . --31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.63%--StripedSmithWaterman::Aligner::Align. | . |--28.27%--ssw_align. | | . | |--14.88%--sw_sse2_word. | | . | |--8.45%--sw_sse2_byte. | | . | |--2.89%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.38%--ssw_init. | . --0.92%--qP_byte. 31.1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:8978,integrability,Messag,Message,8978,"6%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.57%--google::protobuf::python::cmessage::DeepCopy. | | . | --0.56%--google::protobuf::python::cmessage::MergeFrom. | | . | --0.56%--google::protobuf::Message::MergeFrom. | | . | --0.52%--google::protobuf::internal::ReflectionOps::Merge. | . |--1.92%--0x903b40. | | . | --1.78%--PyEval_EvalFrameEx. | . |--1.09%--0x905d60. | | . | --1.09%--PyEval_EvalFrameEx. | . |--0.78%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.62%--0x905200. | | . | --0.62%--PyEval_EvalFrameEx. | . --0.54%--0x9060a0. | . --0.54%--PyEval_EvalFrameEx. 33.23% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.46%--PyEval_EvalFrameEx. | . --31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.63%--StripedSmithWaterman::Aligner::Align. | . |--28.27%--ssw_align. | | . | |--14.88%--sw_sse2_word. | | . | |--8.45%--sw_sse2_byte. | | . | |--2.89%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.38%--ssw_init. | . --0.92%--qP_byte. 31.13% , 0.08% ,python ,libssw_cclib.so ,[.] deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --31.05%--deepvariant_realigner_python_ssw_clifwrap::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:453,interoperability,specif,specifying,453,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:555,interoperability,specif,specify-min-cpu-platform,555,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:681,interoperability,platform,platform,681,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:739,interoperability,Bridg,Bridge,739,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1405,interoperability,Share,Shared,1405,"se for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:3372,interoperability,Messag,Message,3372,"-learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf::python::cmessage::MergeFrom. | | | . | | --0.57%--google::protobuf::Message::MergeFrom. | | | . | | --0.54%--google::protobuf::internal::ReflectionOps::Merge. | | . | --0.59%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | . |--1.84%--0x903b40. | | . | --1.71%--PyEval_EvalFrameEx. | . |--1.06%--0x905d60. | | . | --1.06%--PyEval_EvalFrameEx. | . |--0.76%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.59%--0x905200. | | . | --0.59%--PyEval_EvalFrameEx. | . --0.51%--0x9060a0. | . --0.51%--PyEval_EvalFrameEx. 32.95% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.10%--PyEval_EvalFrameEx. | . --30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.34%--StripedSmithWaterman::Aligner::Align. | . |--27.87%--ssw_align. | | . | |--14.65%--sw_sse2_word. | | . | |--8.32%--sw_sse2_byte. | | . | |--2.91%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.36%--ssw_init. | . --0.89%--qP_byte. 30.81% , 0.07% ,python ,libssw_cclib.so ,[.] deepvariant_realigner_python_ssw_clifwr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6931,interoperability,Share,Shared,6931,"n_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:8978,interoperability,Messag,Message,8978,"6%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.57%--google::protobuf::python::cmessage::DeepCopy. | | . | --0.56%--google::protobuf::python::cmessage::MergeFrom. | | . | --0.56%--google::protobuf::Message::MergeFrom. | | . | --0.52%--google::protobuf::internal::ReflectionOps::Merge. | . |--1.92%--0x903b40. | | . | --1.78%--PyEval_EvalFrameEx. | . |--1.09%--0x905d60. | | . | --1.09%--PyEval_EvalFrameEx. | . |--0.78%--0x8fecc0. | PyEval_EvalFrameEx. | . |--0.62%--0x905200. | | . | --0.62%--PyEval_EvalFrameEx. | . --0.54%--0x9060a0. | . --0.54%--PyEval_EvalFrameEx. 33.23% , 0.00% ,python ,[unknown] ,[.] 0x00000000009060a0. |. ---0x9060a0. | . --32.46%--PyEval_EvalFrameEx. | . --31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --30.63%--StripedSmithWaterman::Aligner::Align. | . |--28.27%--ssw_align. | | . | |--14.88%--sw_sse2_word. | | . | |--8.45%--sw_sse2_byte. | | . | |--2.89%--banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.38%--ssw_init. | . --0.92%--qP_byte. 31.13% , 0.08% ,python ,libssw_cclib.so ,[.] deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | . --31.05%--deepvariant_realigner_python_ssw_clifwrap::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12471,interoperability,distribut,distributed,12471,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:45,modifiability,version,versions,45,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:603,modifiability,variab,variability,603,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1271,modifiability,version,version,1271," is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12483,modifiability,scenario,scenarios,12483,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12,performance,performance analys,performance analysis,12,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:387,performance,CPU,CPUs,387,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:474,performance,CPU,CPU,474,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:567,performance,cpu,cpu-platform,567,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:677,performance,cpu,cpu-platform,677,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:863,performance,perform,performed,863,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:949,performance,CPU,CPU,949,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:986,performance,performance analys,performance analysis,986,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1326,performance,cpu,cpu-clock,1326,"garding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6852,performance,cpu,cpu-clock,6852,"e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12372,performance,perform,performed,12372,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12419,performance,CPU,CPUs,12419,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:714,reliability,availab,available,714,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1116,reliability,sli,slight,1116,"e ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | |",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:441,safety,reme,remedied,441,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:622,safety,test,test,622,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:714,safety,avail,available,714,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:847,safety,test,tests,847,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12363,safety,test,tests,12363,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:587,security,control,control,587,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:714,security,availab,available,714,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:587,testability,control,control,587,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:622,testability,test,test,622,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:847,testability,test,tests,847,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12363,testability,test,tests,12363,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12,usability,perform,performance,12,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:466,usability,minim,minimal,466,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:779,usability,cancel,canceling,779,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:863,usability,perform,performed,863,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:890,usability,consist,consistency,890,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:986,usability,perform,performance,986,"Generalized performance analysis between the versions; Hi Mark (@depristo),. Sorry, I meant to put this together a while ago - regarding https://github.com/google/deepvariant/issues/27#issuecomment-364683474 - but got a bit swamped with a research deadline. In any case, this is purely for intellectual curiosity and discussion. Regarding the first point, where differences in allocated CPUs might be the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__grap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:1396,usability,Command,Command,1396," the cause for the timing, that could be remedied by specifying a minimal CPU requirement, as noted here:. https://cloud.google.com/compute/docs/instances/specify-min-cpu-platform. So to control for the variability in the test, the two options are either: a) to set the `--min-cpu-platform` setting to the maximum available (`""Intel Sandy Bridge""`), or b) to keep requesting and canceling instances until the desired one is allocated on which all tests should be performed, thus satisfying consistency. Just as a quick inspection, by looking at the CPU cycles utilization, I just ran a performance analysis of 0.4 and 0.5.1 on `make_examples` - since it displayed the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2053,usability,learn,learning,2053,"played the initial discrepancy - and there seem to be some slight increases in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2129,usability,learn,learning,2129,"in `0.5.1`, which might cumulatively affect things. In any case, below is the top of the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2213,usability,learn,learning,2213," the call-graph of percent utilization by method (per version):. #### DV 0.4. ```. # Samples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2299,usability,learn,learning,2299,"amples: 186K of event 'cpu-clock'. # Event count (approx.): 46604750000. #. # Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:2377,usability,learn,learning,2377,"Children, Self,Command ,Shared Object ,Symbol . 50.33% , 8.80% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--42.49%--PyEval_EvalFrameEx. | | . | |--30.79%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.34%--StripedSmithWaterman::Aligner::Align. | | | . | | |--27.87%--ssw_align. | | | | . | | | |--14.65%--sw_sse2_word. | | | | . | | | |--8.32%--sw_sse2_byte. | | | | . | | | |--2.91%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.36%--ssw_init. | | | . | | --0.89%--qP_byte. | | . | |--3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.05%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.07%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.63%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.59%--google::protobuf::python::cmessage::DeepCopy. | | | . | | --0.58%--google::protobuf::python::cmessage::MergeFrom. | | | . | | --0.57%--google::protobuf::Message::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:5995,usability,learn,learning,5995,"-banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.36%--ssw_init. | . --0.89%--qP_byte. 27.87% , 0.05% ,python ,libssw.so ,[.] ssw_align. | . --27.82%--ssw_align. | . |--14.65%--sw_sse2_word. | . |--8.32%--sw_sse2_byte. | . |--2.91%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6063,usability,learn,learning,6063,"sw_init. | . --0.89%--qP_byte. 27.87% , 0.05% ,python ,libssw.so ,[.] ssw_align. | . --27.82%--ssw_align. | . |--14.65%--sw_sse2_word. | . |--8.32%--sw_sse2_byte. | . |--2.91%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6139,usability,learn,learning,6139,"ign. | . --27.82%--ssw_align. | . |--14.65%--sw_sse2_word. | . |--8.32%--sw_sse2_byte. | . |--2.91%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. |",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6217,usability,learn,learning,6217,"e2_byte. | . |--2.91%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6287,usability,learn,learning,6287,". 14.65% , 14.62% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.62%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.62%--ssw_align. sw_sse2_word. 8.32% , 8.31% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.31%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.30%--ssw_align. sw_sse2_byte. 4.51% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.66%--PyEval_EvalFrameEx. | . --3.30%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:6922,usability,Command,Command,6922,"er_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.04%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --2.73%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.41%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.75%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.46%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.50%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7579,usability,learn,learning,7579,", tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7655,usability,learn,learning,7655,"etail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7739,usability,learn,learning,7739,"shtable_traits<true, false, true> >::_M_find_before_node. ```. #### DV 0.5.1. ```. # Samples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7825,usability,learn,learning,7825,"amples: 152K of event 'cpu-clock'. # Event count (approx.): 38010500000. #. # Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:7903,usability,learn,learning,7903,"Children, Self,Command ,Shared Object ,Symbol . 51.45% , 9.13% ,python ,python2.7 ,[.] PyEval_EvalFrameEx. | . |--43.33%--PyEval_EvalFrameEx. | | . | |--31.12%--deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. | | | . | | --30.63%--StripedSmithWaterman::Aligner::Align. | | | . | | |--28.27%--ssw_align. | | | | . | | | |--14.88%--sw_sse2_word. | | | | . | | | |--8.45%--sw_sse2_byte. | | | | . | | | |--2.89%--banded_sw. | | | | . | | | --1.19%--__memcpy_sse2_unaligned. | | | . | | --1.38%--ssw_init. | | | . | | --0.92%--qP_byte. | | . | |--3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | | | . | | --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | | | . | | --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | | | . | | --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | | | . | | --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | | | . | | --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | | | . | | --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. | | . | |--3.16%--google::protobuf::python::cmessage::GetAttr. | | | . | | |--1.12%--google::protobuf::python::cmessage::InternalGetScalar. | | | . | | --0.58%--google::protobuf::Descriptor::FindFieldByName. | | . | |--0.70%--deepvariant_python_allelecounter_clifwrap::pyAlleleCounter::wrapAdd_as_add. | | . | |--0.62%--deepvariant_core_python_sam__reader_clifwrap::pySamIterable::wrapNext. | | . | --0.57%--google::protobuf::python::cmessage::DeepCopy. | | . | --0.56%--google::pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11509,usability,learn,learning,11509,"-banded_sw. | | . | --1.19%--__memcpy_sse2_unaligned. | . --1.38%--ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cos",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11577,usability,learn,learning,11577,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11653,usability,learn,learning,11653,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11731,usability,learn,learning,11731,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:11801,usability,learn,learning,11801,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12372,usability,perform,performed,12372,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/50:12543,usability,help,helps,12543,"ssw_init. | . --0.92%--qP_byte. 28.27% , 0.04% ,python ,libssw.so ,[.] ssw_align. | . --28.23%--ssw_align. | . |--14.88%--sw_sse2_word. | . |--8.45%--sw_sse2_byte. | . |--2.89%--banded_sw. | . --1.19%--__memcpy_sse2_unaligned. 14.88% , 14.86% ,python ,libssw.so ,[.] sw_sse2_word. | . --14.86%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --14.86%--ssw_align. sw_sse2_word. 8.45% , 8.43% ,python ,libssw.so ,[.] sw_sse2_byte. | . --8.43%--0x9060a0. PyEval_EvalFrameEx. deepvariant_realigner_python_ssw_clifwrap::pyAligner::wrapAlign_as_align. StripedSmithWaterman::Aligner::Align. | . --8.43%--ssw_align. sw_sse2_byte. 4.72% , 0.00% ,python ,[unknown] ,[.] 0x00000000009063e0. |. ---0x9063e0. | . --3.94%--PyEval_EvalFrameEx. | . --3.57%--deepvariant_realigner_python_debruijn__graph_clifwrap::wrapBuild_as_build. | . --3.32%--learning::genomics::deepvariant::DeBruijnGraph::Build. | . --3.02%--learning::genomics::deepvariant::DeBruijnGraph::DeBruijnGraph. | . --2.63%--learning::genomics::deepvariant::DeBruijnGraph::AddEdgesForRead. | . --1.89%--learning::genomics::deepvariant::DeBruijnGraph::AddEdge. | . --1.60%--learning::genomics::deepvariant::DeBruijnGraph::EnsureVertex. | . --0.56%--std::_Hashtable<tensorflow::StringPiece, std::pair<tensorflow::StringPiece const, void*>, std::allocator<std::pair<tensorflow::StringPiece const, void*> >, std::__detail::_Select1st, std::equal_to<tensorflow::StringPiece>, tensorflow::StringPieceHasher, std::__detail::_Mod_range_hashing, std::__detail::_Default_ranged_hash, std::__detail::_Prime_rehash_policy, std::__detail::_Hashtable_traits<true, false, true> >::_M_find_before_node. ```. To do this properly would require that the tests be performed on different datasets, and different CPUs on the same Cloud environment - with different distributed scenarios - which would be cost-prohibitive for me. Hope it helps and have a great weekend! Paul.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/50
https://github.com/google/deepvariant/issues/51:212,availability,checkpoint,checkpoint,212,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:344,availability,error,error,344,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:380,deployability,Log,Logits,380,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:37,energy efficiency,model,models,37,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:285,energy efficiency,model,model,285,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:17,interoperability,compatib,compatible,17,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:344,performance,error,error,344,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:212,reliability,checkpoint,checkpoint,212,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:344,safety,error,error,344,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:380,safety,Log,Logits,380,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:37,security,model,models,37,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:285,security,model,model,285,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:380,security,Log,Logits,380,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:380,testability,Log,Logits,380,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:137,usability,command,command,137,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/51:344,usability,error,error,344,Binaries are not compatible with the models; I tried running DeepVariant-0.5.0+cl-183695032 on the quickstart dataset with the following command:. ```. python call_variants.zip --dataset_config_p. btxt a.pbtxt --checkpoint DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard/model.ckpt.index. ```. However it exits with the following error:. ```. KeyError: 'InceptionV3/Logits/Conv2d_1c_1x1/weights. ```,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/51
https://github.com/google/deepvariant/issues/52:136,availability,error,error,136,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:394,availability,error,error,394,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:125,deployability,fail,fails,125,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:26,interoperability,format,format,26,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:234,interoperability,format,format,234,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:136,performance,error,error,136,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:394,performance,error,error,394,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:125,reliability,fail,fails,125,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:549,reliability,doe,does,549,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:136,safety,error,error,136,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:394,safety,error,error,394,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:136,usability,error,error,136,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:394,usability,error,error,394,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/52:597,usability,help,help,597,"The TF examples has image/format 'None'; Hi, . when I run deepVariant, using 2 shards for the makeExample, the call_variants fails. The error is : . ```. ValueError: The TF examples in shardedExamples/examples.tfrecord@2.gz has image/format 'None' (expected 'raw') which means you might need to rerun make_examples to genenerate the examples again. ```. One confusing thing that happens: . The error only shows up only when running with my own BAM file ( mapped to hg19 ) but when I run deepVariant with the example BAM file provided by Google this does not happen. I would appreciate any kind of help. Thanks a lot, . Luisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/52
https://github.com/google/deepvariant/issues/53:0,availability,Error,Error,0,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:61,availability,error,error,61,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:844,deployability,fail,failed,844,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:820,energy efficiency,core,core,820,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:0,performance,Error,Error,0,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:61,performance,error,error,61,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:844,reliability,fail,failed,844,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:0,safety,Error,Error,0,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:61,safety,error,error,61,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:0,usability,Error,Error,0,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:61,usability,error,error,61,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/53:98,usability,command,command,98,"Error running example with hg19 genome; Hi,. I am getting an error at postprocess variants. . The command executed is:. ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. And the ouput is:. ```. 2018-03-06 11:34:21.456020: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 11:34:21.457925: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 289. 2018-03-06 11:34:21.457943: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 289. 2018-03-06 11:34:21.457949: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 11:34:21.457957: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. Any idea why I cannot change the genome to run the example?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/53
https://github.com/google/deepvariant/issues/54:0,availability,Error,Error,0,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:244,availability,error,error,244,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:555,availability,error,error,555,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:106,deployability,version,version,106,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:1108,deployability,fail,failed,1108,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:1084,energy efficiency,core,core,1084,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:106,integrability,version,version,106,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:106,modifiability,version,version,106,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:0,performance,Error,Error,0,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:244,performance,error,error,244,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:555,performance,error,error,555,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:1108,reliability,fail,failed,1108,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:0,safety,Error,Error,0,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:39,safety,compl,complete,39,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:97,safety,compl,complete,97,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:244,safety,error,error,244,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:555,safety,error,error,555,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:39,security,compl,complete,39,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:97,security,compl,complete,97,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:0,usability,Error,Error,0,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:244,usability,error,error,244,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:275,usability,command,command,275,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:555,usability,error,error,555,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/issues/54:1237,usability,help,help,1237,"Error running example Bam File on hg19 complete genome; Hi, . I am running DeepVariant using the complete version of the genome ( hg19 with all chromsomes) and the example BAM file provided by google ( NA12878_S1.chr20.10_10p1mb.bam). I get an error when postprocessing. The command executed is: . ```. /opt/deepvariant/bin/postprocess_variants --ref ""hg19.fa.gz"" --infile call_variants_output.tfrecord --outfile ""NA12878_S1.chr20.10_10p1mb.bam.vcf"". ```. and the make_file is called using:. ```. --regions chr20:10,000,000-10,010,000. ```. and I get the error:. ```. 2018-03-06 12:06:27.034036: I deepvariant/postprocess_variants.cc:87] Read from: call_variants_output.tfrecord. 2018-03-06 12:06:27.034770: I deepvariant/postprocess_variants.cc:96] Done reading: call_variants_output.tfrecord. #entries in single_site_calls = 82. 2018-03-06 12:06:27.034797: I deepvariant/postprocess_variants.cc:100] Total #entries in single_site_calls = 82. 2018-03-06 12:06:27.034805: I deepvariant/postprocess_variants.cc:102] Start SortSingleSiteCalls. 2018-03-06 12:06:27.034819: F deepvariant/core/utils.cc:84] Check failed: pos_in_fasta != contig_name_to_pos_in_fasta.end() Reference name chr20 not in contig info. ```. I appreciate any kind of help. Thanks,. Luisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/54
https://github.com/google/deepvariant/pull/55:16,deployability,releas,release,16,Create DV 0.5.2 release to fix gVCF creation.; Minimal changes to fix gVCF reference base creation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/55
https://github.com/google/deepvariant/pull/55:47,usability,Minim,Minimal,47,Create DV 0.5.2 release to fix gVCF creation.; Minimal changes to fix gVCF reference base creation.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/55
https://github.com/google/deepvariant/pull/56:16,deployability,releas,release,16,Create DV 0.5.2 release for gVCF creation fix.; Minimal change to fix gVCF reference base when merging overlapping variants and non-variant sites.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/56
https://github.com/google/deepvariant/pull/56:48,usability,Minim,Minimal,48,Create DV 0.5.2 release for gVCF creation fix.; Minimal change to fix gVCF reference base when merging overlapping variants and non-variant sites.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/56
https://github.com/google/deepvariant/pull/57:16,deployability,releas,release,16,DV 0.5.2 bugfix release: fix gVCF reference base issue; Minimal code changes to fix gVCF reference base when variant and non-variant site merging causes reference changes in the non-variant regions.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/57
https://github.com/google/deepvariant/pull/57:56,usability,Minim,Minimal,56,DV 0.5.2 bugfix release: fix gVCF reference base issue; Minimal code changes to fix gVCF reference base when variant and non-variant site merging causes reference changes in the non-variant regions.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/57
https://github.com/google/deepvariant/issues/58:112,deployability,contain,contains,112,"gVCF records sometimes have incorrect reference base; Occasionally a non-variant record in the gVCF output file contains an incorrect reference base. This occurs when a gVCF block arises in which there is eventually a variant in the middle of the block. When breaking the block, the ""right-hand side"" block needs to re-query the reference genome for the appropriate new reference base. Fixing this only requires modification to the gVCF creation in postprocess_variants.py; the variants VCF does not have this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/58
https://github.com/google/deepvariant/issues/58:205,integrability,event,eventually,205,"gVCF records sometimes have incorrect reference base; Occasionally a non-variant record in the gVCF output file contains an incorrect reference base. This occurs when a gVCF block arises in which there is eventually a variant in the middle of the block. When breaking the block, the ""right-hand side"" block needs to re-query the reference genome for the appropriate new reference base. Fixing this only requires modification to the gVCF creation in postprocess_variants.py; the variants VCF does not have this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/58
https://github.com/google/deepvariant/issues/58:491,reliability,doe,does,491,"gVCF records sometimes have incorrect reference base; Occasionally a non-variant record in the gVCF output file contains an incorrect reference base. This occurs when a gVCF block arises in which there is eventually a variant in the middle of the block. When breaking the block, the ""right-hand side"" block needs to re-query the reference genome for the appropriate new reference base. Fixing this only requires modification to the gVCF creation in postprocess_variants.py; the variants VCF does not have this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/58
https://github.com/google/deepvariant/issues/58:412,security,modif,modification,412,"gVCF records sometimes have incorrect reference base; Occasionally a non-variant record in the gVCF output file contains an incorrect reference base. This occurs when a gVCF block arises in which there is eventually a variant in the middle of the block. When breaking the block, the ""right-hand side"" block needs to re-query the reference genome for the appropriate new reference base. Fixing this only requires modification to the gVCF creation in postprocess_variants.py; the variants VCF does not have this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/58
https://github.com/google/deepvariant/issues/59:249,availability,ERROR,ERROR,249,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:438,availability,ERROR,ERROR,438,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:627,availability,ERROR,ERROR,627,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:816,availability,ERROR,ERROR,816,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1407,availability,ERROR,ERROR,1407,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:147,deployability,instal,installation,147,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:292,deployability,BUILD,BUILD,292,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:481,deployability,BUILD,BUILD,481,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:670,deployability,BUILD,BUILD,670,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:867,deployability,fail,failed,867,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:875,deployability,build,build,875,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1021,deployability,FAIL,FAILED,1021,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1029,deployability,Build,Build,1029,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1117,deployability,build,build,1117,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1226,deployability,build,build,1226,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1336,deployability,build,build,1336,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1433,deployability,build,build,1433,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:210,energy efficiency,Current,Current,210,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:416,energy efficiency,model,modeling,416,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:605,energy efficiency,model,modeling,605,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:794,energy efficiency,model,modeling,794,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1078,energy efficiency,load,loaded,1078,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:313,modifiability,pac,package,313,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:502,modifiability,pac,package,502,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:691,modifiability,pac,package,691,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:898,modifiability,pac,package,898,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1069,modifiability,pac,packages,1069,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:249,performance,ERROR,ERROR,249,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:438,performance,ERROR,ERROR,438,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:627,performance,ERROR,ERROR,627,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:816,performance,ERROR,ERROR,816,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:994,performance,time,time,994,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1078,performance,load,loaded,1078,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1407,performance,ERROR,ERROR,1407,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:867,reliability,fail,failed,867,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1021,reliability,FAIL,FAILED,1021,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:249,safety,ERROR,ERROR,249,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:370,safety,input,input,370,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:438,safety,ERROR,ERROR,438,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:559,safety,input,input,559,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:627,safety,ERROR,ERROR,627,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:748,safety,input,input,748,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:816,safety,ERROR,ERROR,816,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:955,safety,input,input,955,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1043,safety,compl,complete,1043,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1407,safety,ERROR,ERROR,1407,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1454,safety,test,tests,1454,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:416,security,model,modeling,416,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:605,security,model,modeling,605,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:794,security,model,modeling,794,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1043,security,compl,complete,1043,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1454,testability,test,tests,1454,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:249,usability,ERROR,ERROR,249,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:370,usability,input,input,370,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:438,usability,ERROR,ERROR,438,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:559,usability,input,input,559,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:627,usability,ERROR,ERROR,627,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:748,usability,input,input,748,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:816,usability,ERROR,ERROR,816,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:955,usability,input,input,955,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1407,usability,ERROR,ERROR,1407,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/59:1473,usability,Help,Help,1473,"Tensorflow issue while running build_and_test.sh on ubuntu 16.04; When I run build_and_test.sh, I get the following isssues. ```. Extracting Bazel installation... ............................. (12:58:42) INFO: Current date is 2018-03-20. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:02) ERROR: /home/vinay/deepvariant/deepvariant/BUILD:564:1: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream and referenced by '//deepvariant:modeling'. (13:01:03) ERROR: Analysis of target '//deepvariant:binaries' failed; build aborted: no such package '@org_tensorflow_slim//': Unexpected end of ZLIB input stream. (13:01:03) INFO: Elapsed time: 146.946s. (13:01:03) FAILED: Build did NOT complete successfully (60 packages loaded). Fetching https://mirror.bazel.build/ufpr.dl.sourceforge.net/project/giflib/giflib-5.1.4.tar.gz; 26,415b 43s. Fetching https://mirror.bazel.build/github.com/libjpeg-turbo/libjpeg-turbo/archive/1.5.1.tar.gz; 32,588b 42s. Fetching https://mirror.bazel.build/www.kurims.kyoto-u.ac.jp/~ooura/fft.tgz; 20,092b 40s. (13:01:03) ERROR: Couldn't start the build. Unable to run tests. ```. Please Help",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/59
https://github.com/google/deepvariant/issues/60:1991,availability,echo,echo,1991,"0"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2372,availability,operat,operations,2372,"pVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2553,availability,error,errors,2553,"ant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2747,availability,unavail,unavailable,2747,"iant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2801,availability,Error,Error,2801,"loud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package confi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2980,availability,error,errors,2980,"inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The direc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3204,availability,error,error,3204,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3352,availability,avail,available,3352,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1792,deployability,pipelin,pipeline,1792,"\. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1824,deployability,pipelin,pipelines,1824,"art-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--roo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1872,deployability,pipelin,pipeline-file,1872,"ef gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1917,deployability,log,logging,1917,"sc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2403,deployability,fail,failed,2403,"ception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The reposito",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2582,deployability,fail,failed,2582,"413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received %",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2598,deployability,fail,failed,2598,"standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2921,deployability,log,log,2921,"g ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3073,deployability,configurat,configuration,3073,"L}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3111,deployability,instal,installed,3111,"}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3148,deployability,configurat,configuration,3148,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3186,deployability,instal,installed,3186,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3516,deployability,configurat,configuration,3516,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3554,deployability,instal,installed,3554,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3799,deployability,configurat,configuration,3799,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3837,deployability,instal,installed,3837,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3857,deployability,Log,Logging,3857,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:100,energy efficiency,cloud,cloud,100,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:344,energy efficiency,MODEL,MODEL,344,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:779,energy efficiency,model,model,779,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:788,energy efficiency,MODEL,MODEL,788,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1296,energy efficiency,Model,Model,1296,": PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1344,energy efficiency,MODEL,MODEL,1344,"EL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1367,energy efficiency,model,models,1367,"E. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1457,energy efficiency,Model,Model,1457,":. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1500,energy efficiency,MODEL,MODEL,1500,"pvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1523,energy efficiency,model,models,1523,". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2067,energy efficiency,MODEL,MODEL,2067,"OLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2076,energy efficiency,MODEL,MODEL,2076,"E`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package config",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2865,energy efficiency,CPU,CPUS,2865,"\. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging be",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3227,energy efficiency,cloud,cloud,3227,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3248,energy efficiency,cloud,cloud-sdk-xenial,3248,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3426,energy efficiency,cloud,cloud,3426,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3447,energy efficiency,cloud,cloud-sdk-xenial,3447,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3621,energy efficiency,Current,Current,3621,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1792,integrability,pipelin,pipeline,1792,"\. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1824,integrability,pipelin,pipelines,1824,"art-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--roo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1872,integrability,pipelin,pipeline-file,1872,"ef gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3073,integrability,configur,configuration,3073,"L}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3148,integrability,configur,configuration,3148,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3334,integrability,pub,public,3334,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3398,integrability,repositor,repository,3398,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3516,integrability,configur,configuration,3516,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3799,integrability,configur,configuration,3799,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3926,integrability,messag,messages,3926,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3398,interoperability,repositor,repository,3398,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3926,interoperability,messag,messages,3926,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3065,modifiability,pac,package,3065,"DEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3073,modifiability,configur,configuration,3073,"L}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3140,modifiability,pac,package,3140,"OCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wron",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3148,modifiability,configur,configuration,3148,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3218,modifiability,pac,packages,3218,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3417,modifiability,pac,packages,3417,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3508,modifiability,pac,package,3508,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3516,modifiability,configur,configuration,3516,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3791,modifiability,pac,package,3791,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3799,modifiability,configur,configuration,3799,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2553,performance,error,errors,2553,"ant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2801,performance,Error,Error,2801,"loud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package confi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2865,performance,CPU,CPUS,2865,"\. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging be",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2980,performance,error,errors,2980,"inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The direc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3204,performance,error,error,3204,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3606,performance,Time,Time,3606,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3611,performance,Time,Time,3611,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3616,performance,Time,Time,3616,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2403,reliability,fail,failed,2403,"ception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The reposito",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2582,reliability,fail,failed,2582,"413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received %",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2598,reliability,fail,failed,2598,"standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3352,reliability,availab,available,3352,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:275,safety,input,inputParameters,275,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:833,safety,test,testdata,833,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:910,safety,test,testdata,910,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1917,safety,log,logging,1917,"sc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1983,safety,input,inputs,1983,",010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2553,safety,error,errors,2553,"ant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2801,safety,Error,Error,2801,"loud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package confi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2921,safety,log,log,2921,"g ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2980,safety,error,errors,2980,"inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The direc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3204,safety,error,error,3204,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3352,safety,avail,available,3352,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3857,safety,Log,Logging,3857,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:344,security,MODEL,MODEL,344,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:779,security,model,model,779,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:788,security,MODEL,MODEL,788,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1296,security,Model,Model,1296,": PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1344,security,MODEL,MODEL,1344,"EL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1367,security,model,models,1367,"E. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1457,security,Model,Model,1457,":. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1500,security,MODEL,MODEL,1500,"pvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1523,security,model,models,1523,". ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1917,security,log,logging,1917,"sc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2067,security,MODEL,MODEL,2067,"OLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2076,security,MODEL,MODEL,2076,"E`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package config",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2921,security,log,log,2921,"g ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3073,security,configur,configuration,3073,"L}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-0000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3094,security,apt,apt-utils,3094,"E=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3148,security,configur,configuration,3148,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3169,security,apt,apt-utils,3169,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3244,security,apt,apt,3244,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3290,security,sign,signatures,3290,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3352,security,availab,available,3352,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3443,security,apt,apt,3443,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3482,security,sign,signed,3482,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3516,security,configur,configuration,3516,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3537,security,apt,apt-utils,3537,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3799,security,configur,configuration,3799,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3820,security,apt,apt-utils,3820,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3857,security,Log,Logging,3857,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:833,testability,test,testdata,833,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:910,testability,test,testdata,910,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:935,testability,unit,unittest,935,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1917,testability,log,logging,1917,"sc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2921,testability,log,log,2921,"g ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3313,testability,verif,verified,3313,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3857,testability,Log,Logging,3857,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:230,usability,guid,guide,230,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:275,usability,input,inputParameters,275,"Can't Run Quickstart; Hi guys, . I'm running DeepVariant—pretty much exactly as outlined at https://cloud.google.com/genomics/deepvariant —but I can't seem to get it to work. . My `deepvariant_configuration.yaml` (unmodified from guide) is . ```. name: deepvariant_pipeline. inputParameters:. - name: PROJECT_ID. - name: OUTPUT_BUCKET. - name: MODEL. - name: DOCKER_IMAGE. - name: DOCKER_IMAGE_GPU. - name: STAGING_FOLDER_NAME. - name: OUTPUT_FILE_NAME. docker:. imageName: gcr.io/deepvariant-docker/deepvariant_runner. cmd: |. ./opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ""${PROJECT_ID}"" \. --zones 'us-*' \. --docker_image ""${DOCKER_IMAGE}"" \. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --staging ""${OUTPUT_BUCKET}""/""${STAGING_FOLDER_NAME}"" \. --model ""${MODEL}"" \. --bam gs://deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --ref gs://deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta.gz \. --regions ""chr20:10,000,000-10,010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:1983,usability,input,inputs,1983,",010,000"". ```. My `runner.sh` (changed `PROJECT_ID`,`OUTPUT_BUCKET`, and `STAGING_FOLDER_NAME`) is. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=udndv-197518 #changed. OUTPUT_BUCKET=gs://udnXXXXXX #changed. STAGING_FOLDER_NAME=staging-folder #changed. OUTPUT_FILE_NAME=output.vcf. # Model for calling whole genome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-182548131.data-wgs_standard. # Model for calling exome sequencing data. # MODEL=gs://deepvariant/models/DeepVariant/0.5.0/DeepVariant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2553,usability,error,errors,2553,"ant-inception_v3-0.5.0+cl-181413382.data-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2590,usability,command,command,2590,"ta-wes_standard. IMAGE_VERSION=0.5.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". DOCKER_IMAGE_GPU=gcr.io/deepvariant-docker/deepvariant_gpu:""${IMAGE_VERSION}"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Av",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2801,usability,Error,Error,2801,"loud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --pipeline-file deepvariant_pipeline.yaml \. --logging ""${OUTPUT_BUCKET}""/runner_logs \. --zones us-west1-b \. --inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package confi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:2980,usability,error,errors,2980,"inputs `echo \. PROJECT_ID=""${PROJECT_ID}"", \. OUTPUT_BUCKET=""${OUTPUT_BUCKET}"", \. MODEL=""${MODEL}"", \. DOCKER_IMAGE=""${DOCKER_IMAGE}"", \. DOCKER_IMAGE_GPU=""${DOCKER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The direc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:3204,usability,error,error,3204,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/60:4106,usability,help,help,4106,"KER_IMAGE_GPU}"", \. STAGING_FOLDER_NAME=""${STAGING_FOLDER_NAME}"", \. OUTPUT_FILE_NAME=""${OUTPUT_FILE_NAME}"" \. | tr -d '[:space:]'`. ```. I execute `./runner.sh`, and a few minutes later I can tell with `gcloud alpha genomics operations describe` that it's failed. That output is [attached](https://github.com/google/deepvariant/files/1835589/describe.out.txt). . I can see in it several distinct potential errors: . 1. `11: Docker run failed: command failed: [03/21/2018 23:29:54 INFO gcp_deepvariant_runner.py] Running make_examples...`. 2. ` [03/21/2018 23:29:54 WARNING __init__.py] file_cache is unavailable when using oauth2client >= 4.0.0`. 3. `[u'Error in job call-varia--root--180321-233157-28 - code 9: Quota CPUS exceeded in region us-central1']`. The `...-stderr.log` file written to `staging-folder` also begins with the errors. ```. /tmp/ggp-896952821: line 16: type: gsutil: not found. debconf: delaying package configuration, since apt-utils is not installed. debconf: delaying package configuration, since apt-utils is not installed. W: GPG error: http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 3746C208A7317B0F. W: The repository 'http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease' is not signed. debconf: delaying package configuration, since apt-utils is not installed. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0. 100 663 100 663 0 0 5012 0 --:--:-- --:--:-- --:--:-- 5022. debconf: delaying package configuration, since apt-utils is not installed. WARNING: Logging before flag parsing goes to stderr. ```. But I then see many messages about candidate variants it's found. . The directory `staging-folder/examples/0/` also includes 8 `.gz` files like `examples_output.tfrecord-00007-of-00008.gz`. . Can you help me figure out what I'm doing wrong?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/60
https://github.com/google/deepvariant/issues/61:232,safety,test,testdata,232,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:243,safety,input,input,243,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:313,safety,test,testdata,313,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:50,testability,simpl,simple,50,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:232,testability,test,testdata,232,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:313,testability,test,testdata,313,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:50,usability,simpl,simple,50,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/61:243,usability,input,input,243,"Can't copy the quickstart data; Hello, . a rather simple issue, I am following this tutorial . https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-docker.md. and at this step . `gsutil -m cp gs://deepvariant/quickstart-testdata/* input/. `. I get. `zsh: no matches found: gs://deepvariant/quickstart-testdata/*`. Thanks a lot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/61
https://github.com/google/deepvariant/issues/62:124,energy efficiency,frequenc,frequency,124,"Deep sequencing; I am interested in training DeepVariant for deep sequencing on a capture panel. We are interested in lower frequency variants - say 1%. Depth of coverage is on the order of 1000 to 1700 for the data I am using. I have set the default height of the pileup tensors to 2000 via . https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177. In a set with 497 confirmed 'true' variants I'm getting a much smaller number of variants out of make_examples:. I0404 17:02:18.420840 140137671104256 make_examples.py:1032] Found 487 candidate variants. I0404 17:02:18.421224 140137671104256 make_examples.py:620] ----- VariantCounts -----. I0404 17:02:18.421346 140137671104256 make_examples.py:624] All: 29/29 (100.00%). I0404 17:02:18.421475 140137671104256 make_examples.py:624] SNPs: 27/29 (93.10%). I0404 17:02:18.421593 140137671104256 make_examples.py:624] Indels: 2/29 (6.90%). I0404 17:02:18.421717 140137671104256 make_examples.py:624] BiAllelic: 29/29 (100.00%). I0404 17:02:18.421834 140137671104256 make_examples.py:624] MultiAllelic: 0/29 (0.00%). I0404 17:02:18.421953 140137671104256 make_examples.py:624] HomRef: 28/29 (96.55%). I0404 17:02:18.422069 140137671104256 make_examples.py:624] Het: 1/29 (3.45%). What, besides setting the pileup height to match my data, should I be looking at?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:162,testability,coverag,coverage,162,"Deep sequencing; I am interested in training DeepVariant for deep sequencing on a capture panel. We are interested in lower frequency variants - say 1%. Depth of coverage is on the order of 1000 to 1700 for the data I am using. I have set the default height of the pileup tensors to 2000 via . https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177. In a set with 497 confirmed 'true' variants I'm getting a much smaller number of variants out of make_examples:. I0404 17:02:18.420840 140137671104256 make_examples.py:1032] Found 487 candidate variants. I0404 17:02:18.421224 140137671104256 make_examples.py:620] ----- VariantCounts -----. I0404 17:02:18.421346 140137671104256 make_examples.py:624] All: 29/29 (100.00%). I0404 17:02:18.421475 140137671104256 make_examples.py:624] SNPs: 27/29 (93.10%). I0404 17:02:18.421593 140137671104256 make_examples.py:624] Indels: 2/29 (6.90%). I0404 17:02:18.421717 140137671104256 make_examples.py:624] BiAllelic: 29/29 (100.00%). I0404 17:02:18.421834 140137671104256 make_examples.py:624] MultiAllelic: 0/29 (0.00%). I0404 17:02:18.421953 140137671104256 make_examples.py:624] HomRef: 28/29 (96.55%). I0404 17:02:18.422069 140137671104256 make_examples.py:624] Het: 1/29 (3.45%). What, besides setting the pileup height to match my data, should I be looking at?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:395,usability,confirm,confirmed,395,"Deep sequencing; I am interested in training DeepVariant for deep sequencing on a capture panel. We are interested in lower frequency variants - say 1%. Depth of coverage is on the order of 1000 to 1700 for the data I am using. I have set the default height of the pileup tensors to 2000 via . https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177. In a set with 497 confirmed 'true' variants I'm getting a much smaller number of variants out of make_examples:. I0404 17:02:18.420840 140137671104256 make_examples.py:1032] Found 487 candidate variants. I0404 17:02:18.421224 140137671104256 make_examples.py:620] ----- VariantCounts -----. I0404 17:02:18.421346 140137671104256 make_examples.py:624] All: 29/29 (100.00%). I0404 17:02:18.421475 140137671104256 make_examples.py:624] SNPs: 27/29 (93.10%). I0404 17:02:18.421593 140137671104256 make_examples.py:624] Indels: 2/29 (6.90%). I0404 17:02:18.421717 140137671104256 make_examples.py:624] BiAllelic: 29/29 (100.00%). I0404 17:02:18.421834 140137671104256 make_examples.py:624] MultiAllelic: 0/29 (0.00%). I0404 17:02:18.421953 140137671104256 make_examples.py:624] HomRef: 28/29 (96.55%). I0404 17:02:18.422069 140137671104256 make_examples.py:624] Het: 1/29 (3.45%). What, besides setting the pileup height to match my data, should I be looking at?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/63:51,deployability,instal,installed,51,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:111,deployability,instal,install,111,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:201,energy efficiency,model,model,201,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:201,security,model,model,201,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:217,security,ident,identify,217,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:282,usability,learn,learning,282,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:296,usability,help,help,296,"How to work with it on Local system; Hello, I have installed all the binaries and ran all the shell scripts to install tensorflow and bazel, but after that I could not follow how to actually train the model or how to identify the snps for my files. I am sorry I am very new to deep learning. Any help would be greatly appreciate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/64:14,availability,error,error,14,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:326,availability,error,error,326,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:162,energy efficiency,model,models,162,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:575,interoperability,format,format,575,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:14,performance,error,error,14,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:326,performance,error,error,326,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:14,safety,error,error,14,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:326,safety,error,error,326,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:162,security,model,models,162,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:14,usability,error,error,14,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:112,usability,tool,tool,112,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:326,usability,error,error,326,"Training mode error: 'truth_variant needs genotypes to be used for labeling'; Dear all,. Thanks for a fantastic tool! I'm trying to further train the deepvariant models on a truth VCF for a non-human genome. When I run the make_examples script in training mode with my truth vcf and confident regions BED, I get the following error:. ```. ValueError: ('truth_variant needs genotypes to be used for labeling', reference_bases: ""A"". alternate_bases: ""G"". end: 1977. reference_name: ""NC_000962.3"". start: 1976. ). ```. I'm wondering if the truth VCF needs to be in a particular format? Or is the problem because I am working with a haploid genome and thus my truth VCF is haploid? Thank you in advance!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/65:220,testability,understand,understanding,220,"the values of the first 5 rows in the pileup image; Hi, from the section of Creating images around candidate variants in the Suppl. Mats, It seems that the values of the first 5 rows in the pileup image are all 5. Is my understanding correct? Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/65
https://github.com/google/deepvariant/issues/66:284,availability,error,error,284,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:690,availability,state,state,690,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:955,availability,echo,echo,955,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1363,availability,echo,echo,1363,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1444,availability,echo,echo,1444,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1695,availability,down,download,1695,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1902,availability,error,error,1902,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:57,deployability,instal,install,57,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:98,deployability,contain,container,98,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:121,deployability,build,build,121,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:179,deployability,contain,container,179,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:235,deployability,build,build-prereq,235,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:566,deployability,Stage,Stage,566,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:573,deployability,Instal,Install,573,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:598,deployability,infrastructur,infrastructure,598,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:655,deployability,Build,Building,655,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:664,deployability,depend,dependency,664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:982,deployability,contain,containers,982,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1088,deployability,contain,container,1088,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1295,deployability,updat,update,1295,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1316,deployability,instal,install,1316,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1403,deployability,instal,install,1403,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1431,deployability,contain,container,1431,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1646,deployability,updat,update,1646,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1664,deployability,instal,install,1664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1811,deployability,build,build-prereq,1811,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1206,energy efficiency,cloud,cloud-sdk,1206,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1470,energy efficiency,cloud,cloud,1470,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1546,energy efficiency,cloud,cloud-sdk,1546,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1584,energy efficiency,cloud,cloud,1584,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1682,energy efficiency,cloud,cloud-sdk,1682,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:664,integrability,depend,dependency,664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:690,integrability,state,state,690,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1416,integrability,configur,configure,1416,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:20,modifiability,pac,package,20,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:588,modifiability,pac,packaging,588,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:632,modifiability,pac,package,632,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:664,modifiability,depend,dependency,664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:737,modifiability,pac,package,737,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1416,modifiability,configur,configure,1416,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1461,modifiability,pac,packages,1461,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1575,modifiability,pac,packages,1575,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:284,performance,error,error,284,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1902,performance,error,error,1902,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:148,safety,compl,complied,148,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:284,safety,error,error,284,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:664,safety,depend,dependency,664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1295,safety,updat,update,1295,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1646,safety,updat,update,1646,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1902,safety,error,error,1902,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:148,security,compl,complied,148,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1248,security,AUTH,AUTHOR,1248,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1287,security,apt,apt-get,1287,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1295,security,updat,update,1295,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1305,security,apt,apt-get,1305,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1416,security,configur,configure,1416,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1487,security,apt,apt,1487,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1520,security,apt,apt,1520,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1601,security,apt,apt,1601,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1609,security,apt,apt-key,1609,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1623,security,apt,apt-key,1623,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1638,security,apt,apt-get,1638,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1646,security,updat,update,1646,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1656,security,apt,apt-get,1656,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:664,testability,depend,dependency,664,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:284,usability,error,error,284,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1009,usability,command,command,1009,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1902,usability,error,error,1902,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:1913,usability,help,help,1913,"E: Unable to locate package python-wheel; I am trying to install deepvariant within a singularity container using recipe build. I have successfully complied google-sdk within the container, when it comes to the point where its runs ""./build-prereq.sh"" script, it terminates with this error: . **Setting up unzip (6.0-9ubuntu1) ... Setting up zip (3.0-8) ... Setting up zlib1g-dev:amd64 (1:1.2.8.dfsg-1ubuntu1) ... Processing triggers for libc-bin (2.19-0ubuntu6) ... Processing triggers for sgml-base (1.26+nmu4ubuntu1) ... ========== [Tue Apr 17 00:09:23 UTC 2018] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. E: Unable to locate package python-wheel. ABORT: Aborting with RETVAL=255. Cleaning up...**. I am using singularity within in vagrant on my mac and here is my recipe file:. **Bootstrap: shub. From: singularityhub/ubuntu. %runscript. exec echo ""The runscript is the containers default runtime command!"". %files. # /home/vanessa/Desktop/hello-kitty.txt # copied to root of container. # /home/vanessa/Desktop/party_dinosaur.gif /opt/the-party-dino.gif #. %environment. export CLOUD_SDK_REPO=""cloud-sdk-$(lsb_release -c -s)"". %labels. AUTHOR mnoon@email.arizona.edu. %post. apt-get update && apt-get -y install python2.7 git wget curl . mkdir /data. echo ""The post section is where you can install, and configure your container."". echo ""deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main"" > /etc/apt/sources.list.d/google-cloud-sdk.list. curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -. apt-get update && apt-get install -y google-cloud-sdk. ##download deepVariant scripts and run them. git clone https://github.com/google/deepvariant.git. cd deepvariant. . ./build-prereq.sh. ./build_and_test.sh. ./run-prereq.sh**. I have no idea whats causing this error. any help will be appreciated. -M.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/67:508,availability,consist,consists,508,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:200,deployability,stage,stage,200,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:185,energy efficiency,current,currently,185,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:559,energy efficiency,current,current,559,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:708,interoperability,specif,specify,708,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:465,modifiability,paramet,parameter,465,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:685,security,modif,modify,685,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:842,security,modif,modify,842,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:333,testability,understand,understanding,333,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:476,usability,indicat,indicates,476,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:508,usability,consist,consists,508,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:652,usability,close,close,652,"Adding output classes to call_variant; I've been using DeepVariant for about a few months, and it's been working great for me and has been providing me with very pleasing results. I am currently at a stage where I want to add possible outcomes to the CNN in the call_variants script. Here is how I think I should proceed based on my understanding of the software:. - When training, the VCF file (that is given to the make_examples script using the 'truth_variants' parameter) indicates the true label, which consists of 0/0, 0/1, or 1/1 for each of the three current classes. - To train for a new class (e.g. something like classifying het-alt that is close to a splice region), I can modify the VCF file to specify the appropriate regions as a new unused value (e.g. '0/2'). This is as far as I could get unfortunately. I am not sure how to modify the CNN in order to look at this new class as a possible outcome. If I can get pointed in the right direction on how to do this I would appreciate it greatly!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/pull/68:34,availability,failur,failure,34,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:93,availability,error,error,93,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:101,availability,error,error,101,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:28,deployability,build,build,28,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:34,deployability,fail,failure,34,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:54,deployability,build,build,54,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:60,deployability,fail,fails,60,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:34,performance,failur,failure,34,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:93,performance,error,error,93,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:101,performance,error,error,101,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:34,reliability,fail,failure,34,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:60,reliability,fail,fails,60,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:22,safety,avoid,avoid,22,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:93,safety,error,error,93,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:101,safety,error,error,101,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:93,usability,error,error,93,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:101,usability,error,error,101,"Add missing import to avoid build failure; Otherwise, build fails on gcc6 with the following error:. error: 'accumulate' is not a member of 'std'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/issues/69:4,availability,error,error,4,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1207,availability,error,error,1207,"d examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1352,availability,checkpoint,checkpoint,1352,"l. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2213,availability,Restor,Restoring,2213,"happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2326,availability,Restor,Restoring,2326,"tializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2514,availability,checkpoint,checkpoint,2514,"-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = Ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2625,availability,checkpoint,checkpoint,2625,"his TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3603,availability,replic,replica,3603,"ing.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3676,availability,Error,Error,3676,"ensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3948,availability,replic,replica,3948,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4108,availability,replic,replica,4108,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4168,availability,replic,replica,4168,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4327,availability,replic,replica,4327,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:293,deployability,version,version,293,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:304,deployability,releas,released,304,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4525,deployability,modul,module,4525,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:25,energy efficiency,model,model,25,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:34,energy efficiency,current,currently,34,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:88,energy efficiency,model,model,88,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:325,energy efficiency,model,model,325,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:353,energy efficiency,model,model,353,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1095,energy efficiency,model,model-,1095," make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1175,energy efficiency,model,model,1175,"some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1341,energy efficiency,model,model,1341,"training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring paramete",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1420,energy efficiency,model,model-,1420,"zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1500,energy efficiency,model,model,1500,"ads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1553,energy efficiency,core,core,1553,"dent_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1598,energy efficiency,CPU,CPU,1598,"_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1754,energy efficiency,core,core,1754,"xt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1774,energy efficiency,gpu,gpu,1774,"my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queue",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2015,energy efficiency,core,core,2015,"ataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at ste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2035,energy efficiency,gpu,gpu,2035,"tart_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2095,energy efficiency,GPU,GPU,2095,"del-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2256,energy efficiency,model,model,2256,"oked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2369,energy efficiency,model,model,2369,"suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2550,energy efficiency,model,model,2550,"core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""L",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2661,energy efficiency,model,model,2661,"iled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3229,energy efficiency,core,core,3229,"rs from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3382,energy efficiency,core,core,3382,"NFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3627,energy efficiency,GPU,GPU,3627,"kpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3972,energy efficiency,GPU,GPU,3972,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4132,energy efficiency,CPU,CPU,4132,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4192,energy efficiency,GPU,GPU,4192,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4351,energy efficiency,CPU,CPU,4351,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:293,integrability,version,version,293,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2698,integrability,Queue,Queues,2698,"VX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2771,integrability,Queue,Queues,2771,"gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentErro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3543,integrability,messag,message,3543,"nt/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run().",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3888,integrability,messag,message,3888,"INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1558,interoperability,platform,platform,1558,"gions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3543,interoperability,messag,message,3543,"nt/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run().",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3694,interoperability,Coordinat,Coordinator,3694,"eues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3888,interoperability,messag,message,3888,"INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4611,interoperability,platform,platform,4611,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:293,modifiability,version,version,293,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2223,modifiability,paramet,parameters,2223,"hile the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2336,modifiability,paramet,parameters,2336,"model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4525,modifiability,modul,module,4525,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4584,modifiability,pac,packages,4584,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4,performance,error,error,4,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1207,performance,error,error,1207,"d examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1598,performance,CPU,CPU,1598,"_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1774,performance,gpu,gpu,1774,"my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queue",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1876,performance,memor,memoryClockRate,1876,"cord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2035,performance,gpu,gpu,2035,"tart_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2095,performance,GPU,GPU,2095,"del-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2698,performance,Queue,Queues,2698,"VX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2771,performance,Queue,Queues,2771,"gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentErro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3627,performance,GPU,GPU,3627,"kpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3676,performance,Error,Error,3676,"ensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3972,performance,GPU,GPU,3972,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4132,performance,CPU,CPU,4132,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4192,performance,GPU,GPU,4192,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4351,performance,CPU,CPU,4351,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1352,reliability,checkpoint,checkpoint,1352,"l. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2213,reliability,Restor,Restoring,2213,"happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2326,reliability,Restor,Restoring,2326,"tializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2514,reliability,checkpoint,checkpoint,2514,"-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = Ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2625,reliability,checkpoint,checkpoint,2625,"his TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4,safety,error,error,4,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1207,safety,error,error,1207,"d examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3676,safety,Error,Error,3676,"ensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4525,safety,modul,module,4525,"14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 314, in parse_and_run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:25,security,model,model,25,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:88,security,model,model,88,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:325,security,model,model,325,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:353,security,model,model,353,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1095,security,model,model-,1095," make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1175,security,model,model,1175,"some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1341,security,model,model,1341,"training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring paramete",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1420,security,model,model-,1420,"zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1500,security,model,model,1500,"ads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2256,security,model,model,2256,"oked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2369,security,model,model,2369,"suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2408,security,Session,Session,2408,"variant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:11",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2482,security,Session,Session,2482,"-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2550,security,model,model,2550,"core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""L",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2661,security,model,model,2661,"iled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3053,security,loss,loss,3053,"20] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3156,security,loss,loss,3156,"000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3315,security,Loss,LossTensor,3315,"y:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3434,security,Loss,LossTensor,3434,"139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3552,security,Loss,LossTensor,3552,"kpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3779,security,Loss,LossTensor,3779,"tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3897,security,Loss,LossTensor,3897,"rflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 352, in main. parse_and_run(). File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:477,testability,unit,unittest,477,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4,usability,error,error,4,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:827,usability,Document,Documents,827,"the error about training model; I currently tried to write some script to train the new model. The make_example script have created labeled data. But the model_train script have some problem. I made some labeled examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1207,usability,error,error,1207,"d examples using the WGS case study data of Deepvariant on chr20. I used the 0.6.0 version of released DeepVariant model as a started training model. **The make_examples script is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1379,usability,Document,Documents,1379,"pt is:**. `python ../bin/make_examples.zip \. --mode training \. --ref ""file/ucsc.hg19.chr20.unittest.fasta.gz"" \. --reads ""file/NA12878_S1.chr20.10_10p1mb.bam"" \. --confident_regions ""file/test_nist.b37_chr20_100kbp_at_10mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1602,usability,support,supports,1602,"mb.bed"" \. --truth_variants ""file/test_nist.b37_chr20_100kbp_at_10mb.vcf.gz"" \. --examples ""output/examples.tfrecord.gz"". `. **my-training-dataset.pbtxt file:**. `name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1876,usability,memor,memoryClockRate,1876,"cord.gz"". num_examples: 1`. **The model_train script is:**. `python ../bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/my/path/of/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt"". `. **The following error have happened while the model_train.zip is invoked:**. > I0502 10:58:51.903573 139632719935232 model_train.py:182] Initializing model from checkpoint at /home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard/model.ckpt. 2018-05-02 10:58:56.347500: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA. 2018-05-02 10:58:57.263635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:. name: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285. pciBusID: 0000:3b:00.0. totalMemory: 11.91GiB freeMemory: 11.62GiB. 2018-05-02 10:58:57.263682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:3b:00.0, compute capability: 6.0). INFO:tensorflow:Restoring parameters from /tmp/deepvariant/model.ckpt-0. I0502 10:58:57.455770 139632719935232 tf_logging.py:82] Restoring parameters from /tmp/deepvariant/model.ckpt-0. INFO:tensorflow:Starting Session. I0502 10:59:09.842276 139632719935232 tf_logging.py:82] Starting Session. INFO:tensorflow:Saving checkpoint to path /tmp/deepvariant/model.ckpt. I0502 10:59:10.099534 139621333726976 tf_logging.py:82] Saving checkpoint to path /tmp/deepvariant/model.ckpt. INFO:tensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3676,usability,Error,Error,3676,"ensorflow:Starting Queues. I0502 10:59:10.102293 139632719935232 tf_logging.py:82] Starting Queues. INFO:tensorflow:global_step/sec: 0. I0502 10:59:13.668776 139621325334272 tf_logging.py:121] global_step/sec: 0. INFO:tensorflow:Recording summary at step 0. I0502 10:59:14.875045 139621316941568 tf_logging.py:82] Recording summary at step 0. INFO:tensorflow:global step 1: loss = 0.2608 (4.963 sec/step). I0502 10:59:15.326091 139632719935232 tf_logging.py:82] global step 1: loss = 0.2608 (4.963 sec/step). 2018-05-02 10:59:15.584978: E tensorflow/core/kernels/check_numerics_op.cc:157] abnormal_detected_host @0x104ef6dce00 = {1, 0} LossTensor is inf or nan. 2018-05-02 10:59:15.615399: W tensorflow/core/framework/op_kernel.cc:1192] Invalid argument: LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, LossTensor is inf or nan : Tensor had NaN values. [[Node: train_op/CheckNumerics = CheckNumerics[T=DT_FLOAT, message=""LossTensor is inf or nan"", _device=""/job:localhost/replica:0/task:0/device:GPU:0""](control_dependency_4)]]. [[Node: train_op/control_dependency/_5647 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/device:CPU:0"", send_device=""/job:localhost/replica:0/task:0/device:GPU:0"", send_device_incarnation=1, tensor_name=""edge_14228_train_op/control_dependency"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/device:CPU:0""]()]]. Caused by op u'train_op/CheckNumerics', defined at:. File ""/tmp/Bazel.runfiles_ecWAzH/runfiles/com_google_deepvariant/deepvariant/model_train.py"", line 364, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/70:38,availability,Error,Error,38,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,availability,error,error,229,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:380,availability,operat,operations,380,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:544,availability,FAILUR,FAILURE,544,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:556,availability,Error,Error,556,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:652,availability,Error,Error,652,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:850,availability,ERROR,ERROR,850,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:899,availability,error,error,899,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:909,availability,Error,Error,909,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1005,availability,Error,Error,1005,"o insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2317,availability,checkpoint,checkpoint,2317,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2895,availability,error,error,2895,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2905,availability,Error,Error,2905,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3001,availability,Error,Error,3001,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:0,deployability,fail,failed,0,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:74,deployability,resourc,resource,74,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:544,deployability,FAIL,FAILURE,544,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:614,deployability,fail,failed,614,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:688,deployability,resourc,resource,688,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:887,deployability,fail,failed,887,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:967,deployability,fail,failed,967,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1041,deployability,resourc,resource,1041,"00: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\npa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1229,deployability,log,logging,1229,"r pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1276,deployability,stage,stage,1276,"3/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1282,deployability,log,logs,1282,"8 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(print",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1520,deployability,stage,stage,1520,"t--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1728,deployability,stage,stage,1728,"unt': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2537,deployability,modul,module,2537,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2883,deployability,fail,failed,2883,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2963,deployability,fail,failed,2963,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3037,deployability,resourc,resource,3037,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3222,deployability,api,api,3222,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:74,energy efficiency,resourc,resource,74,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:204,energy efficiency,cloud,cloud,204,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:688,energy efficiency,resourc,resource,688,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1041,energy efficiency,resourc,resource,1041,"00: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\npa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1541,energy efficiency,MODEL,MODEL,1541,"FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1564,energy efficiency,model,models,1564,"b call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1759,energy efficiency,core,cores,1759,"be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2331,energy efficiency,MODEL,MODEL,2331,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2339,energy efficiency,model,model,2339,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3037,energy efficiency,resourc,resource,3037,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:300,integrability,discover,discovery,300,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:391,integrability,filter,filter,391,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3222,integrability,api,api,3222,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:300,interoperability,discover,discovery,300,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3222,interoperability,api,api,3222,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2537,modifiability,modul,module,2537,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:38,performance,Error,Error,38,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:74,performance,resourc,resource,74,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,performance,error,error,229,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:544,performance,FAILUR,FAILURE,544,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:556,performance,Error,Error,556,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:652,performance,Error,Error,652,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:688,performance,resourc,resource,688,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:850,performance,ERROR,ERROR,850,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:899,performance,error,error,899,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:909,performance,Error,Error,909,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1005,performance,Error,Error,1005,"o insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1041,performance,resourc,resource,1041,"00: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\npa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1297,performance,disk,disk-size,1297,"scovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1794,performance,disk,disk-size,1794,"s in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2895,performance,error,error,2895,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2905,performance,Error,Error,2905,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3001,performance,Error,Error,3001,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3037,performance,resourc,resource,3037,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:0,reliability,fail,failed,0,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:544,reliability,FAIL,FAILURE,544,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:614,reliability,fail,failed,614,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:887,reliability,fail,failed,887,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:967,reliability,fail,failed,967,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2317,reliability,checkpoint,checkpoint,2317,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2883,reliability,fail,failed,2883,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2963,reliability,fail,failed,2963,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:38,safety,Error,Error,38,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:74,safety,resourc,resource,74,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,safety,error,error,229,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:556,safety,Error,Error,556,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:652,safety,Error,Error,652,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:688,safety,resourc,resource,688,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:850,safety,ERROR,ERROR,850,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:899,safety,error,error,899,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:909,safety,Error,Error,909,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1005,safety,Error,Error,1005,"o insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1041,safety,resourc,resource,1041,"00: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\npa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1229,safety,log,logging,1229,"r pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1282,safety,log,logs,1282,"8 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(print",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1456,safety,input,input-recursive,1456,"ot--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2537,safety,modul,module,2537,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2895,safety,error,error,2895,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2905,safety,Error,Error,2905,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3001,safety,Error,Error,3001,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3037,safety,resourc,resource,3037,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1229,security,log,logging,1229,"r pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1282,security,log,logs,1282,"8 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(print",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1541,security,MODEL,MODEL,1541,"FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1564,security,model,models,1564,"b call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2331,security,MODEL,MODEL,2331,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2339,security,model,model,2339,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:74,testability,resourc,resource,74,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:688,testability,resourc,resource,688,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1041,testability,resourc,resource,1041,"00: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\npa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1229,testability,log,logging,1229,"r pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1282,testability,log,logs,1282,"8 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(print",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2425,testability,Trace,Traceback,2425,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:3037,testability,resourc,resource,3037,"--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180503-232937-37 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. It seems like google api can't insert instance in the make example steps. . Any helps would be appreciated. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:38,usability,Error,Error,38,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,usability,error,error,229,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:300,usability,discov,discovery,300,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:556,usability,Error,Error,556,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:652,usability,Error,Error,652,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:850,usability,ERROR,ERROR,850,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:899,usability,error,error,899,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:909,usability,Error,Error,909,"failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHAR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1005,usability,Error,Error,1005,"o insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. ; Hi, . I have no problem with running deepvariant on example BAM on google cloud, but the following error pops out when I switch to my BAM. ```. [05/03/2018 23:30:18 INFO discovery.py] URL being requested: GET https://genomics.googleapis.com/v1alpha2/operations?filter=projectId+%3D+isb-cgc-06-0004+AND+labels.job-id+%3D+call-varia--root--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1456,usability,input,input-recursive,1456,"ot--180503-233007-45&alt=json&pageSize=256. call-varia--root--180503-233007-45: FAILURE. [u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/03/2018 23:30:18 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180503-233007-45 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-XX-XXXX', '--logging', 'gs://XXXXX/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.0', '--input-recursive', 'EXAMPLES=gs://XXXXX/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://XXXXX/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
