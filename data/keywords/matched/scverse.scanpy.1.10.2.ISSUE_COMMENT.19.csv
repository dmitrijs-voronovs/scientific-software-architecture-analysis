id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/1422:634,integrability,depend,depend,634,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:542,interoperability,conflict,conflicts,542,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:65,modifiability,version,version,65,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:149,modifiability,version,version,149,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:411,modifiability,upgrad,upgrade,411,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:570,modifiability,pac,package,570,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:634,modifiability,depend,depend,634,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:648,performance,content,content,648,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:353,reliability,availab,available,353,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:353,safety,avail,available,353,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:451,safety,avoid,avoid,451,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:557,safety,updat,updating,557,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:634,safety,depend,depend,634,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:681,safety,updat,updated,681,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:353,security,availab,available,353,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:457,security,modif,modifying,457,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:557,security,updat,updating,557,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:681,security,updat,updated,681,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:484,testability,simpl,simply,484,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:634,testability,depend,depend,634,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:303,usability,document,documentation,303,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:484,usability,simpl,simply,484,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/pull/1422:712,usability,help,helped,712,"@hhhh1230511, this PR is not part of any release yet (the latest version `scanpy==1.6` was released August 15, 2020). If you want to have the latest version from GitHub you can follow the instructions for a developer installation [here](https://scanpy.readthedocs.io/en/stable/installation.html) in the documentation, for example. Once a new release is available on `pip`, you can install it via `pip install --upgrade scanpy`. In general, you should avoid modifying the code by e.g. simply copying and pasting. This will either easily cause conflicts when updating the package or cause problems when functions from other files which depend on the content you changed but were not updated accordingly. Hope this helped and clarified things.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1422
https://github.com/scverse/scanpy/issues/1426:16,availability,error,error,16,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:249,deployability,updat,update,249,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:16,performance,error,error,16,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:16,safety,error,error,16,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:133,safety,input,inputs,133,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:249,safety,updat,update,249,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:249,security,updat,update,249,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:16,usability,error,error,16,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:133,usability,input,inputs,133,"Hi,. First, the error that you are reporting has to do with series types of the dataframes. Howerver, it's very difficult to provide inputs, because it's unclear what `database` and `groupA` are. Can you report a reproducible example? Also, can you update to scanpy 1.6? Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:12,deployability,updat,updating,12,Fixed after updating to 1.6! Many thanks! marcos,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:12,safety,updat,updating,12,Fixed after updating to 1.6! Many thanks! marcos,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1426:12,security,updat,updating,12,Fixed after updating to 1.6! Many thanks! marcos,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1426
https://github.com/scverse/scanpy/issues/1429:91,availability,avail,available,91,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:130,availability,state,states,130,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:130,integrability,state,states,130,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:91,reliability,availab,available,91,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:91,safety,avail,available,91,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:91,security,availab,available,91,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/issues/1429:224,usability,close,close,224,"Just came across this - still think its a good idea, other `make_blobs` arguments are also available and setting different random states might come in handy. Will make a small PR... If you think its not worth it we can also close the issue :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1429
https://github.com/scverse/scanpy/pull/1430:42,usability,close,close,42,"Since anndata 0.10 is not yet here, let’s close this and revisit once it’s here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1430
https://github.com/scverse/scanpy/issues/1431:1037,deployability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,deployability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:655,energy efficiency,optim,optimize,655,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1369,energy efficiency,optim,optimization,1369,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:52,integrability,filter,filter,52,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:200,integrability,filter,filter,200,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:286,integrability,filter,filtered,286,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:682,integrability,pub,published,682,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1015,integrability,batch,batch,1015,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,integrability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,integrability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,interoperability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,interoperability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,modifiability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1121,modifiability,scal,scalability,1121,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,modifiability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:490,performance,memor,memory,490,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:655,performance,optimiz,optimize,655,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:837,performance,memor,memory,837,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1015,performance,batch,batch,1015,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1071,performance,memor,memory,1071,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1121,performance,scalab,scalability,1121,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1182,performance,memor,memory,1182,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1224,performance,content,content,1224,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1297,performance,memor,memory,1297,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1369,performance,optimiz,optimization,1369,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:874,reliability,doe,doesn,874,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,reliability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,reliability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1114,safety,test,tested,1114,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,security,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,security,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1037,testability,integr,integration,1037,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1114,testability,test,tested,1114,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1141,testability,integr,integration,1141,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:490,usability,memor,memory,490,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:782,usability,usab,usable,782,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:837,usability,memor,memory,837,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1071,usability,memor,memory,1071,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1153,usability,tool,tools,1153,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1182,usability,memor,memory,1182,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1297,usability,memor,memory,1297,"Hey @ywen1407! The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1597,availability,cluster,clustering,1597,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,deployability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,deployability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1597,deployability,cluster,clustering,1597,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:669,energy efficiency,optim,optimize,669,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1383,energy efficiency,optim,optimization,1383,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:60,integrability,filter,filter,60,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:208,integrability,filter,filter,208,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:294,integrability,filter,filtered,294,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:696,integrability,pub,published,696,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1029,integrability,batch,batch,1029,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,integrability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,integrability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,interoperability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,interoperability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,modifiability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1135,modifiability,scal,scalability,1135,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,modifiability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:504,performance,memor,memory,504,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:669,performance,optimiz,optimize,669,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:851,performance,memor,memory,851,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1029,performance,batch,batch,1029,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1085,performance,memor,memory,1085,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1135,performance,scalab,scalability,1135,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1196,performance,memor,memory,1196,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1238,performance,content,content,1238,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1311,performance,memor,memory,1311,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1383,performance,optimiz,optimization,1383,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:888,reliability,doe,doesn,888,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,reliability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,reliability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1128,safety,test,tested,1128,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,security,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,security,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1051,testability,integr,integration,1051,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1128,testability,test,tested,1128,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1155,testability,integr,integration,1155,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:504,usability,memor,memory,504,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:796,usability,usab,usable,796,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:851,usability,memor,memory,851,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1085,usability,memor,memory,1085,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1167,usability,tool,tools,1167,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1196,usability,memor,memory,1196,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:1311,usability,memor,memory,1311,"> Hey @ywen1407! > . > The ideal case is that you don't pre-filter the gene sets before concatenating. Then, if you have aligned both sets of samples to the same genome, everything should be fine and you can filter out genes afterwards. Otherwise an outer join would only assume all values you filtered out were 0, which is probably not the way forward. That's why the only decent option you really have is an inner join. I assume you should have the unfiltered objects somewhere though. > . > Regarding memory use: ComBat is something we (actually, this was thanks to @Marius1311) just re-implemented from python and R code that was flying around. We do not generally optimize methods that were published elsewhere. How much RAM are you using that it's crashing? I think Marius even made ComBat usable for sparse matrices, so it's already using less memory than it was before. 38K cells doesn't sound like something that would require more than 16GB RAM. I can run datsasets with 50k locally. You can of course always try other batch correction/data integration methods that are less memory intensive such as BBKNN or scVI. We tested scalability of data integration tools (also BBKNN and ComBat memory use) here: https://www.biorxiv.org/content/10.1101/2020.05.22.111161v2. However, ComBat is one of the least memory intensive methods out there... so maybe there is little room for optimization here... Thanks for the explanation. I tried concatenating all samples with inner join and it actually went well! The overall number of genes do drop from 45K to around 20K but after preprosessing, the clustering looks OK.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/issues/1431:46,integrability,filter,filtering,46,I guess 20k genes is still quite a lot. After filtering out genes that aren't expressed in most cells i typically have between 12k and 18k genes left.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1431
https://github.com/scverse/scanpy/pull/1432:209,availability,mainten,maintenance,209,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:52,energy efficiency,core,core,52,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:74,energy efficiency,core,core-type,74,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:238,energy efficiency,core,core,238,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:209,reliability,mainten,maintenance,209,"Is this something for scanpy external or for scanpy core? It seems like a core-type functionality, but given external development easier to credit correctly in scanpy external? and there's ofc the question of maintenance if it's put into core.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:113,availability,mainten,maintenance,113,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:74,energy efficiency,core,core,74,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:128,energy efficiency,core,core,128,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:113,reliability,mainten,maintenance,113,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:79,usability,tool,tool,79,@LuckyMD Its up to you all where'd you like it. I thought it was a pretty core tool. What is the expectation for maintenance in core vs external?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:12,availability,mainten,maintenance,12,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:72,availability,mainten,maintenance,72,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:7,energy efficiency,core,core,7,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:39,energy efficiency,core,core,39,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:146,energy efficiency,core,core,146,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:12,reliability,mainten,maintenance,12,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:72,reliability,mainten,maintenance,72,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:44,security,team,team,44,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:151,security,team,team,151,"Scanpy core maintenance is done by the core team, while in external the maintenance is expected by the external contributor. Of course the scanpy core team grows as well... so i think this is a organization question maybe for @ivirshup and @flying-sheep.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:0,energy efficiency,Cool,Cool,0,Cool. Let me know what you all decide,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:99,availability,mainten,maintenance,99,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:138,energy efficiency,core,core,138,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:99,reliability,mainten,maintenance,99,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:52,security,hash,hash,52,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:68,usability,tool,tool,68,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:160,usability,document,documentation,160,Thanks for the contribution. This is great. I tried hash solo. This tool should be external as the maintenance and code falls outside the core development. The documentation should also point to the main developer of the functionality and give the due credits.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:88,deployability,fail,failing,88,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:88,reliability,fail,failing,88,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:80,safety,test,test,80,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:80,testability,test,test,80,Can you run black (https://black.readthedocs.io/en/stable/) on the new files. A test is failing because of this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:15,safety,test,tests,15,Looks like the tests passed! @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:15,testability,test,tests,15,Looks like the tests passed! @fidelram,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:56,usability,help,help,56,woo hoo! Thanks @fidelram @adamgayoso @LuckyMD for your help getting this in,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:31,usability,document,documentation,31,Shouldn't this be added to the documentation @fidelram ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:189,modifiability,maintain,maintained,189,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:106,performance,time,time,106,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:46,safety,detect,detection,46,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:189,safety,maintain,maintained,189,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:46,security,detect,detection,46,"Is there any interest in regular solo doublet detection to scanpy external? I have used scrublet for some time, but solo claims to outperform it and I am not sure that scrublet is actively maintained",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:67,energy efficiency,current,currently,67,"Hi @chris-rands I hope so. . I'm one of the authors of `solo`. I'm currently working on getting `solo` into `scvi-tools`. After that it should be relatively simple to add to scanpy. Best,. Nick",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:44,security,auth,authors,44,"Hi @chris-rands I hope so. . I'm one of the authors of `solo`. I'm currently working on getting `solo` into `scvi-tools`. After that it should be relatively simple to add to scanpy. Best,. Nick",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:157,testability,simpl,simple,157,"Hi @chris-rands I hope so. . I'm one of the authors of `solo`. I'm currently working on getting `solo` into `scvi-tools`. After that it should be relatively simple to add to scanpy. Best,. Nick",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:114,usability,tool,tools,114,"Hi @chris-rands I hope so. . I'm one of the authors of `solo`. I'm currently working on getting `solo` into `scvi-tools`. After that it should be relatively simple to add to scanpy. Best,. Nick",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/pull/1432:157,usability,simpl,simple,157,"Hi @chris-rands I hope so. . I'm one of the authors of `solo`. I'm currently working on getting `solo` into `scvi-tools`. After that it should be relatively simple to add to scanpy. Best,. Nick",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1432
https://github.com/scverse/scanpy/issues/1433:102,availability,error,error,102,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:102,performance,error,error,102,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:102,safety,error,error,102,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:9,testability,trace,traceback,9,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:102,usability,error,error,102,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:158,usability,close,close,158,"From the traceback, it'ss look like it's scvelo https://github.com/theislab/scvelo. Can you post this error with a reproducible example in scvelo repo ? Will close this, feel free to reopen if problem persist",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:52,deployability,instal,installed,52,@giovp . I solved the problem its scvelo and I have installed the package and now it works fine. Thank you,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:66,modifiability,pac,package,66,@giovp . I solved the problem its scvelo and I have installed the package and now it works fine. Thank you,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1433:115,usability,help,help,115,"Hi ,I have encountered the same problem , I knew it is beacuse a circular import ,but how can i fixed it ? can you help me ,please . ![image](https://github.com/scverse/scanpy/assets/70992194/445595ab-e15a-497f-aa93-6da339c8318c). ![Uploading image.png…]().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1433
https://github.com/scverse/scanpy/issues/1434:30,usability,feedback,feedback,30,"@havardtl, sorry for the late feedback, but this would be a great first PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1434
https://github.com/scverse/scanpy/issues/1434:11,usability,clear,clear,11,"Just to be clear, is **n_genes** = `nFeature_RNA` and **n_genes_by_counts** = `nCounts_RNA `?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1434
https://github.com/scverse/scanpy/issues/1435:53,modifiability,paramet,parameter,53,"Hej,. I would like to implement this (`n_components` parameter). If I am not mistaken, https://github.com/theislab/scanpy/blob/master/scanpy/tools/_tsne.py#L12 is the place where such an extra argument should be added. MulticoreTSNE also supports this parameter (See: https://github.com/DmitryUlyanov/Multicore-TSNE/blob/f30b34041a24bce7d2b02bb93475b0462626d5c8/MulticoreTSNE/__init__.py#L51).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:252,modifiability,paramet,parameter,252,"Hej,. I would like to implement this (`n_components` parameter). If I am not mistaken, https://github.com/theislab/scanpy/blob/master/scanpy/tools/_tsne.py#L12 is the place where such an extra argument should be added. MulticoreTSNE also supports this parameter (See: https://github.com/DmitryUlyanov/Multicore-TSNE/blob/f30b34041a24bce7d2b02bb93475b0462626d5c8/MulticoreTSNE/__init__.py#L51).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:141,usability,tool,tools,141,"Hej,. I would like to implement this (`n_components` parameter). If I am not mistaken, https://github.com/theislab/scanpy/blob/master/scanpy/tools/_tsne.py#L12 is the place where such an extra argument should be added. MulticoreTSNE also supports this parameter (See: https://github.com/DmitryUlyanov/Multicore-TSNE/blob/f30b34041a24bce7d2b02bb93475b0462626d5c8/MulticoreTSNE/__init__.py#L51).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:238,usability,support,supports,238,"Hej,. I would like to implement this (`n_components` parameter). If I am not mistaken, https://github.com/theislab/scanpy/blob/master/scanpy/tools/_tsne.py#L12 is the place where such an extra argument should be added. MulticoreTSNE also supports this parameter (See: https://github.com/DmitryUlyanov/Multicore-TSNE/blob/f30b34041a24bce7d2b02bb93475b0462626d5c8/MulticoreTSNE/__init__.py#L51).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:16,performance,time,time,16,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:224,reliability,doe,does,224,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:84,usability,user,user,84,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:96,usability,tool,tool,96,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:238,usability,support,support,238,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1435:304,usability,tool,tool,304,If I would have time for that probably. But I am no Python programmer and am only a user of the tool. On the other hand scanpy is quite hopeless with 1e+6 cells. That is why I even tried whether TSNE would work. But if that does not even support 3D I might just look for more capable SingleCell analysis tool. Probably give Scarf a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1435
https://github.com/scverse/scanpy/issues/1436:264,availability,slo,slot,264,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:388,availability,slo,slot,388,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:347,deployability,scale,scalefactor,347,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:347,energy efficiency,scale,scalefactor,347,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:130,modifiability,extens,extensions,130,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:347,modifiability,scal,scalefactor,347,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:347,performance,scale,scalefactor,347,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:264,reliability,slo,slot,264,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:388,reliability,slo,slot,388,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:184,security,hack,hacky,184,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:66,usability,support,supported,66,"Hi @vitkl , . by fullres you mean the tiff image yes? This is not supported for now unfortunately, but we are working toward some extensions to make this possible (cc @hspitzer ). One hacky way to go about this for now could be to:. - assign the tiff to the hires slot in `adata.uns['spatial]['library_id']['images']['hires']`. - change the hires scalefactor value to 1 in the respective slot. This should work. also for plotting the spots in the right size. Of course, this is also possible if you replace the ""lowres"" instead. Let me know what you think about it and if it works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:139,availability,sli,slide,139,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:480,availability,slo,slot,480,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:559,availability,slo,slot,559,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1068,availability,slo,slot,1068,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1195,availability,slo,slot,1195,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:75,deployability,pipelin,pipeline,75,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1154,deployability,scale,scalefactor,1154,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:251,energy efficiency,cool,cool,251,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1154,energy efficiency,scale,scalefactor,1154,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:75,integrability,pipelin,pipeline,75,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:602,modifiability,variab,variables,602,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:894,modifiability,extens,extensions,894,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1154,modifiability,scal,scalefactor,1154,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1154,performance,scale,scalefactor,1154,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:88,reliability,doe,doesn,88,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:139,reliability,sli,slide,139,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:480,reliability,slo,slot,480,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:494,reliability,doe,does,494,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:559,reliability,slo,slot,559,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1068,reliability,slo,slot,1068,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1195,reliability,slo,slot,1195,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:417,safety,reme,remember,417,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:145,security,scanner,scanners,145,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:394,security,hack,hacky,394,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:983,security,hack,hacky,983,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1650,security,auth,auth,1650,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:128,usability,experien,experience,128,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:537,usability,support,support,537,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:827,usability,support,supported,827,"Hi @geovp! Yes, I mean the original image that was supplied to SpaceRanger pipeline. It doesn't have to be a TIFF image - in my experience slide scanners save. JPEG images internally, so there is no value in converting that to TIFF. Also, it would be cool to use sc.pl.spatial for other technologies - say to. overlay single cell spatial over the microscopy image image. Nice, I was using this hacky way before (if I remember correctly I also. changed spot size in the respective slot) - so it does work. I am wondering if you could add support for a fullres slot with size factor. 1 and explain which variables need to be set for it to work in the tutorial. On Thu, Oct 1, 2020 at 8:32 PM giovp <notifications@github.com> wrote:. > Hi @vitkl <https://github.com/vitkl> ,. > by fullres you mean the tiff image yes? This is not supported for now. > unfortunately, but we are working toward some extensions to make this. > possible (cc @hspitzer <https://github.com/hspitzer> ). > One hacky way to go about this for now could be to:. >. > - assign the tiff to the hires slot in. > adata.uns['spatial]['library_id']['images']['hires']. > - change the hires scalefactor value to 1 in the respective slot. > This should work. also for plotting the spots in the right size. Of. > course, this is also possible if you replace the ""lowres"" instead. > Let me know what you think about it and if it works. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1436#issuecomment-702351783>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AFMFTV5FBT2DB4GKUIZUVNTSITKMBANCNFSM4R5XDYSQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:56,availability,sli,slide,56,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:458,availability,slo,slot,458,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:200,energy efficiency,cool,cool,200,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1107,energy efficiency,load,load,1107,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:500,modifiability,variab,variables,500,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1107,performance,load,load,1107,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:5,reliability,doe,doesn,5,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:56,reliability,sli,slide,56,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:458,reliability,slo,slot,458,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:62,security,scanner,scanners,62,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:650,testability,context,context,650,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:45,usability,experien,experience,45,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:353,usability,tip,tipe,353,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:436,usability,support,support,436,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:840,usability,visual,visualization,840,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:941,usability,support,supporting,941,"> It doesn't have to be a TIFF image - in my experience slide scanners save JPEG images internally, so there is no value in converting that to TIFF. . This is interesting to know. > Also, it would be cool to use sc.pl.spatial for other technologies - say to overlay single cell spatial over the microscopy image image. . Can you elaborate on this? What tipe of technology and plot do you have in mind? > I am wondering if you could add support for a fullres slot with size factor 1 and explain which variables need to be set for it to work in the tutorial. Mmh, I still think that the added value for looking at the fullres instead of the png in the context of overlaying spots to image is very little. In the hires png, even when cropping, the underlying resulting image is still quite good. Maybe not enough for analysis purpose, but for visualization should do the job no? I'm interested to hear your thoughts on this. The reason for not supporting it in the same way it's done now is that the image can be quite big (several GBs for fluorescent visium for instance) and so maybe it's not a good idea to load it in the anndata. I'll think about including a small section on this in the tutorial.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:312,availability,down,download-,312,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1122,availability,down,download-,1122,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:179,deployability,releas,released,179,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:633,deployability,depend,depends,633,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:953,deployability,contain,containing,953,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:512,energy efficiency,load,load,512,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:577,energy efficiency,load,load,577,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:633,integrability,depend,depends,633,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1066,interoperability,specif,specific,1066,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:135,modifiability,pac,package,135,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:633,modifiability,depend,depends,633,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:28,performance,multiplex,multiplexed,28,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:512,performance,load,load,512,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:577,performance,load,load,577,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:633,safety,depend,depends,633,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:633,testability,depend,depends,633,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:99,usability,visual,visualisation,99,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:333,usability,user,user-images,333,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:1143,usability,user,user-images,1143,"I mean any smFISH or highly-multiplexed protein technology. The plot I have in mind is this:. This visualisation is implemented in our package (in active development - we haven't released yet): https://cell2location.readthedocs.io/en/latest/cell2location.plt.html#cell2location.plt.mapping_video.plot_spatial. ![download-20](https://user-images.githubusercontent.com/22567383/95405951-0ea94380-0911-11eb-84bf-6f712da7875c.png). I agree that the original images can be quite large so it is probably better to not load them by default. However, it is useful to have an option to load. For the Visium data, the utility of using fullres depends on image quality and the goals. Generally, cell diameter in highres images is just 1-4 pixels meaning that a cropped image with, say 10*10 spots will look pixelated and may not be enough to recognise small structures like a gland or a blood vessel, not mentioning cell morphologies or staining (e.g. eosinophils containing red granules). For single-cell resolution data, it is often useful to zoom in to see if only cells of specific morphology express the gene, like Agt below. ![download-19](https://user-images.githubusercontent.com/22567383/95405958-12d56100-0911-11eb-9a9b-3a2faa3fa660.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:100,availability,avail,available,100,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:100,reliability,availab,available,100,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:100,safety,avail,available,100,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:100,security,availab,available,100,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1436:33,usability,feedback,feedback,33,"Hi @vitkl . thanks a lot for the feedback, all noted, we'll work toward enabling large tissue image available for storing+plotting. Will keep this open for reference!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1436
https://github.com/scverse/scanpy/issues/1437:169,usability,close,close,169,"While trying to fix it, I figured that the problem is upstream in `sinfo`. . Here's the issue I created: . https://gitlab.com/joelostblom/sinfo/-/issues/8. Feel free to close, or keep open until the problem is solved there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1437
https://github.com/scverse/scanpy/issues/1438:125,availability,error,error,125,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:125,performance,error,error,125,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:125,safety,error,error,125,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:125,usability,error,error,125,"Still happens in 2023. If I use `palette=sc.pl.palettes.zeileis_28` it works, but when I use `palette='Set2'` I got the same error",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:18,safety,reme,remember,18,"Hi @JackieMium, I remember you said something similar in another issue. If there’s things bugging you, how about making a PR that fixes it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:396,deployability,pipelin,pipeline,396,"> Hi @JackieMium, I remember you said something similar in another issue. > . > If there’s things bugging you, how about making a PR that fixes it? Not sure what you're referring to but I don't think I ever reported color pallette issue before. . I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:396,integrability,pipelin,pipeline,396,"> Hi @JackieMium, I remember you said something similar in another issue. > . > If there’s things bugging you, how about making a PR that fixes it? Not sure what you're referring to but I don't think I ever reported color pallette issue before. . I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:20,safety,reme,remember,20,"> Hi @JackieMium, I remember you said something similar in another issue. > . > If there’s things bugging you, how about making a PR that fixes it? Not sure what you're referring to but I don't think I ever reported color pallette issue before. . I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:262,usability,help,help,262,"> Hi @JackieMium, I remember you said something similar in another issue. > . > If there’s things bugging you, how about making a PR that fixes it? Not sure what you're referring to but I don't think I ever reported color pallette issue before. . I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:376,usability,learn,learning,376,"> Hi @JackieMium, I remember you said something similar in another issue. > . > If there’s things bugging you, how about making a PR that fixes it? Not sure what you're referring to but I don't think I ever reported color pallette issue before. . I hope I could help fix things but I am familiar with R/Seurat and Python/scanpy is a whole new universe to me. I am starting to learning the scanpy pipeline. How things work under the hood with scanpy or basically Python plotting are really beyond my capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:677,deployability,log,logic,677,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:61,reliability,doe,doesn,61,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:317,reliability,doe,does,317,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:677,safety,log,logic,677,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:722,safety,compl,complex,722,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:677,security,log,logic,677,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:722,security,compl,complex,722,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:81,testability,simpl,simpler,81,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:677,testability,log,logic,677,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:690,testability,understand,understand,690,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:81,usability,simpl,simpler,81,"Yeah, plotting in python is difficult, and our plotting code doesn’t make things simpler. This is the relevant part:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_anndata.py#L273-L284. The code that behaves like advertised in the docs is in here, but that function does more things after that:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_utils.py#L364. There’s also this:. https://github.com/scverse/scanpy/blob/0594b7f03917f8c5166d5bb2752031e1665065de/scanpy/plotting/_tools/scatterplots.py#L1181. I think things should be unified so they use the same palette selection logic. But I understand that that’s a pretty complex part of our code base. I meant this comment: https://github.com/scverse/scanpy/issues/1258#issuecomment-1626690231",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,availability,error,error,318,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:324,integrability,messag,message,324,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:72,interoperability,specif,specify,72,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:324,interoperability,messag,message,324,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,performance,error,error,318,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,safety,error,error,318,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,usability,error,error,318,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:1100,usability,help,helps,1100,"I don't know how to fix this in the code, but I do find a workaround to specify a color palette. Turns out both `sc.pl.umap()` and `sc.pl.scatter()` accept a color palette if it's from `seaborn` color palette:. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette='Set3'). ```. throws the above error message. But if I use. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=sns.color_palette('Set3')). ```. if works as expected. Also you can manually assign a color list as :. ```py. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=[. '#000000', '#575757', '#AD2323', '#2A4BD7', '#1D6914', . '#814A19', '#8126C0', '#A0A0A0', '#81C57A', '#9DAFFF', . '#29D0D0', '#FF9233', '#FFEE33', '#E9DEBB', '#FFCDF3', . '#F2F3F4'. ]). ```. `palette=sc.pl.palettes.zeileis_28` works because `sc.pl.palettes.zeileis_28` is already a list of color. This also works for the `palete` argument in`sc.pl.umap()`, but it changes the `adata.uns['louvain_colors']` column values and will change other plots when using this column for plotting. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:12,interoperability,standard,standard,12,"Or just the standard matplotlib palettes, yes:. ```py. from matplotlib import cm. sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). ```. The bug is that you can’t pass the colormap name. Passing a colormap directly works.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,availability,state,state,318,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:318,integrability,state,state,318,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:14,interoperability,standard,standard,14,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:351,performance,time,time,351,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:333,usability,document,documents,333,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1438:365,usability,clear,clear,365,"> Or just the standard matplotlib palettes, yes:. > . > ```python. > from matplotlib import cm. > . > sc.pl.scatter(adata, 'n_genes', 'n_counts', color='louvain', palette=cm.get_cmap('Set3')). > ```. > . > The bug is that you can’t pass the colormap name. Passing a colormap directly works. Is it then, a good idea to state this the documents for the time being to clear the confusion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1438
https://github.com/scverse/scanpy/issues/1439:114,deployability,instal,install,114,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```. python3 -m venv venv. source venv/bin/activate. pip install -e . . pip install ""anndata<=0.7.3"". python3 -c ""import scanpy as sc"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:133,deployability,instal,install,133,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```. python3 -m venv venv. source venv/bin/activate. pip install -e . . pip install ""anndata<=0.7.3"". python3 -c ""import scanpy as sc"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:34,safety,Test,Test,34,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```. python3 -m venv venv. source venv/bin/activate. pip install -e . . pip install ""anndata<=0.7.3"". python3 -c ""import scanpy as sc"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:34,testability,Test,Test,34,"Hej,. I stumbled upon your issue. Test for my PR #1440:. ```. python3 -m venv venv. source venv/bin/activate. pip install -e . . pip install ""anndata<=0.7.3"". python3 -c ""import scanpy as sc"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:152,deployability,version,version,152,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:441,deployability,version,version,441,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:152,integrability,version,version,152,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:441,integrability,version,version,441,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:152,modifiability,version,version,152,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:441,modifiability,version,version,441,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:479,usability,support,supported,479,"Thank you for your PR! I am, however, not sure if #1440 suffices: For one, `anndata/_core/merge.py:concat` only exists since `anndata==0.7.2a1`, so the version of `anndata` in `scanpy/requirements.txt` has to be bumped up to at least `anndata>=0.7.2a1` (`anndata>=0.7.2` would probably be better). In addition, prior to `anndata==0.7.4`, many bug fixes have been implemented for `anndata/_core/merge.py:concat`. Begs the question if a prior version is even desirable / should be supported. @ivirshup, any thoughts on this since you implemented the function?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:56,deployability,version,version,56,You're totally right. Opening a PR to bump the required version now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:56,integrability,version,version,56,You're totally right. Opening a PR to bump the required version now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:56,modifiability,version,version,56,You're totally right. Opening a PR to bump the required version now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:61,security,hack,hackers,61,I am still having this issue. How can this be solved for non-hackers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:61,deployability,version,version,61,"@balthasar0810, are you running into this with an up to date version of anndata?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:61,integrability,version,version,61,"@balthasar0810, are you running into this with an up to date version of anndata?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:61,modifiability,version,version,61,"@balthasar0810, are you running into this with an up to date version of anndata?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:87,deployability,version,versions,87,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:279,deployability,instal,install,279,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:403,deployability,build,build,403,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:411,deployability,build,build-arg,411,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:437,deployability,build,build-arg,437,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:505,deployability,Fail,Fails,505,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:531,deployability,build,build,531,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:539,deployability,build,build-arg,539,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:565,deployability,build,build-arg,565,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:695,deployability,modul,module,695,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:785,deployability,modul,module,785,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:87,integrability,version,versions,87,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:87,modifiability,version,versions,87,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:695,modifiability,modul,module,695,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:742,modifiability,pac,packages,742,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:785,modifiability,modul,module,785,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:922,modifiability,pac,packages,922,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:505,reliability,Fail,Fails,505,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:695,safety,modul,module,695,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:785,safety,modul,module,785,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:628,testability,Trace,Traceback,628,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/issues/1439:171,usability,Confirm,Confirming,171,"I had a false alarm related to this just now (I thought I was on recent anndata+scanpy versions, but a defunct older clone of anndata was sneaking onto my `$PYTHONPATH`). Confirming it's fixed:. **Dockerfile:**. ```Dockerfile. FROM python:3.8.5. ARG anndata. ARG scanpy. RUN pip install anndata==${anndata} scanpy==${scanpy}. ENTRYPOINT [""python"",""-c"",""import scanpy""]. ```. **Works:**. ```bash. docker build --build-arg anndata=0.7.5 --build-arg scanpy=1.7.1 -t scanpy . && docker run scanpy # ✅. ```. **Fails:**. ```bash. docker build --build-arg anndata=0.7.3 --build-arg scanpy=1.6.1 -t scanpy . && docker run scanpy # ❌. # Traceback (most recent call last):. # File ""<string>"", line 1, in <module>. # File ""/usr/local/lib/python3.8/site-packages/scanpy/__init__.py"", line 41, in <module>. # from anndata import AnnData, concat. # ImportError: cannot import name 'concat' from 'anndata' (/usr/local/lib/python3.8/site-packages/anndata/__init__.py). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1439
https://github.com/scverse/scanpy/pull/1440:84,deployability,updat,update,84,"Thanks! This will, however, only work for `anndata>=0.7.2a1`. So you'd also have to update `scanpy/requirements.txt`. I left some more comments in #1439.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:84,safety,updat,update,84,"Thanks! This will, however, only work for `anndata>=0.7.2a1`. So you'd also have to update `scanpy/requirements.txt`. I left some more comments in #1439.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:84,security,updat,update,84,"Thanks! This will, however, only work for `anndata>=0.7.2a1`. So you'd also have to update `scanpy/requirements.txt`. I left some more comments in #1439.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:147,deployability,version,versions,147,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:202,deployability,version,version,202,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:147,integrability,version,versions,147,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:202,integrability,version,version,202,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:147,modifiability,version,versions,147,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/pull/1440:202,modifiability,version,version,202,"Thanks for the contribution! For the reasons outlined in the issue, and because there are a number of important bug fixes related to h5py in newer versions of anndata, I'd like to stick with the higher version restriction as the solution to this. Closing as superseded by #1491",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1440
https://github.com/scverse/scanpy/issues/1441:25,safety,test,test,25,I would suggest `scanpy\[test\]` . Works with BASH and ZSH.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:25,testability,test,test,25,I would suggest `scanpy\[test\]` . Works with BASH and ZSH.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:129,deployability,instal,install,129,"Noglob turns off all globbing though. Would be great if one could turn off just Extended globbing for a command. After all, `pip install *.whl` could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:80,modifiability,Exten,Extended,80,"Noglob turns off all globbing though. Would be great if one could turn off just Extended globbing for a command. After all, `pip install *.whl` could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/issues/1441:104,usability,command,command,104,"Noglob turns off all globbing though. Would be great if one could turn off just Extended globbing for a command. After all, `pip install *.whl` could be useful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1441
https://github.com/scverse/scanpy/pull/1442:97,deployability,automat,automatically,97,"FYI: The related issue seems not to be added as a linked issue and will, probably, not be closed automatically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:97,testability,automat,automatically,97,"FYI: The related issue seems not to be added as a linked issue and will, probably, not be closed automatically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:90,usability,close,closed,90,"FYI: The related issue seems not to be added as a linked issue and will, probably, not be closed automatically.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/pull/1442:0,usability,Close,Closed,0,Closed in favour of #1444.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1442
https://github.com/scverse/scanpy/issues/1443:135,integrability,messag,message,135,"Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to `scvi-tools`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:135,interoperability,messag,message,135,"Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to `scvi-tools`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:161,usability,tool,tools,161,"Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to `scvi-tools`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,deployability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,integrability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,interoperability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:461,interoperability,standard,standard,461,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:44,modifiability,pac,packages,44,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:131,modifiability,pac,packages,131,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:404,modifiability,pac,packages,404,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,modifiability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,reliability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,security,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:443,testability,integr,integrated,443,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:262,usability,user,users,262,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:350,usability,tool,tools,350,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:433,usability,tool,tools,433,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:477,usability,workflow,workflow,477,"With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. . Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:218,deployability,updat,update,218,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,deployability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:163,integrability,messag,message,163,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,integrability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:163,interoperability,messag,message,163,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,interoperability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:784,interoperability,standard,standard,784,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:364,modifiability,pac,packages,364,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:451,modifiability,pac,packages,451,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:727,modifiability,pac,packages,727,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,modifiability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,reliability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:218,safety,updat,update,218,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:218,security,updat,update,218,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,security,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:766,testability,integr,integrated,766,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:188,usability,tool,tools,188,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:582,usability,user,users,582,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:673,usability,tool,tools,673,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:756,usability,tool,tools,756,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:800,usability,workflow,workflow,800,"Thanks for the responses! > Sounds reasonable, would you want to add anything more to Ecosystem about this? Also, would you like to make a PR with the deprecation message pointing to scvi-tools? I already made a PR to update the docs (https://scanpy.readthedocs.io/en/latest/ecosystem.html). I can also do the latter. > With the scanpy ecosystem growing also with packages outside of scanpy external, it would probably be good to have a page with all packages that are part of this ecosystem. Ideally this would be on the Scanpy page I guess as it would be a first port-of-call for users. >. > Such a page could have brief explanations of the capabilities of each of these tools, and link to tutorials from all the independent packages that show how these tools are integrated into a standard Scanpy workflow. What do you guys think? Is this different than the ecosystem page? Sounds reasonable though",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,deployability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:66,energy efficiency,cool,cool,66,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,integrability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,interoperability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,modifiability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,reliability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,security,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:141,testability,integr,integration,141,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:126,usability,clear,clear,126,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1443:204,usability,tool,tools,204,"Hah, so I wasn't aware of the ecosystem page yet. This looks very cool, and could really be built upon nicely. I think a more clear tutorial integration into the page would be useful.... and I guess some tools don't really have any brief explanations there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1443
https://github.com/scverse/scanpy/issues/1445:110,deployability,api,api,110,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:206,deployability,api,api,206,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:110,integrability,api,api,110,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:206,integrability,api,api,206,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:110,interoperability,api,api,110,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:206,interoperability,api,api,206,"Hi @bfurtwa ,. would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:34,deployability,contain,contain,34,"Hi @giovp ,. although these plots contain very similar information, I specifically need the variance explained annotation in the scatter plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:70,interoperability,specif,specifically,70,"Hi @giovp ,. although these plots contain very similar information, I specifically need the variance explained annotation in the scatter plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:332,deployability,api,api,332,"Have you thought about just adding it to the axis like this? ```python. plt.xlabel(f""PC var: {adata.uns[""pca""][""variance_ratio""][0]}""). ```. Any scanpy function can return a matplotlib axis, that could be further manipulated, checkout the `return_axis` argument of e.g. pca plotting function https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:332,integrability,api,api,332,"Have you thought about just adding it to the axis like this? ```python. plt.xlabel(f""PC var: {adata.uns[""pca""][""variance_ratio""][0]}""). ```. Any scanpy function can return a matplotlib axis, that could be further manipulated, checkout the `return_axis` argument of e.g. pca plotting function https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:332,interoperability,api,api,332,"Have you thought about just adding it to the axis like this? ```python. plt.xlabel(f""PC var: {adata.uns[""pca""][""variance_ratio""][0]}""). ```. Any scanpy function can return a matplotlib axis, that could be further manipulated, checkout the `return_axis` argument of e.g. pca plotting function https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:89,integrability,translat,translate,89,"I don't think we'll prioritize adding such functionality, also because it doesn't really translate to other types of embedding. But if you think it's really necessary feel free to open a PR, I'd be happy to help with that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:89,interoperability,translat,translate,89,"I don't think we'll prioritize adding such functionality, also because it doesn't really translate to other types of embedding. But if you think it's really necessary feel free to open a PR, I'd be happy to help with that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:74,reliability,doe,doesn,74,"I don't think we'll prioritize adding such functionality, also because it doesn't really translate to other types of embedding. But if you think it's really necessary feel free to open a PR, I'd be happy to help with that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1445:207,usability,help,help,207,"I don't think we'll prioritize adding such functionality, also because it doesn't really translate to other types of embedding. But if you think it's really necessary feel free to open a PR, I'd be happy to help with that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1445
https://github.com/scverse/scanpy/issues/1446:11,availability,error,error,11,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,performance,error,error,11,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,safety,error,error,11,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,usability,error,error,11,I saw this error in my analysis as welll.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,availability,error,error,11,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,performance,error,error,11,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,safety,error,error,11,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:11,usability,error,error,11,"Exact same error also happened to me in my analysis, need a fix.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:97,deployability,log,logFC,97,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:248,deployability,log,logFC,248,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:380,deployability,log,logFC,380,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:33,integrability,filter,filtered,33,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:97,safety,log,logFC,97,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:248,safety,log,logFC,248,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:380,safety,log,logFC,380,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:97,security,log,logFC,97,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:248,security,log,logFC,248,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:297,security,sign,significant,297,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:380,security,log,logFC,380,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:97,testability,log,logFC,97,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:248,testability,log,logFC,248,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:380,testability,log,logFC,380,"In the main code, they have just filtered the gene names and they haven't done anything with the logFC, thus they get left out. I have written the code which can take care of this, please do let me know if I can push this or not. Besides this, the logFC can be negative but still they are equally significant as that of positive, so can we use **abs** so that the genes for which logFC < -threshold, also holds??",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:64,availability,state,states,64,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:221,availability,cluster,cluster,221,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:221,deployability,cluster,cluster,221,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:64,integrability,state,states,64,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:147,integrability,filter,filtered,147,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:191,testability,simpl,simply,191,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:25,usability,close,closed,25,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:42,usability,document,documentation,42,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:181,usability,User,Users,181,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:191,usability,simpl,simply,191,"@giovp this issue can be closed since the documentation already states that ""To preserve the original structure of adata.uns[‘rank_genes_groups’], filtered genes are set to NaN."" . Users can simply drop the NANs for each cluster column in the adata.uns[‘rank_genes_groups_filtered’] dataframe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1446:66,usability,close,closed,66,"thanks @sayali7 , @scverse/scanpy this issue could be potentially closed",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1446
https://github.com/scverse/scanpy/issues/1448:73,deployability,updat,updated,73,> Can you elaborate? You can use `sc.pl.violin` independently. OK I just updated my question and attached a sample image. What I want to do is split-violinplot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:73,safety,updat,updated,73,> Can you elaborate? You can use `sc.pl.violin` independently. OK I just updated my question and attached a sample image. What I want to do is split-violinplot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:73,security,updat,updated,73,> Can you elaborate? You can use `sc.pl.violin` independently. OK I just updated my question and attached a sample image. What I want to do is split-violinplot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:15,deployability,updat,update,15,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:296,modifiability,variab,variable,296,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:15,safety,updat,update,15,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:15,security,updat,update,15,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:125,testability,simpl,simply,125,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:30,usability,clear,clear,30,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:125,usability,simpl,simply,125,"Thanks for the update. Now is clear. We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:17,deployability,updat,update,17,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:602,interoperability,distribut,distributions,602,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:310,modifiability,variab,variable,310,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:17,safety,updat,update,17,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:17,security,updat,update,17,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:133,testability,simpl,simply,133,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:32,usability,clear,clear,32,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:133,usability,simpl,simply,133,"> Thanks for the update. Now is clear. > . > We do not offer that possibility as most of those functions are based on seaborn, thus, simply passing the relevant data to seaborn will get you the image that you want. > . > Nevertheless, I would like to take a look. How do you think this should work. Just add a variable to show the genes that you would like to see. Or you mean a more generic function just to make split plots between any two categories for the genes that you want to see? Thanks for your attention. Yes it would be nice if I could compare two .obs categories with regard to expression distributions of a list of genes I supply. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:232,deployability,stack,stack,232,"This is a way to do it btw:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). adata = adata[adata.obs.louvain.isin(['0','1'])].copy(). df = sc.get.obs_df(adata, ['PTPN7', 'SMAP2', 'PPDPF', 'louvain']). df = df.set_index('louvain').stack().reset_index(). df.columns = ['louvain', 'gene', 'value']. import seaborn as sns. sns.violinplot(data=df, x='gene', y='value', hue=""louvain"",. split=True, inner=""quart"", linewidth=1) . ```. ![image](https://user-images.githubusercontent.com/4964309/95832957-4a8e3f80-0d3b-11eb-8bbf-47366408815a.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:446,usability,user,user-images,446,"This is a way to do it btw:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). adata = adata[adata.obs.louvain.isin(['0','1'])].copy(). df = sc.get.obs_df(adata, ['PTPN7', 'SMAP2', 'PPDPF', 'louvain']). df = df.set_index('louvain').stack().reset_index(). df.columns = ['louvain', 'gene', 'value']. import seaborn as sns. sns.violinplot(data=df, x='gene', y='value', hue=""louvain"",. split=True, inner=""quart"", linewidth=1) . ```. ![image](https://user-images.githubusercontent.com/4964309/95832957-4a8e3f80-0d3b-11eb-8bbf-47366408815a.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:248,deployability,stack,stack,248,"> This is a way to do it btw:. > . > ```python. > adata = sc.datasets.pbmc68k_reduced(). > adata = adata[adata.obs.louvain.isin(['0','1'])].copy(). > df = sc.get.obs_df(adata, ['PTPN7', 'SMAP2', 'PPDPF', 'louvain']). > df = df.set_index('louvain').stack().reset_index(). > df.columns = ['louvain', 'gene', 'value']. > import seaborn as sns. > sns.violinplot(data=df, x='gene', y='value', hue=""louvain"",. > split=True, inner=""quart"", linewidth=1) . > ```. > . > ![image](https://user-images.githubusercontent.com/4964309/95832957-4a8e3f80-0d3b-11eb-8bbf-47366408815a.png). Thanks for the suggestion! I am new to pthon. In your samples, you have '0' and '1' conditions in 'louvain'. But what if I have three conditions, How can I split the violin? Best,. Young",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1448:478,usability,user,user-images,478,"> This is a way to do it btw:. > . > ```python. > adata = sc.datasets.pbmc68k_reduced(). > adata = adata[adata.obs.louvain.isin(['0','1'])].copy(). > df = sc.get.obs_df(adata, ['PTPN7', 'SMAP2', 'PPDPF', 'louvain']). > df = df.set_index('louvain').stack().reset_index(). > df.columns = ['louvain', 'gene', 'value']. > import seaborn as sns. > sns.violinplot(data=df, x='gene', y='value', hue=""louvain"",. > split=True, inner=""quart"", linewidth=1) . > ```. > . > ![image](https://user-images.githubusercontent.com/4964309/95832957-4a8e3f80-0d3b-11eb-8bbf-47366408815a.png). Thanks for the suggestion! I am new to pthon. In your samples, you have '0' and '1' conditions in 'louvain'. But what if I have three conditions, How can I split the violin? Best,. Young",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1448
https://github.com/scverse/scanpy/issues/1449:94,modifiability,paramet,parameter,94,I think that we should deprecate this function. What I use instead is the `min_logfoldchange` parameter of the `sc.pl.rank_genes_groups_*` plots,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1449
https://github.com/scverse/scanpy/issues/1450:56,deployability,api,api,56,does this help? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.stacked_violin.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:56,integrability,api,api,56,does this help? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.stacked_violin.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:56,interoperability,api,api,56,does this help? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.stacked_violin.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:0,reliability,doe,does,0,does this help? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.stacked_violin.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:10,usability,help,help,10,does this help? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.stacked_violin.html,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:108,deployability,stack,stacked,108,"Thanks for the reply. I looked at that source but I am still not able to generate that plot. I can generate stacked violin plots, as in the core plotting vignette, but have not found a way to draw the plot like the one above (adding the barplot on top of the violin plot, etc.). Any additional advice on how to do it? Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:140,energy efficiency,core,core,140,"Thanks for the reply. I looked at that source but I am still not able to generate that plot. I can generate stacked violin plots, as in the core plotting vignette, but have not found a way to draw the plot like the one above (adding the barplot on top of the violin plot, etc.). Any additional advice on how to do it? Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:192,energy efficiency,draw,draw,192,"Thanks for the reply. I looked at that source but I am still not able to generate that plot. I can generate stacked violin plots, as in the core plotting vignette, but have not found a way to draw the plot like the one above (adding the barplot on top of the violin plot, etc.). Any additional advice on how to do it? Thanks again!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:11,deployability,version,version,11,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:187,deployability,api,api,187,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:322,deployability,api,api,322,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:336,deployability,Stack,StackedViolin,336,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:376,deployability,Stack,StackedViolin,376,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:555,deployability,Stack,StackedViolin,555,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:11,integrability,version,version,11,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:187,integrability,api,api,187,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:322,integrability,api,api,322,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:187,interoperability,api,api,187,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:322,interoperability,api,api,322,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:11,modifiability,version,version,11,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:131,usability,document,documented,131,"The latest version of scanpy added the possibility to enhance the plots in multiple ways. For this you need to use the new classes documented here https://scanpy.readthedocs.io/en/stable/api/scanpy.plotting.html#classes. In particular you want to check the function `add_totals()`: https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.StackedViolin.add_totals.html#scanpy.pl.StackedViolin.add_totals. For your case you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}. sc.pl.StackedViolin(adata, markers, groupby='bulk_labels').add_totals().show(). ```. Other options using the function that you are familiar with is:. ```PYTHON. # here return_fig=True is used. plot = sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', return_fig=True). plot.add_totals().show(). ```. You can find further info here: https://github.com/theislab/scanpy/pull/1210",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1450:19,usability,help,help,19,Thank you for your help! Super useful.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1450
https://github.com/scverse/scanpy/issues/1451:128,deployability,scale,scale,128,"If I recall correctly, the implementation mimic the one found in seaborn. Besides, the idea is to map the gene expression to an scale from 0 to 1, thus is needed to subtract the min.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:128,energy efficiency,scale,scale,128,"If I recall correctly, the implementation mimic the one found in seaborn. Besides, the idea is to map the gene expression to an scale from 0 to 1, thus is needed to subtract the min.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:165,integrability,sub,subtract,165,"If I recall correctly, the implementation mimic the one found in seaborn. Besides, the idea is to map the gene expression to an scale from 0 to 1, thus is needed to subtract the min.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:128,modifiability,scal,scale,128,"If I recall correctly, the implementation mimic the one found in seaborn. Besides, the idea is to map the gene expression to an scale from 0 to 1, thus is needed to subtract the min.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:128,performance,scale,scale,128,"If I recall correctly, the implementation mimic the one found in seaborn. Besides, the idea is to map the gene expression to an scale from 0 to 1, thus is needed to subtract the min.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:314,energy efficiency,heat,heat,314,"Exactly. But I do agree that it can be misleading in some cases e.g if there is one cell with a single UMI out of 1000 cells, this nonzero mean value will be mapped to 1, giving the impression that there is something going on. I recently abandoned standard_scale and switched to zscore and RdBu_r colormap both in heat maps and dotplots with vmin=-3 and vmax=3, which leads to a better standardization. The only caveat of this normalization in dotplot is that the dot size is determined by the number of cells above the average, which was possibly higher than zero before zscore, compared to the regular zero cutoff. In this sense it makes it more stringent than zero expression cutoff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:386,integrability,standardiz,standardization,386,"Exactly. But I do agree that it can be misleading in some cases e.g if there is one cell with a single UMI out of 1000 cells, this nonzero mean value will be mapped to 1, giving the impression that there is something going on. I recently abandoned standard_scale and switched to zscore and RdBu_r colormap both in heat maps and dotplots with vmin=-3 and vmax=3, which leads to a better standardization. The only caveat of this normalization in dotplot is that the dot size is determined by the number of cells above the average, which was possibly higher than zero before zscore, compared to the regular zero cutoff. In this sense it makes it more stringent than zero expression cutoff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1451:386,interoperability,standard,standardization,386,"Exactly. But I do agree that it can be misleading in some cases e.g if there is one cell with a single UMI out of 1000 cells, this nonzero mean value will be mapped to 1, giving the impression that there is something going on. I recently abandoned standard_scale and switched to zscore and RdBu_r colormap both in heat maps and dotplots with vmin=-3 and vmax=3, which leads to a better standardization. The only caveat of this normalization in dotplot is that the dot size is determined by the number of cells above the average, which was possibly higher than zero before zscore, compared to the regular zero cutoff. In this sense it makes it more stringent than zero expression cutoff.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1451
https://github.com/scverse/scanpy/issues/1452:380,availability,error,error,380,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:386,integrability,messag,message,386,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:371,interoperability,share,share,371,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:386,interoperability,messag,message,386,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:380,performance,error,error,380,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:380,safety,error,error,380,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:110,usability,minim,minimal,110,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:380,usability,error,error,380,"Hi @saiteja-danda,. I cannot reproduce your code above as I don't have your data. Could you try to generate a minimal reproducible example with data from e.g., `sc.datasets.pbmc68k_reduced()`? In general, could you check the output of `adata.obs['km'].value_counts()` to check whether the covariate you added was correctly stored? What output are you getting? You didn't share an error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:52,usability,close,close,52,"As we haven't heard back after the followup we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1452:113,usability,behavi,behaviour,113,"As we haven't heard back after the followup we will close the issue for now, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1452
https://github.com/scverse/scanpy/issues/1454:466,modifiability,layer,layer,466,"I think that's a good idea. A general solution would be to move the part of rank_genes_groups where some statistics are calculated (e.g. log2fc, fractions, mean expression per group) to a different function with more flexible features. For example, users run regress_out or combat sometimes and then run rank_genes_groups on these corrected values, but they wanna calculate log2fc and other summary stats on the ""raw"" logTP10k values. Having another function with a layer argument would solve this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:249,usability,user,users,249,"I think that's a good idea. A general solution would be to move the part of rank_genes_groups where some statistics are calculated (e.g. log2fc, fractions, mean expression per group) to a different function with more flexible features. For example, users run regress_out or combat sometimes and then run rank_genes_groups on these corrected values, but they wanna calculate log2fc and other summary stats on the ""raw"" logTP10k values. Having another function with a layer argument would solve this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:191,deployability,automat,automatically,191,"One idea: `sc.get.group_summary_stats()` can be called separately and its results are stored in a way that `sc.get.rank_genes_groups_df` can find and return them. This function can be called automatically in `sc.tl.rank_genes_groups` in a similar way we automatically run `sc.pp.pca` when `sc.pp.neighbors` is called or we run `sc.tl.dendrogram` when `sc.pl.dotplot(..., dendrogram=True)` is called.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:254,deployability,automat,automatically,254,"One idea: `sc.get.group_summary_stats()` can be called separately and its results are stored in a way that `sc.get.rank_genes_groups_df` can find and return them. This function can be called automatically in `sc.tl.rank_genes_groups` in a similar way we automatically run `sc.pp.pca` when `sc.pp.neighbors` is called or we run `sc.tl.dendrogram` when `sc.pl.dotplot(..., dendrogram=True)` is called.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:191,testability,automat,automatically,191,"One idea: `sc.get.group_summary_stats()` can be called separately and its results are stored in a way that `sc.get.rank_genes_groups_df` can find and return them. This function can be called automatically in `sc.tl.rank_genes_groups` in a similar way we automatically run `sc.pp.pca` when `sc.pp.neighbors` is called or we run `sc.tl.dendrogram` when `sc.pl.dotplot(..., dendrogram=True)` is called.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:254,testability,automat,automatically,254,"One idea: `sc.get.group_summary_stats()` can be called separately and its results are stored in a way that `sc.get.rank_genes_groups_df` can find and return them. This function can be called automatically in `sc.tl.rank_genes_groups` in a similar way we automatically run `sc.pp.pca` when `sc.pp.neighbors` is called or we run `sc.tl.dendrogram` when `sc.pl.dotplot(..., dendrogram=True)` is called.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1454:182,usability,tool,tools,182,I like this idea. Even now this summary stats calculation is in the separate private [method](https://github.com/theislab/scanpy/blob/64e3ab864d21b0be8e9bbdf50bd496d34c56f239/scanpy/tools/_rank_genes_groups.py#L137). It should not be problematic to move it to a separate function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1454
https://github.com/scverse/scanpy/issues/1455:281,modifiability,paramet,parameter,281,Can you elaborate? What do you mean with the output? . In the past we only computed up to 100 genes by default but now we do it for all. You can always limit the number of genes you want to see afterwards. So maybe we should remove the `n_genes` from the function or deprecate the parameter.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:55,availability,cluster,cluster,55,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:55,deployability,cluster,cluster,55,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:123,deployability,log,logfoldchanges,123,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:549,deployability,log,logfoldchanges,549,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:204,energy efficiency,optim,optimal,204,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:337,interoperability,share,sharey,337,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:123,safety,log,logfoldchanges,123,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:549,safety,log,logfoldchanges,549,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:123,security,log,logfoldchanges,123,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:549,security,log,logfoldchanges,549,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:123,testability,log,logfoldchanges,123,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:549,testability,log,logfoldchanges,549,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:747,usability,help,help,747,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:764,usability,efficien,efficient,764,"How can one get a DEG table with a pts column for each cluster? So that for each group there would be 4 columns: 'names', 'logfoldchanges', 'pvals_adj' and 'pts'? Manual sorting from 2 files is not quite optimal:. ```. sc.tl.rank_genes_groups(adata, 'cell_types', method='wilcoxon', pts=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. degs_by_cluster = pd.DataFrame({group + '_' + key[:14]: result[key][group]. for group in groups for key in ['names', 'logfoldchanges', 'pvals_adj']}). degs_by_cluster.to_csv(""DEG_adata_cell_types_pct_to_sort.csv""). pts=pd.DataFrame(adata.uns['rank_genes_groups']['pts']). pts.to_csv(""pts_adata.csv""). ```. Could you help with a more efficient way to do that? . @fidelram @ivirshup",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:74,deployability,log,log,74,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:520,deployability,log,logfoldchanges,520,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,deployability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,integrability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:620,integrability,sub,subset,620,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,interoperability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,modifiability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,reliability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:74,safety,log,log,74,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:232,safety,test,test,232,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:520,safety,log,logfoldchanges,520,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:74,security,log,log,74,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:520,security,log,logfoldchanges,520,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,security,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:74,testability,log,log,74,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:232,testability,test,test,232,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:520,testability,log,logfoldchanges,520,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:600,testability,integr,integration,600,"Hello . I am also facing the same problem. I would like to get gene name, log fold change, pval_adj, pts.pts_rest in a single output CSV file but i couldn't able to do that. ` . sc.tl.rank_genes_groups(adata,""leiden_0.6"", method='t-test',pts=True,corr_method='benjamini-hochberg'). pd.DataFrame(adata.uns['rank_genes_groups']['names']). result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df= pd.DataFrame(. {group + '_' + key[:1]: result[key][group]. for group in groups for key in ['names','logfoldchanges','pts','pts_rest','pvals','pvals_adj']}). df.to_csv(""/home/Akila/integration/harmony/subset/celltype/find_markergenes.csv"")`. . Any idea how to get in the single file along with pts?? . Thanks. Akila .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:253,deployability,log,logfoldchanges,253,"Try the following code:. # Differential expression and marker genes. result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df1 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['names','scores','logfoldchanges','pvals','pvals_adj']}). df2 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['pts','pts_rest']}). pd.concat([df1[[group+'_names',group+'_scores',group+'_logfoldchanges',group+'_pvals',group+'_pvals_adj']].merge(df2[[group+""_pts"",group+""_pts_rest""]],how=""left"",left_on=group+""_names"",right_index=True) for group in groups],axis=1).to_csv(""markers.csv"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:253,safety,log,logfoldchanges,253,"Try the following code:. # Differential expression and marker genes. result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df1 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['names','scores','logfoldchanges','pvals','pvals_adj']}). df2 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['pts','pts_rest']}). pd.concat([df1[[group+'_names',group+'_scores',group+'_logfoldchanges',group+'_pvals',group+'_pvals_adj']].merge(df2[[group+""_pts"",group+""_pts_rest""]],how=""left"",left_on=group+""_names"",right_index=True) for group in groups],axis=1).to_csv(""markers.csv"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:253,security,log,logfoldchanges,253,"Try the following code:. # Differential expression and marker genes. result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df1 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['names','scores','logfoldchanges','pvals','pvals_adj']}). df2 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['pts','pts_rest']}). pd.concat([df1[[group+'_names',group+'_scores',group+'_logfoldchanges',group+'_pvals',group+'_pvals_adj']].merge(df2[[group+""_pts"",group+""_pts_rest""]],how=""left"",left_on=group+""_names"",right_index=True) for group in groups],axis=1).to_csv(""markers.csv"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/issues/1455:253,testability,log,logfoldchanges,253,"Try the following code:. # Differential expression and marker genes. result = adata.uns['rank_genes_groups']. groups = result['names'].dtype.names. df1 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['names','scores','logfoldchanges','pvals','pvals_adj']}). df2 = pd.DataFrame({group+'_' + key:result[key][group] for group in groups for key in ['pts','pts_rest']}). pd.concat([df1[[group+'_names',group+'_scores',group+'_logfoldchanges',group+'_pvals',group+'_pvals_adj']].merge(df2[[group+""_pts"",group+""_pts_rest""]],how=""left"",left_on=group+""_names"",right_index=True) for group in groups],axis=1).to_csv(""markers.csv"")",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1455
https://github.com/scverse/scanpy/pull/1456:149,interoperability,distribut,distribution,149,You think this has to do with precision of the dispersion value? Couldn't it be that you just have exactly the same value as you have the same count distribution for 2 genes?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:60,performance,time,times,60,It's due to precision - and has also been reported multiple times for scvelo.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:298,interoperability,distribut,distributions,298,"For instance, scvelo's pancreas example:. ```. adata = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata, min_shared_counts=30). sc.pp.highly_variable_genes(bdata, n_top_genes=2000). adata.obs['highly_variable'].value_counts(). ```. returns 1999. Having two genes with the very same count distributions exactly at the n_top_genes threshold, is theoretically possible, but practically as likely as lotterie jackpot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:381,reliability,pra,practically,381,"For instance, scvelo's pancreas example:. ```. adata = scv.datasets.pancreas(). scv.pp.filter_and_normalize(adata, min_shared_counts=30). sc.pp.highly_variable_genes(bdata, n_top_genes=2000). adata.obs['highly_variable'].value_counts(). ```. returns 1999. Having two genes with the very same count distributions exactly at the n_top_genes threshold, is theoretically possible, but practically as likely as lotterie jackpot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:23,performance,time,times,23,"I've seen this several times as well, but I'm surprised that float32 isn't already sufficient for keeping dispersion values apart... as you should get at least 5 decimal places of precision. I would have thought that's already sufficient to make this very unlikely.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:101,interoperability,convers,conversion,101,"Simply leaving this out, solves it and guarantees exactness. Imho, there's no reason to do this type conversion. It's, the threshold value, thus just a single value that gets converted to float32, which won't yield any considerable speedup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:0,testability,Simpl,Simply,0,"Simply leaving this out, solves it and guarantees exactness. Imho, there's no reason to do this type conversion. It's, the threshold value, thus just a single value that gets converted to float32, which won't yield any considerable speedup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/pull/1456:0,usability,Simpl,Simply,0,"Simply leaving this out, solves it and guarantees exactness. Imho, there's no reason to do this type conversion. It's, the threshold value, thus just a single value that gets converted to float32, which won't yield any considerable speedup.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1456
https://github.com/scverse/scanpy/issues/1457:274,availability,sli,slightly,274,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:283,availability,slo,slower,283,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:398,deployability,log,logg,398,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:274,reliability,sli,slightly,274,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:283,reliability,slo,slower,283,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:398,safety,log,logg,398,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:398,security,log,logg,398,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:398,testability,log,logg,398,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1457:833,testability,simul,simulation,833,"in the source file(highly_variable_genes.py). ```. dispersion_norm = df['dispersion_norm'].values.astype('float32'). if n_top_genes is not None:. dispersion_norm = dispersion_norm[~np.isnan(dispersion_norm)]. dispersion_norm[::-1].sort() # interestingly, np.argpartition is slightly slower. disp_cut_off = dispersion_norm[n_top_genes-1]. gene_subset = df['dispersion_norm'].values >= disp_cut_off. logg.debug(. f'the {n_top_genes} top genes correspond to a '. f'normalized dispersion cutoff of {disp_cut_off}'. ). ``` . the ` df['dispersion_norm']` is the type of `np.float64`,but the `dispersion_norm` is `np.float32`,so the `disp_cut_off` is `np.float32`,but in line . `gene_subset = df['dispersion_norm'].values >= disp_cut_off` , . It means the array of `float64` will compare with `float32`, it is not accurate sometimes. in my simulation code, the dubug result is follows. ```. disp_cut_off. 0.5938217. type(disp_cut_off). <class 'numpy.float32'>. df['dispersion_norm'][44]. 0.593821696856851. type(df['dispersion_norm'][44]). <class 'numpy.float64'>. df['dispersion_norm'][44]>=disp_cut_off. False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1457
https://github.com/scverse/scanpy/issues/1458:14,testability,understand,understand,14,"I don't quite understand what you want to do, but an easy solution is to invert the the ylim or xlim of the plot. For example:. ```PYTHON. aa = sc.datasets.pbmc68k_reduced(). rcParams['figure.figsize'] = 4,1. sc.tl.dendrogram(aa, groupby = 'bulk_labels'). ax = sc.pl.dendrogram(aa, groupby = [""bulk_labels""], show=False). xmin, xmax = ax.get_xlim(). ax.set_xlim(xmax, xmin). ```. <img width=""493"" alt=""image"" src=""https://user-images.githubusercontent.com/4964309/106350619-c904f200-62d6-11eb-912d-5744fc01c537.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1458
https://github.com/scverse/scanpy/issues/1458:422,usability,user,user-images,422,"I don't quite understand what you want to do, but an easy solution is to invert the the ylim or xlim of the plot. For example:. ```PYTHON. aa = sc.datasets.pbmc68k_reduced(). rcParams['figure.figsize'] = 4,1. sc.tl.dendrogram(aa, groupby = 'bulk_labels'). ax = sc.pl.dendrogram(aa, groupby = [""bulk_labels""], show=False). xmin, xmax = ax.get_xlim(). ax.set_xlim(xmax, xmin). ```. <img width=""493"" alt=""image"" src=""https://user-images.githubusercontent.com/4964309/106350619-c904f200-62d6-11eb-912d-5744fc01c537.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1458
https://github.com/scverse/scanpy/issues/1459:46,deployability,version,versions,46,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:93,deployability,stack,stackoverflow,93,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:156,deployability,modul,module-matplotlib-cbook-has-no-attribute-define-a,156,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:46,integrability,version,versions,46,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:20,interoperability,conflict,conflicts,20,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:46,modifiability,version,versions,46,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:156,modifiability,modul,module-matplotlib-cbook-has-no-attribute-define-a,156,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:156,safety,modul,module-matplotlib-cbook-has-no-attribute-define-a,156,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:363,usability,user,user-images,363,"Hi,. you might have conflicts with matplotlib versions, googling raised this [issue](https://stackoverflow.com/questions/53421905/matplotlib-attributeerror-module-matplotlib-cbook-has-no-attribute-define-a). I could reproduce the result. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata, edges=True). ```. ![image](https://user-images.githubusercontent.com/25887487/96875694-cee96c80-1477-11eb-883f-bb1feb0d5f0e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1459:13,usability,close,close,13,"@emdann will close this for now, feel free to reopen if problem persist!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1459
https://github.com/scverse/scanpy/issues/1460:298,availability,error,error,298,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:567,energy efficiency,current,current,567,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:556,integrability,sub,subset,556,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:45,interoperability,coordinat,coordinates,45,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:96,interoperability,specif,specifically,96,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:122,interoperability,coordinat,coordinates,122,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:167,interoperability,coordinat,coordinates,167,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:467,interoperability,coordinat,coordinates,467,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:298,performance,error,error,298,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:246,reliability,doe,does,246,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:283,reliability,doe,does,283,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:298,safety,error,error,298,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:298,usability,error,error,298,"Hi @SNRNS, . `sc.pl.umap` looks for the UMAP coordinates that should be stored in `adata.obsm`, specifically it looks for coordinates in `adata.obsm['X_umap']`. These coordinates are computed and stored by `sc.tl.umap`. If `adata.obsm['X_umap']` does not exist the plotting function does return an error which I think is pretty self-explanatory:. `KeyError: ""Could not find entry in 'obsm' for 'umap'.\nAvailable keys are: ['X_pca'].""`. It must be that you have some coordinates already stored in `adata.obsm['X_umap']`, this could happen because you have subset the current adata from a bigger one, for which you had computed the UMAP, or maybe you got the data already preprocessed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1460:14,usability,close,close,14,@SNRNS I will close this issue for now. Feel free to open again or make further inquiries if you still have doubts.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1460
https://github.com/scverse/scanpy/issues/1461:175,integrability,filter,filtered,175,"Please check your `adata.raw`. The default for `sc.tl.rank_genes_groups` is `use_raw=True`, which means it uses the data stored in `adata.raw` this may include genes that you filtered out in `adata.X`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1461
https://github.com/scverse/scanpy/pull/1464:44,deployability,releas,release,44,@LuckyMD Could you also add this fix to the release notes? https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1464
https://github.com/scverse/scanpy/pull/1464:111,deployability,releas,release-latest,111,@LuckyMD Could you also add this fix to the release notes? https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1464
https://github.com/scverse/scanpy/pull/1466:650,usability,user,user-images,650,"the code provided by @SabrinaRichter now works:. ```python. X = np.array([[1], [2], [3]]). pos = np.array([[1, 0], [0, 2], [0, 0]]). conn = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]]). adata_temp = anndata.AnnData(X=X). adata_temp.obsm[""spatial""] = pos. adata_temp.obsp[""spatial_connectivity""] = conn. key_added = ""spatial"". conns_key = ""spatial_connectivity"". adata_temp.uns[key_added] = {}. neighbors_dict = adata_temp.uns[key_added]. neighbors_dict[""connectivities_key""] = conns_key. neighbors_dict[""distances_key""] = ""dummy"". sc.pl.embedding(adata_temp, basis=""spatial"", edges=True, neighbors_key=""spatial"", edges_width=4). ```. ![image](https://user-images.githubusercontent.com/25887487/96875540-9c3f7400-1477-11eb-82c4-1dee4efe2fd3.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1466
https://github.com/scverse/scanpy/issues/1467:308,availability,error,error,308,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:98,interoperability,format,format,98,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:308,performance,error,error,308,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:308,safety,error,error,308,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1467:308,usability,error,error,308,Please check this issue: #456 . Your data in `adata.raw` are probably `np.matrix`. You can either format to `np.ndarray` or to `scipy.sparse.csr_matrix()` to solve this. Note you are using `adata.raw.X` and not `adata.X` in `rank_genes_groups()` by default. So your proposed line of code will not solve your error. Please instead use for example:. `adata.raw.X = scipy.sparse.csr_matrix(adata.raw.X)`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1467
https://github.com/scverse/scanpy/issues/1468:33,deployability,instal,install,33,"Hi, if you use conda, try `conda install pytables`. If you don't, try installing from the corresponding wheel here https://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:70,deployability,instal,installing,70,"Hi, if you use conda, try `conda install pytables`. If you don't, try installing from the corresponding wheel here https://www.lfd.uci.edu/~gohlke/pythonlibs/#pytables",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:134,deployability,instal,installing,134,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:620,deployability,modul,module,620,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:731,deployability,modul,module,731,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:793,deployability,fail,failed,793,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:788,energy efficiency,load,load,788,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:805,interoperability,specif,specified,805,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:84,modifiability,pac,package,84,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:171,modifiability,pac,packages,171,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:369,modifiability,pac,packaged,369,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:620,modifiability,modul,module,620,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:688,modifiability,pac,packages,688,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:731,modifiability,modul,module,731,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:189,performance,time,times,189,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:788,performance,load,load,788,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:793,reliability,fail,failed,793,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:620,safety,modul,module,620,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:731,safety,modul,module,731,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:556,testability,Trace,Traceback,556,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:233,usability,User,Users,233,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:269,usability,User,Users,269,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:472,usability,help,help,472,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:638,usability,User,Users,638,"@Koncopd Hi, Thank you for the pointer. It seems to be a problem caused by pytables package. But I still couldn't import tables after installing and uninstalling pytables packages for many times. And I'm in Windows system. (base) C:\Users\yuhong>python. ```. (base) C:\Users\yuhong>conda list | grep pytables. pytables 3.6.1 py37h14417ae_3 conda-forge . Python 3.7.8 | packaged by conda-forge | (default, Jul 31 2020, 01:53:57) [MSC v.1916 64 bit (AMD64)] on win32. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tables. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:54,deployability,instal,installing,54,You can also try creating a new conda environment and installing pytables there at first and try to import it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:103,deployability,instal,install,103,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:164,deployability,instal,installation,164,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:224,deployability,instal,installation,224,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:256,deployability,instal,installing,256,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:280,deployability,instal,install,280,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:353,deployability,version,versions,353,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:380,deployability,version,version,380,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:353,integrability,version,versions,353,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:380,integrability,version,version,380,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:429,integrability,messag,message,429,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:326,interoperability,conflict,conflicts,326,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:420,interoperability,conflict,conflict,420,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:429,interoperability,messag,message,429,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:353,modifiability,version,versions,353,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:380,modifiability,version,version,380,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:409,safety,except,except,409,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:177,usability,guid,guide,177,"`pytables` in pip is named `tables`, and scanpy `import tables` accordingly, so you have to separately install it using also pip, not conda. I suggest editing the [installation guide](https://scanpy.readthedocs.io/en/stable/installation.html). Besides, my installing using `conda install -c bioconda scanpy` would always give conflicts with nvidia cuda versions, but changing the version makes nothing change except the conflict message. Is it a Windows feature?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:68,deployability,build,building,68,"I suspect it might be the same issue as in #454 , so a problem with building libraries for h5py (which pytables needs) since Windows misses a C++ compiler for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1469:312,availability,cluster,clustering,312,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:312,deployability,cluster,clustering,312,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:522,deployability,compos,compositional,522,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:566,deployability,log,log,566,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:758,deployability,compos,compositional,758,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:27,integrability,transform,transform,27,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:133,integrability,topic,topic,133,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:462,integrability,compon,components,462,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:582,integrability,transform,transformation,582,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:27,interoperability,transform,transform,27,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:110,interoperability,format,formative,110,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:462,interoperability,compon,components,462,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:582,interoperability,transform,transformation,582,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:462,modifiability,compon,components,462,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:522,modifiability,compos,compositional,522,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:758,modifiability,compos,compositional,758,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:566,safety,log,log,566,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:566,security,log,log,566,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:566,testability,log,log,566,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:611,usability,user,user-images,611,"It's equivalent to the CLR transform. However, I'm not sure if this is the right way to go. CLR was used in a formative paper on the topic (doi:10.1038/nmeth.4380), and it's been brought forward from there. Here's that explanation for it's use:. <img width=""559"" alt=""CBMC antibody-derived tag normalization and clustering. Since each ADT count for a given cell can be interpreted as part of a whole (all ADT counts assigned to that cell), and there are only 13 components in this experiment, we treated this data type as compositional data and applied the centered log ratio (CLR) transformation"" src=""https://user-images.githubusercontent.com/8238804/98912624-75c2a500-251a-11eb-92e0-6d1d9004e3e2.png"">. I'm not convinced the UMIs from antibodies are more compositional than UMIs from mRNA, especially considering they are captured and amplified together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:436,deployability,log,log,436,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:440,integrability,transform,transformation,440,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:440,interoperability,transform,transformation,440,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:481,modifiability,scal,scaling,481,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:436,safety,log,log,436,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:436,security,log,log,436,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:394,testability,simpl,simplest,394,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:429,testability,simpl,simple,429,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:436,testability,log,log,436,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:394,usability,simpl,simplest,394,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:429,usability,simpl,simple,429,"I'm also a bit confused about how the CLR is applied. In the CITE-seq paper, I think it was done within a cell (over proteins), then I think they had switched to within a protein (over cells), and now in Seurat v4 it appears to be back to within a cell. Any per cell normalization is a bit tricky because the panels will differ between datasets as well as the titration of antibodies used. The simplest thing to me seems to be a simple log transformation combined with per protein scaling, as values between proteins are not comparable to begin with. We have some additional thoughts in the appendix of our totalVI paper.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/pull/1470:193,deployability,fail,failing,193,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:273,deployability,fail,failing,273,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:295,deployability,instal,install,295,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:331,deployability,instal,installed,331,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:57,energy efficiency,core,core,57,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:17,integrability,sub,submitting,17,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:193,reliability,fail,failing,193,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:273,reliability,fail,failing,273,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:48,safety,review,reviewer,48,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:201,safety,test,tests,201,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:263,safety,test,tests,263,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:48,testability,review,reviewer,48,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:201,testability,test,tests,201,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:263,testability,test,tests,263,"Thanks a lot for submitting a PR!!! Will add as reviewer core dev @fidelram to see what he thinks. It's a bit an ad-hoc since it's an additional argument just for this function. Meanwhile, for failing tests, can you reformat with black? That seems the reason why tests are failing. ```bash. pip install black #if you don't have it installed. black scanpy/plotting/_tools/scatterplots.py. ```. or you can do the same from within whatever IDE you work with. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:64,modifiability,paramet,parameters,64,"Thanks for the PR. . I am not a big fan of adding more and more parameters to generic functions like `embedding`. Rather, would be better if this code is handled in the `pca` function itself. . In other words, could be possible to add the code to annotate the axis labels in the `pca` function and not in the `embedding` function? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:285,availability,avail,available,285,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:260,interoperability,specif,specific,260,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:199,modifiability,paramet,parameter,199,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:285,reliability,availab,available,285,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:285,safety,avail,available,285,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:285,security,availab,available,285,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:116,usability,user,user,116,"Two ideas: . 1. pass to `embedding` `show=False, save=False` and then call `save_fig_or_show` within `pca` with the user values for `show` and `save`. 2. allow `embedding` to rename any axis using a parameter like `component_labels`. Thus, this feature is not specific to PCA but also available to any other embedding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/issues/1471:119,deployability,automat,automatically,119,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:86,integrability,messag,message,86,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:86,interoperability,messag,message,86,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:25,performance,time,time,25,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:119,testability,automat,automatically,119,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:0,usability,close,closed,0,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:150,usability,close,closed,150,"closed with #1472 , next time @danielStrobl you could just do `git commit -m ""<commit-message> #1471""` and it would be automatically linked (and then closed if PR is merged)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/pull/1472:46,deployability,releas,release,46,I'm guessing this should also be added to the release notes @Koncopd?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:34,availability,error,error,34,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```. >>> import scanpy as sc. >>> adata_ref = sc.datasets.pbmc3k_processed(). pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]. Traceback (most recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3520,availability,error,error,3520,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3545,availability,error,error,3545,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1557,deployability,fail,failed,1557,"/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_do",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1752,deployability,modul,module,1752,"ndheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3603,deployability,fail,failed,3603,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1863,integrability,wrap,wrapper,1863,"/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1863,interoperability,wrapper,wrapper,1863,"/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1752,modifiability,modul,module,1752,"ndheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1814,modifiability,pac,packages,1814,"e_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/pyth",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1952,modifiability,pac,packages,1952,"envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/ur",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2183,modifiability,pac,packages,2183,"-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/re",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2297,modifiability,pac,packages,2297,"thon3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2486,modifiability,pac,packages,2486,"ficationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2650,modifiability,pac,packages,2650,"ion, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ss",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:34,performance,error,error,34,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```. >>> import scanpy as sc. >>> adata_ref = sc.datasets.pbmc3k_processed(). pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]. Traceback (most recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2896,performance,time,timeout,2896,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3520,performance,error,error,3520,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3545,performance,error,error,3545,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1557,reliability,fail,failed,1557,"/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_do",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3603,reliability,fail,failed,3603,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:34,safety,error,error,34,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```. >>> import scanpy as sc. >>> adata_ref = sc.datasets.pbmc3k_processed(). pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]. Traceback (most recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1648,safety,except,exception,1648,"nked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-pac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1667,safety,except,exception,1667,"). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1752,safety,modul,module,1752,"ndheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2896,safety,timeout,timeout,2896,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3520,safety,error,error,3520,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3545,safety,error,error,3545,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1209,security,ssl,ssl,1209,"recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1244,security,session,session,1244,"envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1252,security,session,session,1252,"B-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaco",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1309,security,ssl,ssl,1309,"n do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1409,security,ssl,ssl,1409,"b/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, bac",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1475,security,ssl,ssl,1475,"uest(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1479,security,SSL,SSLCertVerificationError,1479,"rl, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1506,security,SSL,SSL,1506,", encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1538,security,certif,certificate,1538,"envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafil",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1592,security,certif,certificate,1592,"275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3552,security,SSL,SSL,3552,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3584,security,certif,certificate,3584,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3638,security,certif,certificate,3638,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:195,testability,Trace,Traceback,195,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```. >>> import scanpy as sc. >>> adata_ref = sc.datasets.pbmc3k_processed(). pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]. Traceback (most recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1550,testability,verif,verify,1550,"-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:1688,testability,Trace,Traceback,1688,"nvs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3340,testability,context,context,3340,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3596,testability,verif,verify,3596,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:34,usability,error,error,34,"Even I changed it manually, still error with CERTIFICATE_VERIFY_FAILED:. ```. >>> import scanpy as sc. >>> adata_ref = sc.datasets.pbmc3k_processed(). pbmc3k_processed.h5ad: 0.00B [00:00, ?B/s]. Traceback (most recent call last):. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1317, in do_open. encode_chunked=req.has_header('Transfer-encoding')). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1229, in request. self._send_request(method, url, body, headers, encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1275, in _send_request. self.endheaders(body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1224, in endheaders. self._send_output(message_body, encode_chunked=encode_chunked). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1016, in _send_output. self.send(msg). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 956, in send. self.connect(). File ""/anaconda3/envs/scIB-python/lib/python3.7/http/client.py"", line 1392, in connect. server_hostname=server_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 412, in wrap_socket. session=session. File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 853, in _create. self.do_handshake(). File ""/anaconda3/envs/scIB-python/lib/python3.7/ssl.py"", line 1117, in do_handshake. self._sslobj.do_handshake(). ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2736,usability,User,User-agent,2736,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:2757,usability,user,user,2757,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3520,usability,error,error,3520,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:3545,usability,error,error,3545,"ception occurred:. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_utils.py"", line 10, in wrapper. return f(*args, **kwargs). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/datasets/_datasets.py"", line 305, in pbmc3k_processed. backup_url='https://raw.githubusercontent.com/chanzuckerberg/cellxgene/main/example-dataset/pbmc3k.h5ad',. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 122, in read. **kwargs,. File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 694, in _read. is_present = _check_datafile_present_and_download(filename, backup_url=backup_url,). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 970, in _check_datafile_present_and_download. _download(backup_url, path). File ""/anaconda3/envs/scIB-python/lib/python3.7/site-packages/scanpy/readwrite.py"", line 936, in _download. urlopen(Request(url, headers={""User-agent"": ""scanpy-user""})) as resp:. File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 222, in urlopen. return opener.open(url, data, timeout). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 525, in open. response = self._open(req, data). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 543, in _open. '_open', req). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 503, in _call_chain. result = func(*args). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1360, in https_open. context=self._context, check_hostname=self._check_hostname). File ""/anaconda3/envs/scIB-python/lib/python3.7/urllib/request.py"", line 1319, in do_open. raise URLError(err). urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1056)>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1474:0,availability,Ping,Ping,0,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:226,energy efficiency,estimat,estimator,226,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:275,safety,review,review,275,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:275,testability,review,review,275,Ping. This is a needed in the https://github.com/clara-parabricks/rapids-single-cell-examples so that we can make our notebooks reproducible. It's a trivial addition to propagate the `random_state` argument to the RAPIDS UMAP estimator. Any chance this can be considered for review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1476:77,availability,error,error,77,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:102,availability,down,down,102,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:51,deployability,fail,fails,51,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:77,performance,error,error,77,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:51,reliability,fail,fails,51,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:77,safety,error,error,77,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:77,usability,error,error,77,@Koncopd @ivirshup can you have a look at this? CI fails for some weird docs error that we can't nail down.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:76,safety,review,review,76,Thanks for all the good feedback @ivirshup - I'll work on it and re-request review when I'm done.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:76,testability,review,review,76,Thanks for all the good feedback @ivirshup - I'll work on it and re-request review when I'm done.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:24,usability,feedback,feedback,24,Thanks for all the good feedback @ivirshup - I'll work on it and re-request review when I'm done.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:304,availability,avail,available,304,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:187,deployability,log,logic,187,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:304,reliability,availab,available,304,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:187,safety,log,logic,187,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:304,safety,avail,available,304,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:461,safety,test,tests,461,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:88,security,expos,exposed,88,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:187,security,log,logic,187,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:243,security,expos,exposed,243,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:304,security,availab,available,304,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:187,testability,log,logic,187,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:461,testability,test,tests,461,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:327,usability,user,users,327,"Okay @ivirshup , think I've addressed your comments:. - old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). New sce.pp.scrublet now the main exposed function, with scrublet_simulate_doublets() function available for advanced users. - plot function moved to scanpy/external/pl.py as scrublet_score_distribution(). - functions linked via 'See also' sections. - tests added for 'scrublet()' and scrublet_simlulate_doublets().",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:18,safety,test,tests,18,"I checked the new tests locally, can't work out why they're not running in the CI here- hopefully it's obvious to you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:18,testability,test,tests,18,"I checked the new tests locally, can't work out why they're not running in the CI here- hopefully it's obvious to you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1023,availability,down,down,1023,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:133,deployability,log,logic,133,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1056,deployability,modul,modular,1056,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1056,integrability,modular,modular,1056,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1056,modifiability,modul,modular,1056,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:133,safety,log,logic,133,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1056,safety,modul,modular,1056,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:34,security,expos,exposed,34,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:133,security,log,logic,133,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:133,testability,log,logic,133,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:261,testability,Simul,Simulate,261,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:312,testability,simul,simulated,312,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:396,testability,simul,simulated,396,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:560,testability,simul,simulates,560,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:740,testability,simpl,simple,740,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1056,testability,modula,modular,1056,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:177,usability,clear,clear,177,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:509,usability,workflow,workflow,509,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:715,usability,workflow,workflow,715,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:740,usability,simpl,simple,740,"> old 'scrublet' function now not exposed, has become an internal _scrublet_call_doublets (I like it still being separate, makes the logic easier to read). Oh, I think I wasn't clear here. I was thinking that there would be three doublet calling functions:. 1. Simulate doublets. Receives count anndata, returns simulated doublet count anndata. 2. Given two anndata objects, one source data, one simulated, call doublets in the source data. It's assumed both objects have already been normalized. 3. The full workflow. Takes an AnnData object with count data, simulates doublets, runs normalization on both, and then calls doublets on the source object. Uses the previous two functions as well as the normalization workflow internally. The simple use case is just to call function 3. The advanced use case is to use function 2, potentially with data from function 1, or generated some other way. The advanced use case also allows you to use your own normalization. By not giving function 2 the ability to normalize, we cut down on arguments, and have more modular functions. What do you think of that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:87,deployability,log,logic,87,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:50,energy efficiency,current,current,50,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:87,safety,log,logic,87,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:87,security,log,logic,87,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:87,testability,log,logic,87,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:40,usability,prefer,prefer,40,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:142,usability,user,user,142,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:161,usability,prefer,prefer,161,"> What do you think of that? I actually prefer my current layout- it accomplishes your logic without duplication of arguments etc, and from a user perspective I prefer having one main function I can use in the two ways (one anndata you get 3., Two anndata you get 2). But I'm also very happy for you to tweak things to match your vision!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:75,deployability,instal,installed,75,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:104,deployability,build,build,104,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:177,deployability,log,logs,177,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:198,deployability,instal,install,198,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:296,deployability,build,build,296,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:323,deployability,Instal,Installing,323,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:334,deployability,build,build,334,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,deployability,depend,dependencies,340,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:391,deployability,build,build,391,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,integrability,depend,dependencies,340,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,modifiability,depend,dependencies,340,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:491,reliability,doe,does,491,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:18,safety,test,tests,18,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:177,safety,log,logs,177,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:212,safety,test,test,212,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,safety,depend,dependencies,340,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:177,security,log,logs,177,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:18,testability,test,tests,18,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:177,testability,log,logs,177,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:212,testability,test,test,212,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,testability,depend,dependencies,340,"@pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. ```. 203$ pip install .[dev,test,louvain,leiden,magic,scvi,harmony,skmisc,scrublet]. 204Processing /home/travis/build/theislab/scanpy. 205 Installing build dependencies ... done. 206 Getting requirements to build wheel ... done. 207 Preparing wheel metadata ... done. 208 WARNING: scanpy 0.1.dev67+g3918588 does not provide the extra 'scrublet'. ```. You'll need to add a scrublet entry to `extras_require` here: https://github.com/theislab/scanpy/blob/d56d6beacdd951a010bb6a93078db26e1ac904b0/setup.py#L31-L56",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:40,performance,time,times,40,Also sorry about these horrible CI wait times! Hopefully these will be better sometime next week.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:77,deployability,instal,installed,77,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:106,deployability,build,build,106,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:179,deployability,log,logs,179,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:20,safety,test,tests,20,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:179,safety,log,logs,179,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:179,security,log,logs,179,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:20,testability,test,tests,20,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:179,testability,log,logs,179,"> @pinin4fjords the tests aren't running since scrublet isn't actually being installed (I'm surprised the build still worked, apparently this is just a warning?). From the travis logs:. > You'll need to add a scrublet entry to `extras_require` here:. Ahh, I see- thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:42,performance,time,times,42,> Also sorry about these horrible CI wait times! Hopefully these will be better sometime next week. Maybe you're having issues with the new Travis credits system? We've certainly had issues- we're gradually migrating to GitHub actions now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:45,interoperability,format,formatting,45,Tests passing! With exception of silly Black formatting issue I've just corrected.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:0,safety,Test,Tests,0,Tests passing! With exception of silly Black formatting issue I've just corrected.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:20,safety,except,exception,20,Tests passing! With exception of silly Black formatting issue I've just corrected.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:0,testability,Test,Tests,0,Tests passing! With exception of silly Black formatting issue I've just corrected.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:22,integrability,coupl,couple,22,"@pinin4fjords, just a couple minor changes requested. I'd add them myself, but it looks like I don't have permissions to push to this branch on your repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:22,modifiability,coupl,couple,22,"@pinin4fjords, just a couple minor changes requested. I'd add them myself, but it looks like I don't have permissions to push to this branch on your repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:106,safety,permiss,permissions,106,"@pinin4fjords, just a couple minor changes requested. I'd add them myself, but it looks like I don't have permissions to push to this branch on your repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:22,testability,coupl,couple,22,"@pinin4fjords, just a couple minor changes requested. I'd add them myself, but it looks like I don't have permissions to push to this branch on your repo.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/issues/1477:195,safety,except,except,195,"[This](https://github.com/theislab/scvelo/blob/5aefd1e2d1157d92578698e5897b517e1a117cdb/scvelo/settings.py#L329) works, i.e. . ```. def _is_run_from_ipython(): . try:. __IPYTHON__. rreturn True. except NameError:. return False. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:127,deployability,version,versions,127,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:174,deployability,version,versions,174,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:445,deployability,log,logical,445,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:497,deployability,updat,updated,497,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:453,energy efficiency,CPU,CPU,453,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:457,energy efficiency,core,cores,457,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:127,integrability,version,versions,127,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:174,integrability,version,versions,174,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:127,modifiability,version,versions,127,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:174,modifiability,version,versions,174,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:453,performance,CPU,CPU,453,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:445,safety,log,logical,445,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:497,safety,updat,updated,497,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:445,security,log,logical,445,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:477,security,Session,Session,477,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:497,security,updat,updated,497,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:445,testability,log,logical,445,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:95,usability,behavi,behaviour,95,"> `hasattr(__builtins__, ""__IPYTHON__"")` now seems to always return False. I'm not seeing this behaviour, could you check what versions you're using? <details>. <summary> My versions </summary>. ```. -----. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.11. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.3.0. -----. Python 3.8.9 (default, Apr 3 2021, 01:50:09) [Clang 12.0.0 (clang-1200.0.32.29)]. macOS-10.15.7-x86_64-i386-64bit. 16 logical CPU cores, i386. -----. Session information updated at 2021-05-10 10:13. ```. </details>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:231,deployability,Version,Versions,231,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:484,deployability,log,logical,484,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:492,energy efficiency,CPU,CPU,492,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:496,energy efficiency,core,cores,496,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:231,integrability,Version,Versions,231,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:231,modifiability,Version,Versions,231,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:492,performance,CPU,CPU,492,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:484,safety,log,logical,484,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:484,security,log,logical,484,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:484,testability,log,logical,484,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:143,usability,confirm,confirmed,143,"```. from scanpy._settings import ScanpyConfig. ScanpyConfig._is_run_from_ipython(). ```. returns `False` when running from within a notebook (confirmed by 3 other colleagues), and causes non-vectorized figures. <details><summary> Versions </summary>. ```. sinfo 0.3.1. -----. IPython 7.23.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.15. notebook 6.3.0. -----. Python 3.8.8 (default, Feb 24 2021, 21:46:12) [GCC 7.3.0]. Linux-5.4.0-1038-aws-x86_64-with-glibc2.10. 16 logical CPU cores, x86_64. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:88,interoperability,specif,specific,88,I think I see what's going on. I'm going to reclose this issue in favor of the two more specific ones I've opened on this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1478:127,deployability,version,version,127,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:172,deployability,instal,installing,172,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:200,deployability,instal,install,200,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:222,deployability,version,version,222,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:127,integrability,version,version,127,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:222,integrability,version,version,222,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:127,modifiability,version,version,127,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:222,modifiability,version,version,222,"I too have the exact same issue with scanpy.tl.rank_genes_groups(). Is this something to do with anndata 0.7.5 requires pandas version >=1.0, yet, pandas coming along with installing scanpy with 'pip install scanpy' is in version 0.23.4?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:7,deployability,instal,install,7,Please install the latest scanpy in a clean environment. Feel free to reopen if this issue persists.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1479:238,availability,cluster,cluster,238,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:469,availability,cluster,clusters,469,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:586,availability,consist,consistent,586,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:677,availability,cluster,clusters,677,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:884,availability,cluster,clusters,884,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:238,deployability,cluster,cluster,238,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:469,deployability,cluster,clusters,469,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:677,deployability,cluster,clusters,677,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:884,deployability,cluster,clusters,884,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:842,energy efficiency,heat,heatmap,842,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:586,usability,consist,consistent,586,"Hi @wkopp . you are defining group labels from this:. ```python. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. ```. but none of those cluster labels are presents in `pbmc`. If you run the function you'll also notice the warning. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. ```. as in `adata.obs.clusters` there is no `NK` or `T-cell` category. Try this, and you'll see that the warning disappear and plotting is consistent. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:760,availability,cluster,clusters,760,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1187,availability,cluster,cluster,1187,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:304,deployability,continu,continue,304,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:760,deployability,cluster,clusters,760,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:955,deployability,observ,observe,955,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1187,deployability,cluster,cluster,1187,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1005,energy efficiency,heat,heatmap,1005,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:446,modifiability,paramet,parameters,446,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1108,reliability,doe,doesn,1108,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1195,security,ident,identities,1195,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:955,testability,observ,observe,955,"Thank @giovp! I have replaced the previous definition of `marker_genes_dict` with the one you suggested. ```python. marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['FCGR3A'],. '3': ['FCER1A']}. ```. But I still seem to obtain inconsistent color codes. I also continue to obtain warnings. ```. WARNING: dendrogram data not found (using key=dendrogram_clusters). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. I have also tried to use different groupby arguments (`clusters` or `louvain`) and `dendrogram=True/False`, but this didn't seem to matter much regarding the color code matching. However, the warning disappear with `dendrogram=False`. In all cases I observe that the ordering of the colors below the heatmap (from left to right) matches the ordering of the colors on the right (top to bottom). But that doesn't necessarily result in a correct matching of colors with respect to the cluster identities. I am using `scanpy.__version__==1.5.1`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:140,availability,cluster,clusters,140,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:347,availability,cluster,clusters,347,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:596,availability,cluster,clusters,596,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:140,deployability,cluster,clusters,140,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:347,deployability,cluster,clusters,347,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:596,deployability,cluster,clusters,596,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:305,energy efficiency,heat,heatmap,305,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:698,interoperability,mismatch,mismatch,698,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:825,interoperability,specif,specific,825,"if you reproduce exactly this code, it still throws warning? ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```. The point about `groupby` argument is that the unique labels in that obs column need to match the ones in marker_genes_dict. So for instance, if. ```python. adata.obs.clusters.unique() # [""foo"",""bar""]. marker_genes_dict = {. ""foo"":...,. ""bar"":... }. ```. if there is a mismatch, then the warning will be thrown. RE: colors, that as to do with whether you called any plotting function before that specific one. For whatever `adata.obs[""your_feature""]`, the plotting functions look in `adata.uns` if there is a key `""your_feature_colors""`. If there is none, then a random one is picked. You'll see for pbmc you'll find one in e.g. ""louvain"" I believe, but for a new annotation (like yours with leiden) then you would have to call a plotting function before, or passing your own palette explictly",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:65,availability,cluster,clustering,65,"Could you try to use `resolution=0.5`. For me, when using leiden clustering with `resolution=.1`, the issue/warning is not provoked, but with 0.5 it is, because there are more clusters identified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:176,availability,cluster,clusters,176,"Could you try to use `resolution=0.5`. For me, when using leiden clustering with `resolution=.1`, the issue/warning is not provoked, but with 0.5 it is, because there are more clusters identified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:65,deployability,cluster,clustering,65,"Could you try to use `resolution=0.5`. For me, when using leiden clustering with `resolution=.1`, the issue/warning is not provoked, but with 0.5 it is, because there are more clusters identified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:176,deployability,cluster,clusters,176,"Could you try to use `resolution=0.5`. For me, when using leiden clustering with `resolution=.1`, the issue/warning is not provoked, but with 0.5 it is, because there are more clusters identified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:185,security,ident,identified,185,"Could you try to use `resolution=0.5`. For me, when using leiden clustering with `resolution=.1`, the issue/warning is not provoked, but with 0.5 it is, because there are more clusters identified.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:58,availability,cluster,clusters,58,"exactly, the reason is that `resolution=0.5` returns more clusters than the one I listed above (from 0 to 4). Just include in the dictionary `marker_genes_dict` all of the clusters returned by res=1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:172,availability,cluster,clusters,172,"exactly, the reason is that `resolution=0.5` returns more clusters than the one I listed above (from 0 to 4). Just include in the dictionary `marker_genes_dict` all of the clusters returned by res=1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:58,deployability,cluster,clusters,58,"exactly, the reason is that `resolution=0.5` returns more clusters than the one I listed above (from 0 to 4). Just include in the dictionary `marker_genes_dict` all of the clusters returned by res=1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:172,deployability,cluster,clusters,172,"exactly, the reason is that `resolution=0.5` returns more clusters than the one I listed above (from 0 to 4). Just include in the dictionary `marker_genes_dict` all of the clusters returned by res=1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:13,availability,cluster,clusters,13,> all of the clusters returned by res=1. I'm not following. Do you mean I should add empty lists for clusters without known markers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:101,availability,cluster,clusters,101,> all of the clusters returned by res=1. I'm not following. Do you mean I should add empty lists for clusters without known markers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:13,deployability,cluster,clusters,13,> all of the clusters returned by res=1. I'm not following. Do you mean I should add empty lists for clusters without known markers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:101,deployability,cluster,clusters,101,> all of the clusters returned by res=1. I'm not following. Do you mean I should add empty lists for clusters without known markers?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:174,availability,cluster,clusters,174,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:362,availability,cluster,clusters,362,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:439,availability,cluster,clusters,439,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:174,deployability,cluster,clusters,174,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:362,deployability,cluster,clusters,362,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:439,deployability,cluster,clusters,439,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:337,energy efficiency,heat,heatmap,337,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:75,integrability,sub,subset,75,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:6,safety,compl,complain,6,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:6,security,compl,complain,6,"might complain with empty lists, but you could just add other markers. or, subset the anndata. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=1). marker_genes_dict = {'1': ['GNLY', 'NKG7'],. '0': ['CD3D'],. '2': ['CD79A', 'MS4A1'],. '4': ['CD79A', 'MS4A1'],. '3': ['FCER1A']}. sc.pl.heatmap(. 	pbmc[pbmc.obs.clusters.isin([""0"", ""2"",""1"",""4"",""3""]), :], . 	marker_genes_dict, . 	groupby='clusters', . 	vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:97,availability,cluster,clusters,97,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:170,availability,cluster,clusters,170,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:515,availability,cluster,clusters,515,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:631,availability,cluster,clusters,631,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:97,deployability,cluster,clusters,97,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:170,deployability,cluster,clusters,170,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:515,deployability,cluster,clusters,515,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:631,deployability,cluster,clusters,631,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:41,energy efficiency,heat,heatmap,41,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:282,energy efficiency,heat,heatmap,282,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:555,energy efficiency,heat,heatmap,555,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:879,energy efficiency,core,core,879,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:156,integrability,sub,subset,156,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:370,integrability,sub,subset,370,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:617,integrability,sub,subset,617,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:240,usability,document,documentation,240,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:271,usability,help,help,271,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:417,usability,document,documentation,417,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:471,usability,clear,clear,471,"Thank you, @giovp . I see. So when using heatmap, the mapping of marker genes must represent all clusters. It won't work if markers are supplied for only a subset of the clusters. As far as I can tell, though, this is not apparent from the documentation of the function `help(sc.pl.heatmap)`. Also, in the plotting tutorial, which I referred to in the beginning, only a subset of markers are supplied. So, either the documentation and tutorial should be adjusted to make clear that markers must be supplied for all clusters. Or, which I would find great, heatmap could be adjusted to be able to display markers for a subset of the clusters, which I had assumed to be the case in the beginning. Btw. from looking at the tutorial, I believe the same issue may apply to some other plotting functions, e.g. for [Tracksplot](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Tracksplot).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:153,availability,cluster,clusters,153,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:367,availability,cluster,clusters,367,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:591,availability,cluster,clusters,591,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:707,availability,cluster,clusters,707,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1696,availability,error,error,1696,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:153,deployability,cluster,clusters,153,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:367,deployability,cluster,clusters,367,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:591,deployability,cluster,clusters,591,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:707,deployability,cluster,clusters,707,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:875,deployability,fail,fails,875,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:321,energy efficiency,heat,heatmap,321,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:661,energy efficiency,heat,heatmap,661,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1197,energy efficiency,heat,heatmap,1197,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1696,performance,error,error,1696,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:11,reliability,doe,does,11,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:875,reliability,fail,fails,875,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1696,safety,error,error,1696,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:908,usability,clear,clearly,908,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1186,usability,help,help,1186,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1296,usability,behavi,behaviour,1296,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1432,usability,clear,clearer,1432,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1696,usability,error,error,1696,"Mmh no, it does work as you expect, just need to turn the dendrogram off. ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""CD79A"", ""MS4A1""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=False,. swap_axes=True,. ). ```. or just pass the list of markers (list, not mapping). ```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=1). marker_genes_list = [""GNLY"", ""NKG7""]. sc.pl.heatmap(. pbmc,. marker_genes_list,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. If you pass a dict with incomplete annotation and request dendrogram, then it fails, and the warning says this clearly:. ```. WARNING: Groups are not reordered because the `groupby` categories and the `var_group_labels` are different. categories: 0, 1, 2, etc. var_group_labels: 1, 0, 2, etc. ```. and it still produces a plot (yet unordered). The `var_group_labels` is also described in `help(sc.pl.heatmap)` as you pointed out. I think the misunderstanding is that passing a mapping or a list the behaviour is different, although potentially expected since a mapping and a list are different things. This could probably be explained clearer in the `var_names` argument yes. Just to go back to your original problem, in your case you were using as mapping categories that were not present in your `groupby` key altogether. This is a different issue, and probably the function should have thrown an error saying `var_group_labels` are not present in `categories`. . If you feel like opening a PR for this, we would really appreciate!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:223,availability,error,error,223,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:569,availability,cluster,clusters,569,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:599,availability,cluster,clusters,599,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:739,availability,error,error,739,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:854,availability,cluster,cluster,854,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:891,availability,cluster,clusters,891,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1007,availability,error,error,1007,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:569,deployability,cluster,clusters,569,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:599,deployability,cluster,clusters,599,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:854,deployability,cluster,cluster,854,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:891,deployability,cluster,clusters,891,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1210,deployability,pipelin,pipeline,1210,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:381,energy efficiency,heat,heatmap,381,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1463,energy efficiency,heat,heatmap,1463,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:555,integrability,sub,subset,555,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:881,integrability,sub,subset,881,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1020,integrability,messag,message,1020,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1210,integrability,pipelin,pipeline,1210,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1607,integrability,sub,substitutes,1607,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1020,interoperability,messag,message,1020,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1253,interoperability,mismatch,mismatching,1253,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1398,interoperability,mismatch,mismatching,1398,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:223,performance,error,error,223,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:739,performance,error,error,739,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1007,performance,error,error,1007,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1471,reliability,doe,doesn,1471,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:223,safety,error,error,223,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:739,safety,error,error,739,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1007,safety,error,error,1007,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1452,safety,avoid,avoided,1452,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:223,usability,error,error,223,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:739,usability,error,error,739,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1007,usability,error,error,1007,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1170,usability,user,user,1170,"> Just to go back to your original problem, in your case you were using as mapping categories that were not present in your groupby key altogether. This is a different issue, and probably the function should have thrown an error saying var_group_labels are not present in categories. Since I just copied the example from the tutorial, I think it would be great fix the handling of heatmap there. There, the problem is sort of two-fold: 1) as you mentioned, the groupby labels NK/T-cell etc. hadn't been defined before, and 2) that only markers for only a subset of the clusters are used (5 out of 9 clusters have markers) are used with `dendrogram=True`. Both of them independently provoke the warning/issue about the reordering. Maybe an error would be appropriate not only for undefined groupby labels (as you suggested), . but also for the case where cluster markers for only a subset of clusters are supplied, instead of delivering a warning and a potentially incorrect ordering. In the latter case, an error with a message suggesting to use `dendrogram=False` would be worthwhile. The danger with just printing a warning is that it might be . missed/ignored by the user (e.g. if the function is used in a pipeline with lots of other outputs) . and mismatching color codes might also not be apparent initially. . For instance, it took me a while to even spot this issue, as i didn't notice the mismatching colors initially. This confusion could be avoided if heatmap doesn't produce a plot at all when incorrect arguments are used. I agree that your workarounds also work, but they don't fully serve as substitutes to make the plots as in the tutorial yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:96,availability,error,error,96,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:82,deployability,fail,fail,82,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:109,energy efficiency,heat,heatmap,109,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:96,performance,error,error,96,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:219,performance,time,time,219,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:82,reliability,fail,fail,82,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:96,safety,error,error,96,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:96,usability,error,error,96,"yes very good point, the tutorial needs to be fixed for sure because now it would fail. trowing error in the heatmap is also probably the best way to go. Thank you for reporting this! I'll have a look as soon as I have time",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1480:87,reliability,doe,does,87,"Tracking this under https://github.com/theislab/anndata/issues/442. Basically, anndata does not work with h5py 3.0 at the moment.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1482:8,integrability,sub,submitting,8,I'll be submitting a fix for this shortly,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/pull/1483:32,security,hash,hashsolo,32,"@njbernstein I had also noticed hashsolo wasn't added to the documentation, which you can do by adding `pp.hashsolo` [here](https://github.com/theislab/scanpy/blob/master/scanpy/external/__init__.py). Though I'm unsure which heading it belongs under.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:107,security,hash,hashsolo,107,"@njbernstein I had also noticed hashsolo wasn't added to the documentation, which you can do by adding `pp.hashsolo` [here](https://github.com/theislab/scanpy/blob/master/scanpy/external/__init__.py). Though I'm unsure which heading it belongs under.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:61,usability,document,documentation,61,"@njbernstein I had also noticed hashsolo wasn't added to the documentation, which you can do by adding `pp.hashsolo` [here](https://github.com/theislab/scanpy/blob/master/scanpy/external/__init__.py). Though I'm unsure which heading it belongs under.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,deployability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,integrability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,interoperability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,modifiability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,reliability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,security,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:145,security,hash,hashing,145,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,testability,integr,integration,86,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:64,usability,tool,tool,64,@adamgayoso I don't think it fits under the other preprocessing tool headings of Data integration or Imputation. Maybe add a new one called Call hashing or Sample demultiplexing. @fidelram thoughts? Not sure who else to tag,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:54,safety,detect,detection,54,"I think a new section would good here, maybe ""Doublet detection""?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:54,security,detect,detection,54,"I think a new section would good here, maybe ""Doublet detection""?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:26,safety,detect,detection,26,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:205,safety,detect,detection,205,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:26,security,detect,detection,26,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:163,security,hash,hashing,163,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:205,security,detect,detection,205,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:220,usability,prefer,prefer,220,"@ivirshup I think doublet detection is a little too narrow in that we can also associate cells to the original sample they came from. Although many folks use cell hashing solely for the purpose of doublet detection. I'd prefer ""Sample demultiplexing"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:152,deployability,releas,release,152,"I'd be happy with whatever, but it needs to go somewhere! How about ""Demultiplexing/ Doublet detection"", so it can go with scrublet (#1476) in the next release, and potentially get split out later if more demultiplexing methods are added?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:93,safety,detect,detection,93,"I'd be happy with whatever, but it needs to go somewhere! How about ""Demultiplexing/ Doublet detection"", so it can go with scrublet (#1476) in the next release, and potentially get split out later if more demultiplexing methods are added?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:93,security,detect,detection,93,"I'd be happy with whatever, but it needs to go somewhere! How about ""Demultiplexing/ Doublet detection"", so it can go with scrublet (#1476) in the next release, and potentially get split out later if more demultiplexing methods are added?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:35,deployability,build,build,35,Any advice for getting the docs to build? The link above doesn't give any details.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:57,reliability,doe,doesn,57,Any advice for getting the docs to build? The link above doesn't give any details.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:117,deployability,fail,failing,117,mm still not going. @adamgayoso sorry to bug ya again. or @ivirshup @fidelram is there a way to see why the docs are failing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:117,reliability,fail,failing,117,mm still not going. @adamgayoso sorry to bug ya again. or @ivirshup @fidelram is there a way to see why the docs are failing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:61,deployability,build,building,61,Could you rebase on master? I can't see any info on the docs building since there are conflicts. Can you build the docs locally?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:105,deployability,build,build,105,Could you rebase on master? I can't see any info on the docs building since there are conflicts. Can you build the docs locally?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:86,interoperability,conflict,conflicts,86,Could you rebase on master? I can't see any info on the docs building since there are conflicts. Can you build the docs locally?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:9,deployability,build,build,9,The docs build locally just fine. There are some warnings but it looks like they are from across the repo. Not sure why they are not building up here. The issue before was that I needed to remove typing from my docstrings. @adamgayoso @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/pull/1483:133,deployability,build,building,133,The docs build locally just fine. There are some warnings but it looks like they are from across the repo. Not sure why they are not building up here. The issue before was that I needed to remove typing from my docstrings. @adamgayoso @ivirshup,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/issues/1484:91,availability,error,error,91,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:316,availability,error,error,316,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:456,availability,error,error,456,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:569,availability,failur,failure,569,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:569,deployability,fail,failure,569,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:103,integrability,messag,message,103,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:462,integrability,messag,message,462,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:103,interoperability,messag,message,103,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:462,interoperability,messag,message,462,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:473,interoperability,specif,specific,473,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:91,performance,error,error,91,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:316,performance,error,error,316,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:456,performance,error,error,456,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:569,performance,failur,failure,569,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:569,reliability,fail,failure,569,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:91,safety,error,error,91,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:161,safety,test,test,161,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:284,safety,test,tests,284,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:316,safety,error,error,316,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:456,safety,error,error,456,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:631,safety,test,test,631,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:161,testability,test,test,161,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:284,testability,test,tests,284,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:631,testability,test,test,631,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:91,usability,error,error,91,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:316,usability,error,error,316,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:456,usability,error,error,456,"The issue is that there was a blank line starting with three spaces, and that triggered an error whose message wasn't particularly related to that. I think this test could probably get rewritten. https://github.com/theislab/scanpy/blob/a8ee1e01e6cea1d3b9f5474997508c99497d4fb4/scanpy/tests/test_docs.py#L18-L38. The error came from the `if any(broken)` block. Basically it's checking for lines which aren't 1) empty, 2) start with a four space indent. The error message is specific to the first line. The PR had a three line indent in between paragraphs triggering the failure. @flying-sheep, thoughts on removing this part of the test? Should we have a separate rst linting check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:230,availability,consist,consistent,230,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:352,energy efficiency,cool,cool,352,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:165,interoperability,format,format,165,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:241,interoperability,format,formatting,241,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:326,performance,time,time,326,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:76,safety,test,test,76,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:291,safety,test,test,291,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:76,testability,test,test,76,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:291,testability,test,test,291,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:230,usability,consist,consistent,230,"If a linter flexible enough to enforce this existed, it would be great. The test should definitely exist, something in our code requires the docstrings to have that format, I just forgot which part. (But in any case it guarantees consistent formatting so that’s nice). #1492 should fix that test to ignore blank lines for the time being. Also isn’t it cool that it points exactly to the problematic line?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1485:142,interoperability,specif,specify-groups-and-implementation-for-multiple-tests,142,This issue has been mentioned on **Scanpy**. There might be relevant details there:. https://scanpy.discourse.group/t/sc-tl-rank-genes-groups-specify-groups-and-implementation-for-multiple-tests/328/3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:189,safety,test,tests,189,This issue has been mentioned on **Scanpy**. There might be relevant details there:. https://scanpy.discourse.group/t/sc-tl-rank-genes-groups-specify-groups-and-implementation-for-multiple-tests/328/3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:189,testability,test,tests,189,This issue has been mentioned on **Scanpy**. There might be relevant details there:. https://scanpy.discourse.group/t/sc-tl-rank-genes-groups-specify-groups-and-implementation-for-multiple-tests/328/3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:56,usability,feedback,feedback,56,"Hi @ivirshup,. Yes, both of them are me. I incorporated feedback from the help forum which suggested that this function has a bug, hence, the bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:74,usability,help,help,74,"Hi @ivirshup,. Yes, both of them are me. I incorporated feedback from the help forum which suggested that this function has a bug, hence, the bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:56,deployability,updat,update,56,@BrianLohman . I can't reproduce this. Could you please update scanpy and check?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:56,safety,updat,update,56,@BrianLohman . I can't reproduce this. Could you please update scanpy and check?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:56,security,updat,update,56,@BrianLohman . I can't reproduce this. Could you please update scanpy and check?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1486:45,deployability,updat,updated,45,"> Hi @rbf22 ,. > what's the issue here? I’ve updated the issue. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:45,safety,updat,updated,45,"> Hi @rbf22 ,. > what's the issue here? I’ve updated the issue. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:45,security,updat,updated,45,"> Hi @rbf22 ,. > what's the issue here? I’ve updated the issue. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:14,deployability,fail,fail,14,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:292,deployability,version,versions,292,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:712,deployability,version,version,712,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:292,integrability,version,versions,292,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:712,integrability,version,version,712,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:191,interoperability,specif,specified,191,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:353,interoperability,share,share,353,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:103,modifiability,pac,packages,103,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:292,modifiability,version,versions,292,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:712,modifiability,version,version,712,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:5,reliability,doe,does,5,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:14,reliability,fail,fail,14,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:27,reliability,doe,does,27,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:56,usability,User,Users,56,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:135,usability,User,UserWarning,135,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:586,usability,user,user-images,586,"This does not fail, but it does produce the warnings:. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning: Vertical orientation ignored with only `x` specified. Here is the plot that shows that individual plots are horizontal compared to the previous versions that were vertical. Also you can see that the plots share the same x axis, which should not be the case as a default for scanpy I suspect. To see how scanpy has historically plotted this data check out: https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. ![Unknown](https://user-images.githubusercontent.com/2634345/98390821-bdbd6580-200a-11eb-958f-aed2cf240c7f.png). This was generated with seaborn version 0.11.0 (sept 2020) https://seaborn.pydata.org/whatsnew.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:78,usability,tip,tips,78,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:103,usability,tip,tips,103,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:133,usability,tip,tips,133,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:171,usability,user,user-images,171,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:287,usability,tip,tips,287,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:325,usability,user,user-images,325,"Try this for a fix,. import seaborn as sns. sns.set_theme(style=""whitegrid""). tips = sns.load_dataset(""tips""). ax = sns.violinplot(x=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392560-ff4f1000-200c-11eb-88f8-07bb00582841.png). ax = sns.violinplot(y=tips[""total_bill""]). ![image](https://user-images.githubusercontent.com/2634345/98392610-0f66ef80-200d-11eb-8056-4ec97049fd13.png). So to have the vertical plots the syntax has changed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:100,deployability,scale,scale,100,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:106,deployability,scale,scale,106,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:100,energy efficiency,scale,scale,100,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:106,energy efficiency,scale,scale,106,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:100,modifiability,scal,scale,100,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:106,modifiability,scal,scale,106,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:100,performance,scale,scale,100,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:106,performance,scale,scale,106,"The line that creates this in scanpy looks like:. g = g.map(. sns.violinplot, y, orient='vertical', scale=scale, order=keys, **kwds,. ).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:46,usability,close,close,46,"Yes, this looks like the same issue, happy to close this for now. Is matplotlib more stable for plotting?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:4,deployability,updat,updating,4,try updating scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:4,safety,updat,updating,4,try updating scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:4,security,updat,updating,4,try updating scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:387,deployability,updat,updating,387,"Thank you,I will have a try&nbsp;. 发自我的iPhone. ------------------ Original ------------------. From: giovp <notifications@github.com&gt;. Date: Mon,Jan 4,2021 10:45 PM. To: theislab/scanpy <scanpy@noreply.github.com&gt;. Cc: Dan <735393152@qq.com&gt;, Comment <comment@noreply.github.com&gt;. Subject: Re: [theislab/scanpy] plotting data horizontal plots with shared axis (#1486). . try updating scanpy. . —. You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:293,integrability,Sub,Subject,293,"Thank you,I will have a try&nbsp;. 发自我的iPhone. ------------------ Original ------------------. From: giovp <notifications@github.com&gt;. Date: Mon,Jan 4,2021 10:45 PM. To: theislab/scanpy <scanpy@noreply.github.com&gt;. Cc: Dan <735393152@qq.com&gt;, Comment <comment@noreply.github.com&gt;. Subject: Re: [theislab/scanpy] plotting data horizontal plots with shared axis (#1486). . try updating scanpy. . —. You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:360,interoperability,share,shared,360,"Thank you,I will have a try&nbsp;. 发自我的iPhone. ------------------ Original ------------------. From: giovp <notifications@github.com&gt;. Date: Mon,Jan 4,2021 10:45 PM. To: theislab/scanpy <scanpy@noreply.github.com&gt;. Cc: Dan <735393152@qq.com&gt;, Comment <comment@noreply.github.com&gt;. Subject: Re: [theislab/scanpy] plotting data horizontal plots with shared axis (#1486). . try updating scanpy. . —. You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:387,safety,updat,updating,387,"Thank you,I will have a try&nbsp;. 发自我的iPhone. ------------------ Original ------------------. From: giovp <notifications@github.com&gt;. Date: Mon,Jan 4,2021 10:45 PM. To: theislab/scanpy <scanpy@noreply.github.com&gt;. Cc: Dan <735393152@qq.com&gt;, Comment <comment@noreply.github.com&gt;. Subject: Re: [theislab/scanpy] plotting data horizontal plots with shared axis (#1486). . try updating scanpy. . —. You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:387,security,updat,updating,387,"Thank you,I will have a try&nbsp;. 发自我的iPhone. ------------------ Original ------------------. From: giovp <notifications@github.com&gt;. Date: Mon,Jan 4,2021 10:45 PM. To: theislab/scanpy <scanpy@noreply.github.com&gt;. Cc: Dan <735393152@qq.com&gt;, Comment <comment@noreply.github.com&gt;. Subject: Re: [theislab/scanpy] plotting data horizontal plots with shared axis (#1486). . try updating scanpy. . —. You are receiving this because you commented. Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1487:153,availability,error,error,153,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:26,integrability,sub,subsetting,26,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:153,performance,error,error,153,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:153,safety,error,error,153,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:153,usability,error,error,153,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:213,usability,command,commands,213,"Hi Brian,. Did you do any subsetting of your adata between running `rank_genes_groups` and `filter_rank_genes_groups`? The only way I can reproduce your error is by removing genes from my adata in between the two commands.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:32,energy efficiency,Current,Currently,32,"Hi Lisa, I didn't remove genes. Currently I'm using scanpy1.5.0 and everything is fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:196,availability,error,error,196,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:249,availability,error,error,249,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:196,performance,error,error,196,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:249,performance,error,error,249,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:196,safety,error,error,196,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:249,safety,error,error,249,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:196,usability,error,error,196,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:249,usability,error,error,249,"Okay, when I run this:. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, ""bulk_labels"", method=""wilcoxon""). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). I get no error. . Can you find a reproducible example of your error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:69,availability,error,error,69,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:69,performance,error,error,69,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:69,safety,error,error,69,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:69,usability,error,error,69,@brianpenghe Did you find a solution for this? I am getting the same error in scanpy 1.7.0.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/pull/1489:77,energy efficiency,current,currently,77,"Hi. Thanks for the PR. I would like to know what is the advantage of this as currently, the `cmap` value can be passed to any scatter plot. . Can you show an example when this could be useful to have?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:235,modifiability,paramet,parameter,235,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:662,safety,test,test,662,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:259,testability,simpl,simpler,259,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:662,testability,test,test,662,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:259,usability,simpl,simpler,259,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:676,usability,user,user-images,676,"The biggest advantage would be the possibility to create such panels as shown in the example, where e.g. quality metrics have different cmaps as gene expression. Another advantage would be that cmaps could be defined globally for each parameter, resulting in simpler plotting calls. ```. adata = sc.datasets.paul15(). adata.X = adata.X.astype('float64'). sc.pp.filter_cells(adata, min_genes=100). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver='arpack'). adata.uns['n_counts_all_cmap'] = 'copper'. adata.uns['n_genes_cmap'] = 'copper'. sc.pl.pca(adata, color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2'], ncols=3). ```. ![test](https://user-images.githubusercontent.com/23263654/99387978-28a55100-28d5-11eb-975d-f91211370c16.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:213,deployability,continu,continuous,213,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:386,deployability,scale,scale,386,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:813,deployability,continu,continuous,813,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:386,energy efficiency,scale,scale,386,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:300,modifiability,paramet,parameters,300,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:386,modifiability,scal,scale,386,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:510,modifiability,paramet,parameter,510,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:824,modifiability,variab,variables,824,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:386,performance,scale,scale,386,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:745,safety,compl,complete,745,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:745,security,compl,complete,745,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:754,security,control,control,754,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:9,testability,context,context,9,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:754,testability,control,control,754,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:331,usability,minim,minimum,331,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:885,usability,ergonom,ergonomic,885,"For some context, this has come up in discussion with cellxgene before: (https://github.com/chanzuckerberg/cellxgene/issues/1152#issuecomment-604286306). I think I still feel the same way about this. Basically, a continuous colormap is defined by more than just the name of the colorspace. There are parameters like maximum value, minimum value, middle value (for divergent colormaps), scale, and binning. I'm not sure how useful it is to keep just the color scheme without any of these other values. Why this parameter, and not others? I'm not sure it's the right solution for the use case. I think that use case would be better fit by being able to generate all the plots individually, then collect them into a figure. This way you would have complete control over how the colormaps were applied to each of the continuous variables separately. Unfortunately, this isn't particularly ergonomic to do with matplotlib since individuals plots have to know about the `Figure` when constructed. Side issue: We probably don't want to save separate color palettes for each gene.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:92,modifiability,variab,variable,92,"Ok, makes sense. What if I implement that `cmap `in `embedding` also accepts a `dict ` of `{variable: colormap}`? `{'n_counts_all': 'copper', 'n_genes_cmap': matplotlib.colors.Colormap}`. It maps variable names to `str ` or `Colormap`. Therefore, the colormap can be processed before and is not stored in AnnData.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:196,modifiability,variab,variable,196,"Ok, makes sense. What if I implement that `cmap `in `embedding` also accepts a `dict ` of `{variable: colormap}`? `{'n_counts_all': 'copper', 'n_genes_cmap': matplotlib.colors.Colormap}`. It maps variable names to `str ` or `Colormap`. Therefore, the colormap can be processed before and is not stored in AnnData.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:333,availability,consist,consistency,333,"Using a dict is an interesting idea. Right now I'd prefer that it matches with other ""vectorized"" arguments (like `vmin`, `vmax`) which take a list. I think for categorical values the continuous arguments are ignored (right @fidelram?). Using a `dict` would get rid of the ""sometimes arguments are ignored"" part of this, but I think consistency is more important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:184,deployability,continu,continuous,184,"Using a dict is an interesting idea. Right now I'd prefer that it matches with other ""vectorized"" arguments (like `vmin`, `vmax`) which take a list. I think for categorical values the continuous arguments are ignored (right @fidelram?). Using a `dict` would get rid of the ""sometimes arguments are ignored"" part of this, but I think consistency is more important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:51,usability,prefer,prefer,51,"Using a dict is an interesting idea. Right now I'd prefer that it matches with other ""vectorized"" arguments (like `vmin`, `vmax`) which take a list. I think for categorical values the continuous arguments are ignored (right @fidelram?). Using a `dict` would get rid of the ""sometimes arguments are ignored"" part of this, but I think consistency is more important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:333,usability,consist,consistency,333,"Using a dict is an interesting idea. Right now I'd prefer that it matches with other ""vectorized"" arguments (like `vmin`, `vmax`) which take a list. I think for categorical values the continuous arguments are ignored (right @fidelram?). Using a `dict` would get rid of the ""sometimes arguments are ignored"" part of this, but I think consistency is more important here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:138,interoperability,specif,specifically,138,"I think a problem with a list would be that is would need to be the same length as `color`, and therefore, each colormap would need to be specifically defined, even for categorical plots. E.g. ```. color=['paul15_clusters', 'n_counts_all', 'n_genes', 'Zyx', 'calp80', 'slc43a2']. cmap=['??', 'copper', 'copper', 'viridis', 'viridis', 'viridis']. ```. I don't think that this would make sense...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:81,availability,consist,consistency,81,"I agree, but this is also a problem with the other vectorized arguments. I think consistency is important for the API, so that we can just handle each of these arguments the same way. This also makes it easier to make a change across all of these arguments in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:114,deployability,API,API,114,"I agree, but this is also a problem with the other vectorized arguments. I think consistency is important for the API, so that we can just handle each of these arguments the same way. This also makes it easier to make a change across all of these arguments in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:114,integrability,API,API,114,"I agree, but this is also a problem with the other vectorized arguments. I think consistency is important for the API, so that we can just handle each of these arguments the same way. This also makes it easier to make a change across all of these arguments in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:114,interoperability,API,API,114,"I agree, but this is also a problem with the other vectorized arguments. I think consistency is important for the API, so that we can just handle each of these arguments the same way. This also makes it easier to make a change across all of these arguments in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:81,usability,consist,consistency,81,"I agree, but this is also a problem with the other vectorized arguments. I think consistency is important for the API, so that we can just handle each of these arguments the same way. This also makes it easier to make a change across all of these arguments in the future.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1490:51,availability,error,error,51,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:442,availability,down,downstream,442,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:143,deployability,contain,contains,143,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:51,performance,error,error,51,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:463,reliability,Doe,Does,463,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:51,safety,error,error,51,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:3,usability,prefer,preference,3,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:51,usability,error,error,51,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:453,usability,behavi,behavior,453,"My preference would be to throw a more informative error. Something like: ""Could not calculate statistics for group {group_name} since it only contains one sample."". I don't like that groups would be implicitly excluded from the results. In general I would expect each category of `adata.obs[""cat""]` to be in the results of `sc.tl.rank_genes_groups(adata, ""cat"")`. If they can implicitly be excluded, I think that will lead to more confusing downstream behavior. Does that sound reasonable @pinin4fjords, @Koncopd?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:40,availability,cluster,clustering,40,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:456,availability,cluster,clusters,456,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:40,deployability,cluster,clustering,40,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:456,deployability,cluster,clusters,456,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:164,interoperability,specif,specify,164,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:251,modifiability,layer,layer,251,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:79,safety,detect,detection,79,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:79,security,detect,detection,79,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:11,usability,workflow,workflows,11,"So for our workflows, where we pass the clustering step directly to the marker detection, it would be good to be able to get markers for non-singlet groups when we specify 'all', even where there are singlet groups. We can add a workaround to our CLI layer and in fact I'm doing that anyway since we need a fix quickly https://github.com/ebi-gene-expression-group/scanpy-scripts/pull/88, but there I'm having to transiently edit .obs to remove the singlet clusters which seems messier (and we're not sure if that will have unintended consequences).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:46,availability,cluster,clusters,46,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:145,availability,cluster,clusters,145,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:240,availability,cluster,clusters,240,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:46,deployability,cluster,clusters,46,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:145,deployability,cluster,clusters,145,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:240,deployability,cluster,clusters,240,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:659,deployability,releas,released,659,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:23,usability,user,users,23,"We should probably let users provide a set of clusters for the reference. . Until then, could you do:. ```python. groups_to_test = (. adata.obs[""clusters""]. .value_counts(). .loc[lambda x: x > 1]. .index. ). subset_adata = adata[adata.obs[""clusters""].isin(groups_to_test)].copy(). sc.tl.rank_genes_groups(subset_adata, ...). adata.uns[""rank_genes_groups""] = subset_adata.uns[""rank_genes_groups""]. ```. Or, if you want the singlets in the reference:. ```python. sc.tl.rank_genes_groups(adata, groups=list(groups_to_test), ...). ```. BTW, about the h5py bytes thing, things written as strings are read as strings with h5py 3 as of anndata 0.7.5, which just got released.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:33,reliability,doe,does,33,"Looking at your code a bit more, does the `groups` argument work for your issue?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:35,reliability,doe,does,35,"> Looking at your code a bit more, does the `groups` argument work for your issue? Yep, should do as well- I'll try",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:113,availability,avail,available,113,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:157,deployability,fail,failing,157,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:113,reliability,availab,available,113,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:157,reliability,fail,failing,157,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:113,safety,avail,available,113,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:113,security,availab,available,113,"Thanks @ivirshup that worked nicely, I should have thought of it. I'll remove our h5py pin once anndata 0.7.5 is available on Conda (have you seen that it's failing right now? https://github.com/conda-forge/anndata-feedstock/pull/13)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:197,availability,error,error,197,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,deployability,build,build,52,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:131,integrability,topic,topic,131,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:203,integrability,messag,message,203,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:203,interoperability,messag,message,203,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:84,modifiability,maintain,maintainers,84,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:197,performance,error,error,197,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:84,safety,maintain,maintainers,84,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:197,safety,error,error,197,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:189,usability,help,helpful,189,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:197,usability,error,error,197,"Great! I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:211,availability,error,error,211,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:313,availability,error,error,313,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:60,deployability,build,build,60,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:145,integrability,topic,topic,145,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:217,integrability,messag,message,217,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:217,interoperability,messag,message,217,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:92,modifiability,maintain,maintainers,92,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:211,performance,error,error,211,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:313,performance,error,error,313,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:92,safety,maintain,maintainers,92,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:211,safety,error,error,211,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:313,safety,error,error,313,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:203,usability,help,helpful,203,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:211,usability,error,error,211,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:313,usability,error,error,313,"> Great! > . > I'm not sure what's going on with that conda build, but hopefully one of the maintainers there will know what to do. > . > On the topic of this PR, I do think this case should give a more helpful error message. Would you like to do that? Sure- there you go. I reverted the above and just raised an error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:50,availability,error,error,50,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:50,performance,error,error,50,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:77,reliability,doe,does,77,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:28,safety,test,test,28,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:50,safety,error,error,50,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:28,testability,test,test,28,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:50,usability,error,error,50,Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,availability,error,error,52,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,performance,error,error,52,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:79,reliability,doe,does,79,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:30,safety,test,test,30,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,safety,error,error,52,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:156,safety,test,tests,156,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:246,safety,test,test,246,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:30,testability,test,test,30,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:156,testability,test,tests,156,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:246,testability,test,test,246,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,usability,error,error,52,"> Great! Could you also add a test to make sure the error is being thrown? And does this handle cases where there are categories with no entries? Sorry yep tests added. And yep, the value_counts() will also catch empty categories (though added a test for that too).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1492:331,availability,error,error,331,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:16,energy efficiency,cool,cool,16,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:69,energy efficiency,Current,Currently,69,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:337,integrability,messag,message,337,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:337,interoperability,messag,message,337,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:331,performance,error,error,331,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:331,safety,error,error,331,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:381,safety,test,testing,381,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:381,testability,test,testing,381,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:407,testability,assert,assert,407,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:331,usability,error,error,331,"> Also isn’t it cool that it points exactly to the problematic line? Currently, I think the line number reported is the number of lines past the `:` in the function definition. It'd be really nice if it could tell you which line number in the file it was (which might be difficult for manipulated doc-strings). Also, from what the error message says, isn't the `any(broken)` check testing the same thing as assert lines[0], `f""{name} needs a single-line summary""`? Isn't the first one sufficient?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:58,testability,assert,assert,58,It’s using `__orig_doc__` so the line should be correct. `assert lines[0]` just asserts that the first line is non-empty. `any(broken)` checks if there’s under-indented lines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:80,testability,assert,asserts,80,It’s using `__orig_doc__` so the line should be correct. `assert lines[0]` just asserts that the first line is non-empty. `any(broken)` checks if there’s under-indented lines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:68,availability,error,error,68,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:281,availability,error,error,281,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:68,performance,error,error,68,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:281,performance,error,error,281,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:68,safety,error,error,68,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:281,safety,error,error,281,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:68,usability,error,error,68,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:281,usability,error,error,281,"> any(broken) checks if there’s under-indented lines. Sure, but the error it throws is: ```""Header of function `{name}`’s docstring should start with one-line description:""```, which suggests that wasn't the intent of the check. If it's a check for white space, it should throw an error about white space.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:109,integrability,messag,message,109,"Same thing: If the line is under-indented, the first line summary can’t be properly extracted. I’ll make the message more clear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:109,interoperability,messag,message,109,"Same thing: If the line is under-indented, the first line summary can’t be properly extracted. I’ll make the message more clear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:122,usability,clear,clear,122,"Same thing: If the line is under-indented, the first line summary can’t be properly extracted. I’ll make the message more clear.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1493:27,performance,time,time,27,"Oh wow, that’s been a long time coming!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/issues/1495:12,usability,help,helpful,12,"it would be helpful to see the lines of code you ran in each of the two cases you describe. for example when you say "" if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back."" --> in this case, did you use the default fold change argument?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1496:24,availability,replic,replicate,24,"@TheAustinator, can you replicate this in a fresh environment (e.g. conda)? It could help to limit the number of other installed packages. @flying-sheep, any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:119,deployability,instal,installed,119,"@TheAustinator, can you replicate this in a fresh environment (e.g. conda)? It could help to limit the number of other installed packages. @flying-sheep, any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:129,modifiability,pac,packages,129,"@TheAustinator, can you replicate this in a fresh environment (e.g. conda)? It could help to limit the number of other installed packages. @flying-sheep, any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:85,usability,help,help,85,"@TheAustinator, can you replicate this in a fresh environment (e.g. conda)? It could help to limit the number of other installed packages. @flying-sheep, any ideas?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:15,reliability,doe,does,15,@TheAustinator does the `flit` branch work?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:60,deployability,instal,install,60,"Hey guys, thanks for getting back to me. @flying-sheep `pip install -e` isn't working on the flit branch because it doesn't have a `setup.py` -- is there another way to install?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:169,deployability,instal,install,169,"Hey guys, thanks for getting back to me. @flying-sheep `pip install -e` isn't working on the flit branch because it doesn't have a `setup.py` -- is there another way to install?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:116,reliability,doe,doesn,116,"Hey guys, thanks for getting back to me. @flying-sheep `pip install -e` isn't working on the flit branch because it doesn't have a `setup.py` -- is there another way to install?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:56,deployability,instal,install,56,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:76,deployability,instal,install,76,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:104,deployability,instal,install,104,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:119,deployability,instal,installing,119,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:195,deployability,instal,installation,195,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:225,deployability,version,version,225,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:268,deployability,instal,install,268,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:374,deployability,build,build,374,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:338,energy efficiency,current,currently,338,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:225,integrability,version,version,225,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:225,modifiability,version,version,225,"I merged it into master now. You can try a regular `pip install .` or `flit install -s` for an editable install (after installing flit) as described here: https://scanpy.readthedocs.io/en/latest/installation.html#development-version. Pip says that btw if you try `pip install -e .`. > A ""pyproject.toml"" file was found, but editable mode currently requires a setup.py based build.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1497:621,deployability,modul,module,621,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:260,energy efficiency,cool,coolwarm,260,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:434,energy efficiency,cool,coolwarm,434,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:762,energy efficiency,cool,coolwarm,762,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1458,energy efficiency,core,core,1458,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:996,integrability,compon,components,996,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:996,interoperability,compon,components,996,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:621,modifiability,modul,module,621,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:877,modifiability,pac,packages,877,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:954,modifiability,layer,layers,954,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:996,modifiability,compon,components,996,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1442,modifiability,pac,packages,1442,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:594,safety,input,input-,594,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:621,safety,modul,module,621,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1537,security,hash,hash,1537,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:550,testability,Trace,Traceback,550,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:594,usability,input,input-,594,"我同样面临着这个 bug. 我的代码是. ```python. #genes_to_plot = ['Blvrb','Klf1','Serpina3f','Coro1a','Napsa','Ly6c2']. genes_to_plot = ['Blvrb',#MEP marker. 'Klf1',#MEP marker. 'Serpina3f']#CMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). genes_to_plot = ['Coro1a',#CMP and GMP marker. 'Napsa',#GMP marker. 'Ly6c2']#GMP marker. sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). ```. 错误信息：. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-13-61edd8063c25> in <module>(). 3 'Klf1',#MEP marker. 4 'Serpina3f']#CMP marker. ----> 5 sc.pl.scatter(adata,'cd34_log','fcgr_log',color=genes_to_plot,color_map='coolwarm'). 6 genes_to_plot = ['Coro1a',#CMP and GMP marker. 7 'Napsa',#GMP marker. ~/anaconda3/lib/python3.7/site-packages/scanpy/plotting/_anndata.py in scatter(adata, x, y, color, use_raw, layers, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, legend_fontoutline, color_map, palette, frameon, right_margin, left_margin, size, title, show, save, ax). 124 (x in adata.obs.keys() or x in adata.var.index). 125 and (y in adata.obs.keys() or y in adata.var.index). --> 126 and (color is None or color in adata.obs.keys() or color in adata.var.index). 127 ):. 128 return _scatter_obs(**args). ~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'list'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:52,modifiability,paramet,parameter,52,"This is still not resolved. It works if you set the parameter `colorbar` to something else, like `colorbar=False`. So that in the linked if-else the else is executed https://github.com/theislab/scanpy/blob/8fe1cf9cb6309fa0e91aa5cfd9ed7580e9d5b2ad/scanpy/plotting/_tools/paga.py#L472.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:25,energy efficiency,current,currently,25,"I don't think any of the currently active maintainers are particularly familiar with this code, so a pull request to address this would be much appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:42,modifiability,maintain,maintainers,42,"I don't think any of the currently active maintainers are particularly familiar with this code, so a pull request to address this would be much appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:42,safety,maintain,maintainers,42,"I don't think any of the currently active maintainers are particularly familiar with this code, so a pull request to address this would be much appreciated.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:39,usability,document,documentation,39,Me neither. Can I just add this to the documentation as quick&dirty fix or do I need to actually correct the colorbar code as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/pull/1499:72,interoperability,semant,semantics,72,"About `use_raw` with `sc.get.var_df`: I didn't include this because the semantics differ significantly from `sc.get.obs_df`, as `raw` can have a different number of variables. I think it makes more sense for a user to call `sc.get.var_df(adata.raw, ...)`, since it's much more explicit that `adata.raw.var` and `adata.raw.varm` will be used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:165,modifiability,variab,variables,165,"About `use_raw` with `sc.get.var_df`: I didn't include this because the semantics differ significantly from `sc.get.obs_df`, as `raw` can have a different number of variables. I think it makes more sense for a user to call `sc.get.var_df(adata.raw, ...)`, since it's much more explicit that `adata.raw.var` and `adata.raw.varm` will be used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:89,security,sign,significantly,89,"About `use_raw` with `sc.get.var_df`: I didn't include this because the semantics differ significantly from `sc.get.obs_df`, as `raw` can have a different number of variables. I think it makes more sense for a user to call `sc.get.var_df(adata.raw, ...)`, since it's much more explicit that `adata.raw.var` and `adata.raw.varm` will be used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:210,usability,user,user,210,"About `use_raw` with `sc.get.var_df`: I didn't include this because the semantics differ significantly from `sc.get.obs_df`, as `raw` can have a different number of variables. I think it makes more sense for a user to call `sc.get.var_df(adata.raw, ...)`, since it's much more explicit that `adata.raw.var` and `adata.raw.varm` will be used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:202,deployability,build,build,202,"It's not just that the length is different, is that `sc.get.obs_df(adata, [""col""], use_raw=x)[""col""]` is the same regardless of the value of `x`, but it's different for `var_df`. I think it's easier to build code around functions with more orthogonal arguments. > However, I consider that since this option is everywhere it should be here as well. . Could we add an example of `sc.get.var_df(adata.raw, ...)`, leave out `use_raw` for now, and see if anyone complains? I've been trying to leave out `use_raw` on functions where variable length matters anyways. For example: `adata.var_vector`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:527,modifiability,variab,variable,527,"It's not just that the length is different, is that `sc.get.obs_df(adata, [""col""], use_raw=x)[""col""]` is the same regardless of the value of `x`, but it's different for `var_df`. I think it's easier to build code around functions with more orthogonal arguments. > However, I consider that since this option is everywhere it should be here as well. . Could we add an example of `sc.get.var_df(adata.raw, ...)`, leave out `use_raw` for now, and see if anyone complains? I've been trying to leave out `use_raw` on functions where variable length matters anyways. For example: `adata.var_vector`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:457,safety,compl,complains,457,"It's not just that the length is different, is that `sc.get.obs_df(adata, [""col""], use_raw=x)[""col""]` is the same regardless of the value of `x`, but it's different for `var_df`. I think it's easier to build code around functions with more orthogonal arguments. > However, I consider that since this option is everywhere it should be here as well. . Could we add an example of `sc.get.var_df(adata.raw, ...)`, leave out `use_raw` for now, and see if anyone complains? I've been trying to leave out `use_raw` on functions where variable length matters anyways. For example: `adata.var_vector`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:457,security,compl,complains,457,"It's not just that the length is different, is that `sc.get.obs_df(adata, [""col""], use_raw=x)[""col""]` is the same regardless of the value of `x`, but it's different for `var_df`. I think it's easier to build code around functions with more orthogonal arguments. > However, I consider that since this option is everywhere it should be here as well. . Could we add an example of `sc.get.var_df(adata.raw, ...)`, leave out `use_raw` for now, and see if anyone complains? I've been trying to leave out `use_raw` on functions where variable length matters anyways. For example: `adata.var_vector`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:138,availability,sli,slicing,138,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:18,deployability,fail,failed,18,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:18,reliability,fail,failed,18,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:138,reliability,sli,slicing,138,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:13,safety,test,test,13,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:76,safety,test,tests,76,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:13,testability,test,test,13,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:76,testability,test,tests,76,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:36,usability,clear,clear,36,"The previous test failed but is not clear to me why, as it passes the local tests (anndata 0.7.5). It seems that on travis server, backed slicing requires integer indices and will not work with a boolean vector. I changed to sorted integers hoping that this will solve the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:241,interoperability,specif,specific,241,"My thinking on my change is that I would like all the code that handles backed mode to be cleanly separated. I think this should be handled more cleanly on the `anndata` side, and once that's been done it's easier to replace the backed mode specific code if it's all together.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/issues/1500:244,modifiability,paramet,parameters,244,"This has been worked on here: https://github.com/theislab/anndata/pull/342. The idea is to allow any vector from the anndata object to be used for coloring, but that PR seems a bit stalled at the moment. This would also be useful for providing parameters in other places, like `regress_out`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/pull/1501:232,availability,mask,mask,232,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:64,energy efficiency,current,currently,64,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:48,integrability,transform,transformation,48,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:95,integrability,sub,subset,95,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:140,integrability,transform,transformation,140,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:48,interoperability,transform,transformation,48,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:140,interoperability,transform,transformation,140,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:38,usability,learn,learn,38,"Should the reference object where you learn the transformation (currently `adata`) always be a subset of the data you're going to apply the transformation to (`adata2`)? If so, instead of passing a separate object, could there be a mask of which samples to train on? If not, what do you think about making this a separate function? Maybe `combat_by_reference`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:203,availability,mask,mask,203,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:405,availability,mask,mask,405,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:50,integrability,transform,transformation,50,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:77,integrability,sub,subset,77,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:122,integrability,transform,transformation,122,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:50,interoperability,transform,transformation,50,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:122,interoperability,transform,transformation,122,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:40,usability,learn,learn,40,"> Should the reference object where you learn the transformation always be a subset of the data you're going to apply the transformation to? If so, instead of passing a separate object, could there be a mask of which samples to train on? > . > If not, what do you think about making this a separate function? Maybe `combat_by_reference`? Thank you for your great suggestions. I think it's easier to add a mask for train/evaluate instead of splitting into 2 objects. . I don't think it should be a separate `combat_by_reference` function, though, because the chance in the function is small and I preserved the original functionality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/issues/1502:270,modifiability,paramet,parameter,270,"You can pass `legend_loc=None`. Thanks for noting this. Looking at the docs, I can definitely see how this isn't clear. ```. legend_loc : str, optional (default: 'right margin'). Location of legend, either `'on data'`, `'right margin'` or a valid keyword. for the `loc` parameter of :class:`~matplotlib.legend.Legend`. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:241,safety,valid,valid,241,"You can pass `legend_loc=None`. Thanks for noting this. Looking at the docs, I can definitely see how this isn't clear. ```. legend_loc : str, optional (default: 'right margin'). Location of legend, either `'on data'`, `'right margin'` or a valid keyword. for the `loc` parameter of :class:`~matplotlib.legend.Legend`. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:113,usability,clear,clear,113,"You can pass `legend_loc=None`. Thanks for noting this. Looking at the docs, I can definitely see how this isn't clear. ```. legend_loc : str, optional (default: 'right margin'). Location of legend, either `'on data'`, `'right margin'` or a valid keyword. for the `loc` parameter of :class:`~matplotlib.legend.Legend`. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:82,integrability,sub,substrate,82,"Tada! Works perfectly. . Thanks for the tip, and may this GitHub comment serve as substrate to all future google searches on this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:40,usability,tip,tip,40,"Tada! Works perfectly. . Thanks for the tip, and may this GitHub comment serve as substrate to all future google searches on this issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:13,deployability,updat,update,13,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:89,deployability,continu,continuous,89,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:66,modifiability,variab,variables,66,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:100,modifiability,variab,variables,100,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:13,safety,updat,update,13,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:129,safety,test,testData,129,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:13,security,updat,update,13,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:129,testability,test,testData,129,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:263,usability,user,user-images,263,"So one small update here -- it works like a charm for categorical variables, but not for continuous variables. e.g. > sc.pl.umap(testData, save = fileName, color='CCL5',s=50,frameon=False,legend_loc = None). Still gives something like a legend:. ![image](https://user-images.githubusercontent.com/10536275/99786010-40234a80-2b1e-11eb-83ab-77c9341dab05.png). Presumably this is because the color strip on the right is not actually a legend in the underlying matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1503:129,integrability,pub,public,129,"hi @pedrofale ! Thanks a lot for the interest! Yes indeed we are working on an extension that handles spatial data and should be public in ~1 month. I'll keep you posted here as soon as we have it ready. question re: IMC. What's the data format that you are interested in importing to anndata? Is it something more elaborate than a feature matrix `(obs, features)` and spatial coordinates `(obs, coordinates)` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:238,interoperability,format,format,238,"hi @pedrofale ! Thanks a lot for the interest! Yes indeed we are working on an extension that handles spatial data and should be public in ~1 month. I'll keep you posted here as soon as we have it ready. question re: IMC. What's the data format that you are interested in importing to anndata? Is it something more elaborate than a feature matrix `(obs, features)` and spatial coordinates `(obs, coordinates)` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:377,interoperability,coordinat,coordinates,377,"hi @pedrofale ! Thanks a lot for the interest! Yes indeed we are working on an extension that handles spatial data and should be public in ~1 month. I'll keep you posted here as soon as we have it ready. question re: IMC. What's the data format that you are interested in importing to anndata? Is it something more elaborate than a feature matrix `(obs, features)` and spatial coordinates `(obs, coordinates)` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:396,interoperability,coordinat,coordinates,396,"hi @pedrofale ! Thanks a lot for the interest! Yes indeed we are working on an extension that handles spatial data and should be public in ~1 month. I'll keep you posted here as soon as we have it ready. question re: IMC. What's the data format that you are interested in importing to anndata? Is it something more elaborate than a feature matrix `(obs, features)` and spatial coordinates `(obs, coordinates)` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:79,modifiability,extens,extension,79,"hi @pedrofale ! Thanks a lot for the interest! Yes indeed we are working on an extension that handles spatial data and should be public in ~1 month. I'll keep you posted here as soon as we have it ready. question re: IMC. What's the data format that you are interested in importing to anndata? Is it something more elaborate than a feature matrix `(obs, features)` and spatial coordinates `(obs, coordinates)` ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:229,usability,close,close,229,"Just came across this open issue. I suppose with [SpatialData](https://spatialdata.scverse.org/en/latest/) and [squidpy](https://squidpy.readthedocs.io/en/stable/), this question has been addressed in the meanwhile. :). We might close this issue soon, but please don't hesitate to reopen this issue or create a new one if you have more related questions. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1504:23,availability,error,error,23,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:102,availability,error,error,102,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:108,integrability,messag,message,108,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:108,interoperability,messag,message,108,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:23,performance,error,error,23,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:102,performance,error,error,102,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:23,safety,error,error,23,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:102,safety,error,error,102,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:23,usability,error,error,23,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:38,usability,behavi,behavior,38,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:94,usability,help,helpful,94,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:102,usability,error,error,102,Could you suggest some error handling behavior here? I think there could definitely be a more helpful error message.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:143,availability,error,error,143,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:149,integrability,messag,message,149,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:149,interoperability,messag,message,149,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:30,performance,time,times,30,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:54,performance,time,time,54,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:143,performance,error,error,143,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:143,safety,error,error,143,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:62,testability,understand,understand,62,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:7,usability,experien,experienced,7,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:143,usability,error,error,143,"I also experienced this a few times, and took me some time to understand what is going on. I fully agree with @ivirshup, we should improve the error message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:147,reliability,doe,does,147,"I wish I understood why this was happening too. I believe it's the same underlying C code as the R implementation, and I don't think Seurat's code does anything special to prevent this. Increasing the span could really affect which genes are selected as HVG I believe, whereas removing some outliers by low expression might not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:172,safety,prevent,prevent,172,"I wish I understood why this was happening too. I believe it's the same underlying C code as the R implementation, and I don't think Seurat's code does anything special to prevent this. Increasing the span could really affect which genes are selected as HVG I believe, whereas removing some outliers by low expression might not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:172,security,preven,prevent,172,"I wish I understood why this was happening too. I believe it's the same underlying C code as the R implementation, and I don't think Seurat's code does anything special to prevent this. Increasing the span could really affect which genes are selected as HVG I believe, whereas removing some outliers by low expression might not?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:139,availability,error,error,139,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:34,integrability,batch,batch,34,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:72,integrability,batch,batches,72,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:177,integrability,batch,batch,177,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:207,integrability,batch,batch,207,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:34,performance,batch,batch,34,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:72,performance,batch,batches,72,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:139,performance,error,error,139,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:177,performance,batch,batch,177,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:207,performance,batch,batch,207,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:106,reliability,Doe,Does,106,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:213,reliability,doe,doesn,213,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:139,safety,error,error,139,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:149,testability,simpl,simply,149,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:6,usability,experien,experience,6,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:139,usability,error,error,139,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:149,usability,simpl,simply,149,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:197,usability,user,user,197,"In my experience, this happens if batch key is not None and one or more batches have low number of cells. Does it make sense to catch this error and simply skip the problematic batch or inform the user that batch doesn't have enough cells?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:182,availability,error,error,182,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:304,availability,error,error,304,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:54,integrability,batch,batch,54,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:87,integrability,batch,batch,87,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:204,integrability,filter,filtering,204,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:446,modifiability,layer,layer,446,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:54,performance,batch,batch,54,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:87,performance,batch,batch,87,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:182,performance,error,error,182,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:304,performance,error,error,304,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:182,safety,error,error,182,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:304,safety,error,error,304,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:182,usability,error,error,182,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:304,usability,error,error,304,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:598,usability,user,user-images,598,"I ran into this recently - the problem can occur when batch key has many cells in each batch (see plot). Increasing the span from the default of 0.3 to 0.5 seems to have ""fixed"" the error. Increasing the filtering stringency for lowly expressed genes (to min_gene=500, min_cells=10) also gets rid of the error. ```. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). ```. ```. sc.pp.highly_variable_genes(. adata,. layer=""counts"",. flavor=""seurat_v3"",. n_top_genes=num_hvgs,. batch_key='sex_cell_subtype',. span=0.5. ). ```. <img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/4561831/234303299-74bee98d-94a8-40a8-b0dd-cc10eac1acec.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/pull/1505:0,energy efficiency,Cool,Cool,0,Cool! Do I also get a minor developer tag for the couple of small functions I added? ;),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1505:50,integrability,coupl,couple,50,Cool! Do I also get a minor developer tag for the couple of small functions I added? ;),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1505:50,modifiability,coupl,couple,50,Cool! Do I also get a minor developer tag for the couple of small functions I added? ;),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1505:50,testability,coupl,couple,50,Cool! Do I also get a minor developer tag for the couple of small functions I added? ;),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1506:5,deployability,updat,updated,5,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:299,deployability,depend,dependency,299,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:341,deployability,updat,update,341,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:299,integrability,depend,dependency,299,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:299,modifiability,depend,dependency,299,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:5,safety,updat,updated,5,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:106,safety,test,test,106,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:171,safety,test,test,171,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:204,safety,valid,valid,204,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:294,safety,test,test,294,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:299,safety,depend,dependency,299,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:341,safety,updat,update,341,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:374,safety,test,test,374,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:5,security,updat,updated,5,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:341,security,updat,update,341,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:106,testability,test,test,106,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:171,testability,test,test,171,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:294,testability,test,test,294,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:299,testability,depend,dependency,299,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:374,testability,test,test,374,"I've updated the code to store the image path in `adata.uns['spatial'][sample_id]['tif_image_path']`. The test now also checks whether the image file exists. . I can also test whether the image file is a valid tiff image, but for this we'd need to add a tiff reading library like `pillow` as a test dependency to scanpy. If that is ok, I'll update the PR with an additional test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:122,modifiability,pac,packages,122,"thanks a lot @hspitzer ! I think checking for image is indeed problematic, maybe we can drop it if it requests additional packages. re: image path. I would store it in the metadata dict:. ```python. adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""metadata""]. >>> {'chemistry_description': ""Spatial 3' v1"",. >>> 'software_version': 'spaceranger-1.0.0'}. ```. with some name like key=image_name and value=path ? or something like that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:121,availability,down,downloaded,121,"> with some name like key=image_name and value=path ? or something like that. sure! What do you mean with image_name? As downloaded from the 10x website, the tiff image always has the same filename (""image.tif""). Or do you mean the string ""image_name"" as key? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:26,interoperability,format,format,26,"good point, maybe the img format? like `'tif_image':''[PATH]`. so that if it's jpeg than it's visible?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:111,integrability,standardiz,standardized,111,"Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:111,interoperability,standard,standardized,111,"Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:399,availability,down,downloading,399,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:61,deployability,depend,dependency,61,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:98,deployability,depend,dependencies,98,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:61,integrability,depend,dependency,61,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:98,integrability,depend,dependencies,98,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:61,modifiability,depend,dependency,61,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:98,modifiability,depend,dependencies,98,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:76,reliability,doe,doesn,76,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:56,safety,test,test,56,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:61,safety,depend,dependency,61,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:98,safety,depend,dependencies,98,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:56,testability,test,test,56,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:61,testability,depend,dependency,61,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:98,testability,depend,dependencies,98,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:211,usability,command,command,211,"Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:232,deployability,contain,container,232,"> Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:113,integrability,standardiz,standardized,113,"> Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:113,interoperability,standard,standardized,113,"> Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:240,deployability,contain,container,240,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:450,deployability,automat,automatically,450,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:115,integrability,standardiz,standardized,115,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:115,interoperability,standard,standardized,115,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:288,interoperability,standard,standardised,288,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:450,testability,automat,automatically,450,"> > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > . > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:407,availability,down,downloading,407,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:528,availability,down,downloads,528,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:63,deployability,depend,dependency,63,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:100,deployability,depend,dependencies,100,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:63,integrability,depend,dependency,63,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:100,integrability,depend,dependencies,100,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:63,modifiability,depend,dependency,63,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:100,modifiability,depend,dependencies,100,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:78,reliability,doe,doesn,78,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:58,safety,test,test,58,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:63,safety,depend,dependency,63,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:100,safety,depend,dependencies,100,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:58,testability,test,test,58,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:63,testability,depend,dependency,63,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:100,testability,depend,dependencies,100,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:219,usability,command,command,219,"> Also, I don't think I would mind `Pillow` too much as a test dependency (it doesn't have a ton of dependencies, right?). > . > A more lightweight solution would be to call [`file`](https://en.wikipedia.org/wiki/File_(command)) on the path, which should be able to recognize it as a `tiff`. I think this would only look at the head of the file though, and wouldn't check if it was corrupted/ didn't finish downloading. I was not aware of `file`. I think it might be a good solution! `readwrite._download` should make sure that downloads are not incomplete, so just reading the header might be enough",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:252,deployability,contain,container,252,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:468,deployability,automat,automatically,468,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:659,deployability,depend,depending,659,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:689,deployability,automat,automatic,689,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:117,integrability,standardiz,standardized,117,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:659,integrability,depend,depending,659,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:117,interoperability,standard,standardized,117,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:306,interoperability,standard,standardised,306,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:591,interoperability,format,format,591,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:659,modifiability,depend,depending,659,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:739,modifiability,extens,extensive,739,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:659,safety,depend,depending,659,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:468,testability,automat,automatically,468,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:659,testability,depend,depending,659,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:689,testability,automat,automatic,689,"> > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > . > > . > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > . > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:260,deployability,contain,container,260,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:486,deployability,automat,automatically,486,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:683,deployability,depend,depending,683,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:713,deployability,automat,automatic,713,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:119,integrability,standardiz,standardized,119,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:683,integrability,depend,depending,683,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:119,interoperability,standard,standardized,119,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:324,interoperability,standard,standardised,324,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:615,interoperability,format,format,615,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:683,modifiability,depend,depending,683,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:763,modifiability,extens,extensive,763,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:683,safety,depend,depending,683,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:486,testability,automat,automatically,486,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:683,testability,depend,depending,683,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:713,testability,automat,automatic,713,"> > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > . > > > . > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > . > > . > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > . > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:268,deployability,contain,container,268,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:500,deployability,automat,automatically,500,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:707,deployability,depend,depending,707,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:737,deployability,automat,automatic,737,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:121,integrability,standardiz,standardized,121,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:707,integrability,depend,depending,707,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:121,interoperability,standard,standardized,121,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:338,interoperability,standard,standardised,338,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:639,interoperability,format,format,639,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:707,modifiability,depend,depending,707,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:787,modifiability,extens,extensive,787,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:707,safety,depend,depending,707,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:500,testability,automat,automatically,500,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:707,testability,depend,depending,707,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:737,testability,automat,automatic,737,"> > > > > Should this argument be added to `sc.read_visium` as well? That is, add a path to the tiff if it would be in a standardized place? > > > > . > > > > . > > > > yes that's a very good point actually. It could even make it easier for us to initialize the image container maybe? > > > . > > > . > > > I thought about that already - standardised places for the tiff would be `sample_id""_image.tif` and `image.tif`. I don't think we need to add an extra argument to `sc.read_visium`, couldn't it automatically add the path if it exists? > > . > > . > > good point, agree probably best solution, however one thing it's not given is the format of the file (could be tif or jpg, but potentially some else, depending on the lab). But an automatic search would be best, just not sure how extensive we can make it. > . > do you have an example where the image is a jpg? I can account for both tif and jpg, but I'm wondering if its worth it. collaborators that generated visium data sent me jpg",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:5,deployability,updat,update,5,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:75,deployability,automat,automatically,75,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:5,safety,updat,update,5,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:28,safety,test,test,28,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:5,security,updat,update,5,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:28,testability,test,test,28,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:75,testability,automat,automatically,75,"I've update the code to . - test that the file is actually a tiff image. - automatically add the path to the image to `adata.uns['spatial'][library_id]['metadata']['tissue_image_path']`. It's looking for a tiff or jpeg file with the name `""image""` or `library_id""_image""`. This should cover most cases hopefully?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:262,security,modif,modifications,262,I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:141,usability,user,user,141,I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:686,availability,consist,consistent,686,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:379,deployability,scale,scalefactors,379,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:750,deployability,contain,container,750,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:379,energy efficiency,scale,scalefactors,379,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:379,modifiability,scal,scalefactors,379,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:379,performance,scale,scalefactors,379,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:305,reliability,doe,doesn,305,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:349,safety,input,input,349,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:264,security,modif,modifications,264,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:532,testability,simpl,simply,532,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:143,usability,user,user,143,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:349,usability,input,input,349,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:532,usability,simpl,simply,532,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:686,usability,consist,consistent,686,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:713,usability,tool,tool,713,"> I think it would be fine to only cover the case of what `space ranger` actually outputs. I was thinking there could be an argument where the user manually passes an alternate path. This could be useful for cases where they've processed the image themselves some modifications to the image. space ranger doesn't output this image, as it's taken as input to assign spots and get scalefactors and metadata. This type of image is in the same folder just for chance in the 10x genomics dataset. . In the `read_visium` function I would simply add an argument to pass the path of the image, and basically just assign it to the `adata.uns` metadata. Otherwise just assign None. THis way it's consistent for the spatial tool whichlater uses it in the image container. It's also convenient to add it as argument so that `read_visium` could just be passed in that same way as it is now in `datasets.visium_sge`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:18,deployability,updat,update,18,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:101,interoperability,specif,specify,101,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:54,modifiability,paramet,parameter,54,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:18,safety,updat,update,18,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:18,security,updat,update,18,I've made a small update to add a `tissue_image_path` parameter to `read_visium` that you can use to specify the tissue image path to put in `adata.uns`,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:0,deployability,Updat,Updated,0,Updated the PR:. - renamed argument in `visium_sge` to `include_hires_tiff`. - renamed argument in `read_visium` to `source_image_path` and removed guessing of image file if `source_image_path` is None,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:0,safety,Updat,Updated,0,Updated the PR:. - renamed argument in `visium_sge` to `include_hires_tiff`. - renamed argument in `read_visium` to `source_image_path` and removed guessing of image file if `source_image_path` is None,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:0,security,Updat,Updated,0,Updated the PR:. - renamed argument in `visium_sge` to `include_hires_tiff`. - renamed argument in `read_visium` to `source_image_path` and removed guessing of image file if `source_image_path` is None,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:20,deployability,releas,release,20,"> Please also add a release note! sorry for the naive question, but how do I add a release note? As a comment in the PR? As a commit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:83,deployability,releas,release,83,"> Please also add a release note! sorry for the naive question, but how do I add a release note? As a comment in the PR? As a commit?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:116,deployability,releas,release-latest,116,"just mention this PR with brief description and your name here: https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst. nice! only one PR to go, thank you @hspitzer @ivirshup !",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:118,deployability,releas,release-latest,118,"> just mention this PR with brief description and your name here: https://github.com/theislab/scanpy/blob/master/docs/release-latest.rst. ok, done. I put it in the ""on master"" section",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1507:95,availability,error,errors,95,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:192,modifiability,inherit,inherit,192,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:95,performance,error,errors,95,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:184,reliability,doe,doesn,184,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:95,safety,error,errors,95,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:206,safety,Except,Exception,206,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:95,usability,error,errors,95,"The main change here is passing `None` instead of `0` to `total`, right? Also: this makes some errors with files still existing make much more sense. I had no idea `KeyboardInterrupt` doesn't inherit from `Exception`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:506,availability,error,errors,506,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:601,modifiability,inherit,inherit,601,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:683,modifiability,inherit,inherits,683,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:506,performance,error,errors,506,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:217,reliability,doe,doesn,217,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:593,reliability,doe,doesn,593,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:506,safety,error,errors,506,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:614,safety,Except,Exception,614,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:768,safety,except,exceptions,768,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:784,safety,except,exception-hierarchy,784,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:263,usability,user,user-images,263,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:386,usability,user,user-images,386,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:506,usability,error,errors,506,"Thanks for a quick response and the comments. > The main change here is passing None instead of 0 to total, right? It was actually setting it in the contructor, rather than assigning it to the tqdm object (the latter doesn't work). Here's before:. ![old](https://user-images.githubusercontent.com/46717574/100207740-3b88d880-2f08-11eb-882f-cae14be0837e.png). and after:. ![new](https://user-images.githubusercontent.com/46717574/100207756-3fb4f600-2f08-11eb-85f8-5938ff04572d.png). > Also: this makes some errors with files still existing make much more sense. I had no idea KeyboardInterrupt doesn't inherit from Exception. I didn't know that either, so I looked it up (it actually inherits from `BaseException` among other things:. https://docs.python.org/3/library/exceptions.html#exception-hierarchy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:84,deployability,updat,updating,84,"Just noticed the `?` at the end (both-cases), last commit should fix it (it was the updating), here's the final result:. ![newnew](https://user-images.githubusercontent.com/46717574/100208974-9c64e080-2f09-11eb-966e-fe168c2877f1.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:84,safety,updat,updating,84,"Just noticed the `?` at the end (both-cases), last commit should fix it (it was the updating), here's the final result:. ![newnew](https://user-images.githubusercontent.com/46717574/100208974-9c64e080-2f09-11eb-966e-fe168c2877f1.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:84,security,updat,updating,84,"Just noticed the `?` at the end (both-cases), last commit should fix it (it was the updating), here's the final result:. ![newnew](https://user-images.githubusercontent.com/46717574/100208974-9c64e080-2f09-11eb-966e-fe168c2877f1.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:139,usability,user,user-images,139,"Just noticed the `?` at the end (both-cases), last commit should fix it (it was the updating), here's the final result:. ![newnew](https://user-images.githubusercontent.com/46717574/100208974-9c64e080-2f09-11eb-966e-fe168c2877f1.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/issues/1508:332,deployability,API,API,332,"How I save plots is:. ```python. from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi. sc.pl.plotting_function(..., show=False). plt.savefig(""path/to/file.extension"", bbox_inches=""tight""). ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:345,deployability,releas,release,345,"How I save plots is:. ```python. from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi. sc.pl.plotting_function(..., show=False). plt.savefig(""path/to/file.extension"", bbox_inches=""tight""). ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:332,integrability,API,API,332,"How I save plots is:. ```python. from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi. sc.pl.plotting_function(..., show=False). plt.savefig(""path/to/file.extension"", bbox_inches=""tight""). ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:332,interoperability,API,API,332,"How I save plots is:. ```python. from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi. sc.pl.plotting_function(..., show=False). plt.savefig(""path/to/file.extension"", bbox_inches=""tight""). ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:213,modifiability,extens,extension,213,"How I save plots is:. ```python. from matplotlib import pyplot as plt. with plt.rc_context(): # Use this to set figure params like size and dpi. sc.pl.plotting_function(..., show=False). plt.savefig(""path/to/file.extension"", bbox_inches=""tight""). ```. I think how this argument works is one of the things we would change in a major API breaking release. @fidelram, would you add anything to this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:175,deployability,releas,release,175,"You could also not make this breaking by checking if there are any `/` in the string and appending `umap` or `violin` after the last `/`? Would be a bit messy, but quicker to release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:77,safety,detect,detect,77,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:77,security,detect,detect,77,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:366,security,control,controlling,366,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:366,testability,control,controlling,366,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:169,usability,behavi,behaviour,169,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:229,usability,behavi,behaviour,229,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:457,usability,user,user,457,"I don't want to do too much with string mangling. Now that mention trying to detect it though, I don't think I'd have anything against passing a `Path` to override this behaviour. We could also add a different argument with this behaviour – like `path` – then deprecate `save`, or at least passing a string to `save`. On the other hand, I wonder how much we gain by controlling the saving of a figure. Maybe the only way to save a figure should be from the user calling matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:235,usability,intuit,intuitive,235,I quite like the saving of figures as it means people can use scanpy who otherwise aren't as familiar with data science in python. Calling a function on an axis object or saving the last axis object that was is displayed is not always intuitive to new users.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:252,usability,user,users,252,I quite like the saving of figures as it means people can use scanpy who otherwise aren't as familiar with data science in python. Calling a function on an axis object or saving the last axis object that was is displayed is not always intuitive to new users.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:237,usability,intuit,intuitive,237,"> I quite like the saving of figures as it means people can use scanpy who otherwise aren't as familiar with data science in python. Calling a function on an axis object or saving the last axis object that was is displayed is not always intuitive to new users. How about adding a ""plotting cookbook"" section to the docs instead? `plt.rc_context` is such a neat trick (also beyond scanpy), but it wasn't obvious to me either (#1648). . Obligatory quote from the ""Zen of Python"":. ```. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:254,usability,user,users,254,"> I quite like the saving of figures as it means people can use scanpy who otherwise aren't as familiar with data science in python. Calling a function on an axis object or saving the last axis object that was is displayed is not always intuitive to new users. How about adding a ""plotting cookbook"" section to the docs instead? `plt.rc_context` is such a neat trick (also beyond scanpy), but it wasn't obvious to me either (#1648). . Obligatory quote from the ""Zen of Python"":. ```. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:510,usability,prefer,preferably,510,"> I quite like the saving of figures as it means people can use scanpy who otherwise aren't as familiar with data science in python. Calling a function on an axis object or saving the last axis object that was is displayed is not always intuitive to new users. How about adding a ""plotting cookbook"" section to the docs instead? `plt.rc_context` is such a neat trick (also beyond scanpy), but it wasn't obvious to me either (#1648). . Obligatory quote from the ""Zen of Python"":. ```. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:66,interoperability,specif,specifies,66,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:96,interoperability,specif,specified,96,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:314,interoperability,specif,specifies,314,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:7,usability,stop,stop,7,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:61,usability,user,user,61,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:309,usability,user,user,309,"Please stop forcing plots to have an unwanted prefix. When a user specifies a save filename the specified filename should ALWAYS be exactly the filename that is produced, nothing else. This applies to all scanpy outputs, and in fact the entire scanpy ""family"", it's fine to have a default value, but when the user specifies a filename that should be all the output is named. This should never have been implemented this way, and its extremely frustrating.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1509:124,availability,ping,ping,124,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:169,availability,error,error,169,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:22,deployability,releas,release,22,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:740,deployability,releas,release,740,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:718,energy efficiency,cool,cool,718,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:169,performance,error,error,169,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:169,safety,error,error,169,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:169,usability,error,error,169,"It looks like the new release breaks most of our usage from (at least) a change in arguments to `simplicial_set_embedding` (ping @Koncopd). <details>. <summary> Example error </summary>. ```pytb. n_epochs = 0 if maxiter is None else maxiter. > X_umap = simplicial_set_embedding(. X,. neighbors['connectivities'].tocoo(),. n_components,. alpha,. a,. b,. gamma,. negative_sample_rate,. n_epochs,. init_coords,. random_state,. neigh_params.get('metric', 'euclidean'),. neigh_params.get('metric_kwds', {}),. verbose=settings.verbosity > 3,. E TypeError: simplicial_set_embedding() missing 3 required positional arguments: 'densmap', 'densmap_kwds', and 'output_dens'. ```. </details>. It looks like there is also a lot of cool stuff in the new release!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:184,energy efficiency,cool,cool,184,This seems related to the new Densmap feature https://umap-learn.readthedocs.io/en/latest/densmap_demo.html (see https://www.biorxiv.org/content/10.1101/2020.05.12.077776v1). Would be cool to support it in scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:137,performance,content,content,137,This seems related to the new Densmap feature https://umap-learn.readthedocs.io/en/latest/densmap_demo.html (see https://www.biorxiv.org/content/10.1101/2020.05.12.077776v1). Would be cool to support it in scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:59,usability,learn,learn,59,This seems related to the new Densmap feature https://umap-learn.readthedocs.io/en/latest/densmap_demo.html (see https://www.biorxiv.org/content/10.1101/2020.05.12.077776v1). Would be cool to support it in scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:192,usability,support,support,192,This seems related to the new Densmap feature https://umap-learn.readthedocs.io/en/latest/densmap_demo.html (see https://www.biorxiv.org/content/10.1101/2020.05.12.077776v1). Would be cool to support it in scanpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:187,modifiability,paramet,parameters,187,"@gokceneraslan, have you tried `densmap`? I'm curious to hear someone's thoughts on it. I'm also wondering if adding it as a feature would be more complicated than adding a few pass-thru parameters to `sc.tl.umap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:147,safety,compl,complicated,147,"@gokceneraslan, have you tried `densmap`? I'm curious to hear someone's thoughts on it. I'm also wondering if adding it as a feature would be more complicated than adding a few pass-thru parameters to `sc.tl.umap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:147,security,compl,complicated,147,"@gokceneraslan, have you tried `densmap`? I'm curious to hear someone's thoughts on it. I'm also wondering if adding it as a feature would be more complicated than adding a few pass-thru parameters to `sc.tl.umap`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:0,usability,Close,Closed,0,Closed by #1601 and #1589,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1510:24,usability,help,help,24,"Hi @justinesjw,. As the help page you linked to suggests the function is called `scanpy.external.exporting.spring_project`. You could use:. ```. import scanpy.external as sce. sce.exporting.spring_project(adata, project_dir=...). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:23,usability,help,help,23,Noted. Thanks for your help!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/pull/1511:79,availability,cluster,clusters,79,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:287,availability,cluster,clusters,287,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:671,availability,consist,consistent,671,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:696,availability,cluster,clusters,696,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:79,deployability,cluster,clusters,79,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:287,deployability,cluster,clusters,287,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:696,deployability,cluster,clusters,696,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:753,deployability,updat,updated,753,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:241,energy efficiency,heat,heatmap,241,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:636,energy efficiency,heat,heatmap,636,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:753,safety,updat,updated,753,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:753,security,updat,updated,753,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:403,usability,user,user-images,403,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:524,usability,user,user-images,524,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:671,usability,consist,consistent,671,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:723,usability,help,helpful,723,"```python. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). marker_genes_dict = {. ""1"": [""GNLY"", ""NKG7""],. ""0"": [""CD3D""],. ""2"": [""CD79A"", ""MS4A1""],. ""4"": [""FCGR3A""],. ""3"": [""FCER1A""],. }. sc.pl.heatmap(. pbmc,. marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```. before:. ![image](https://user-images.githubusercontent.com/25887487/100453873-0e7d2700-30bc-11eb-9451-0240f6170e2f.png). after:. ![image](https://user-images.githubusercontent.com/25887487/100453885-15a43500-30bc-11eb-9b95-66d0881aad31.png). as you can see, heatmap colors for rows (genes) is consistent with columns (clusters) . @wkopp is this helpful? notebook still to be updated",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:63,availability,cluster,clusters,63,"One thing to note:. if the categories of the groupby variable (clusters in this case) don't match up with the categories in the marker_genes_dict, there will be no matching if colors between rows and columns. This is what also happens in the tutorial, where. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. while the clusters are numbers (""1"", ""2"" etc.). We could consider throwing a warning in that case, but I don't think it's necessary.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:419,availability,cluster,clusters,419,"One thing to note:. if the categories of the groupby variable (clusters in this case) don't match up with the categories in the marker_genes_dict, there will be no matching if colors between rows and columns. This is what also happens in the tutorial, where. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. while the clusters are numbers (""1"", ""2"" etc.). We could consider throwing a warning in that case, but I don't think it's necessary.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:63,deployability,cluster,clusters,63,"One thing to note:. if the categories of the groupby variable (clusters in this case) don't match up with the categories in the marker_genes_dict, there will be no matching if colors between rows and columns. This is what also happens in the tutorial, where. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. while the clusters are numbers (""1"", ""2"" etc.). We could consider throwing a warning in that case, but I don't think it's necessary.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:419,deployability,cluster,clusters,419,"One thing to note:. if the categories of the groupby variable (clusters in this case) don't match up with the categories in the marker_genes_dict, there will be no matching if colors between rows and columns. This is what also happens in the tutorial, where. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. while the clusters are numbers (""1"", ""2"" etc.). We could consider throwing a warning in that case, but I don't think it's necessary.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:53,modifiability,variab,variable,53,"One thing to note:. if the categories of the groupby variable (clusters in this case) don't match up with the categories in the marker_genes_dict, there will be no matching if colors between rows and columns. This is what also happens in the tutorial, where. marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. while the clusters are numbers (""1"", ""2"" etc.). We could consider throwing a warning in that case, but I don't think it's necessary.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:37,availability,Cluster,Cluster,37,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:176,availability,Cluster,Cluster,176,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:284,availability,Cluster,Cluster,284,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:305,availability,Cluster,Cluster,305,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:360,availability,cluster,clusters,360,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:37,deployability,Cluster,Cluster,37,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:176,deployability,Cluster,Cluster,176,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:284,deployability,Cluster,Cluster,284,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:305,deployability,Cluster,Cluster,305,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:360,deployability,cluster,clusters,360,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:57,energy efficiency,green,green,57,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:73,energy efficiency,heat,heatmap,73,"I'm confused by the figure above. In Cluster 2 (shown in green below the heatmap) the marker gene that is coming up most prominently is CD3D, which was defined as a marker for Cluster 0, though. The color code on the right seems correct, but why is CD3D most prominently expressed in Cluster 2 and not in Cluster 0? The same seems to be the case for the other clusters. Or were the marker genes perhaps just mislabelled?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:125,availability,cluster,clusters,125,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:254,availability,cluster,clusters,254,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:300,availability,cluster,clusters,300,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:468,availability,cluster,clusters,468,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:125,deployability,cluster,clusters,125,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:254,deployability,cluster,clusters,254,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:300,deployability,cluster,clusters,300,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:468,deployability,cluster,clusters,468,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:309,modifiability,variab,variable,309,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:402,reliability,Doe,Does,402,"Yeah the marker assignments here are random, that might be a bit confusing indeed. The only point is that the colors for the clusters (columns) match with the *names* of the marker gene lists (rows). So if, in an actual dataset, you now name the correct clusters ""T cells"", ""B cells"" etc. in you obs.clusters variable, and match those names with your marker gene dict keys, everything will match up. . Does that make sense? I just didn't go through annotations of the clusters here, that would be a bit tedious. But try it out on your own (correctly annotated) anndata object if you'd like.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:122,availability,cluster,cluster,122,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:177,availability,cluster,cluster,177,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:321,availability,cluster,clusters,321,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:122,deployability,cluster,cluster,122,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:177,deployability,cluster,cluster,177,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:321,deployability,cluster,clusters,321,"Yes, the colorcodes are matching now and the confusion about the marker genes is just because of with mislabelling marker-cluster associations. You can find the correct markers-cluster associations from cross-checking with umap figures, e.g. ```{python}. sc.pl.umap(pbmc, color=[""GNLY"",'FCER1A',""CD3D"",""CD79A"",""FCGR3A"", ""clusters""]). ```. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:420,availability,error,error,420,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:71,energy efficiency,heat,heatmap,71,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:420,performance,error,error,420,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:420,safety,error,error,420,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:47,testability,context,context,47,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:420,usability,error,error,420,"exactly! also this makes a lot of sense in the context of the reversed heatmap (where keys of the mapping are plotted as column annotation). . This is also particularly useful if you have 2 annotations `cluster1=['1','2','3']` and `cluster2=['foo','bar']`, and you want to check for. ```python. markers={. 	""foo"":[""gene1"", ""gene2""],. 	""bar"":[""gene3""]. }. ```. but with respect to `cluster1`. I would have just thrown an error but this is a much more elegant solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:71,availability,cluster,cluster,71,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:534,availability,cluster,clusters,534,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:671,availability,cluster,clusters,671,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:886,availability,cluster,clusters,886,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:71,deployability,cluster,cluster,71,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:534,deployability,cluster,clusters,534,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:671,deployability,cluster,clusters,671,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:886,deployability,cluster,clusters,886,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:824,energy efficiency,heat,heatmap,824,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:162,usability,user,user-images,162,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:311,usability,user,user-images,311,"Okay true that's not that hard. So here a better example, with correct cluster + marker gene combinations:. before:. ![Screenshot 2020-11-27 at 15 48 18](https://user-images.githubusercontent.com/32548783/100460796-15aa3200-30c8-11eb-94c7-1dc472b34d54.png). after:. ![Screenshot 2020-11-27 at 15 47 16](https://user-images.githubusercontent.com/32548783/100460831-278bd500-30c8-11eb-96a8-f8bcccdcdfb5.png). and code to reproduce it:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added=""clusters"", resolution=0.5). sc.pl.umap(. pbmc,. color=[. ""GNLY"",. ""FCER1A"",. ""CD3D"",. ""CD79A"",. ""FCGR3A"",. ""NKG7"",. ""CD79A"",. ""MS4A1"",. ""clusters"",. ],. ). marker_genes_dict = {. ""3"": [""GNLY"", ""NKG7""],. ""1"": [""FCER1A""],. ""2"": [""CD3D""],. ""0"": [""FCGR3A""],. ""4"": [""CD79A"", ""MS4A1""],. }. sc.pl.heatmap(. adata=pbmc,. var_names=marker_genes_dict,. groupby=""clusters"",. vmin=-2,. vmax=2,. cmap=""RdBu_r"",. dendrogram=True,. swap_axes=True,. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:31,deployability,fail,failed,31,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:31,reliability,fail,failed,31,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:25,safety,test,tests,25,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:25,testability,test,tests,25,"Hi! not sure why the two tests failed, I don't think it's related to my edits",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:61,safety,test,test,61,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:82,safety,test,test,82,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:315,safety,test,tests,315,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:61,testability,test,test,61,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:82,testability,test,test,82,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:315,testability,test,tests,315,"@LisaSikkema, no worries there's been some flakiness of that test. Can this get a test case like ? Maybe even two, one where groups match, one where they don't? I'm thinking something that calls `save_and_compare_images`, like https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L272",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:69,safety,detect,detected,69,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:152,safety,test,test,152,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:266,safety,test,test,266,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:328,safety,test,tests,328,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:69,security,detect,detected,69,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:152,testability,test,test,152,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:266,testability,test,test,266,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:328,testability,test,tests,328,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:240,usability,help,help,240,"Thanks for looking at this... it is surprising that this bug was not detected earlier. . I looked at the code and looks fine but, I would like to add a test. @LisaSikkema can you check this? If this is too much trouble I can do it or I can help you because the plot test are difficult as they require similar setup as in the CI tests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:54,safety,test,test,54,"Yes would be happy to look into it and come up with a test! I have no experience with the testing code yet though, so might take me a while to figure out how to write it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:90,safety,test,testing,90,"Yes would be happy to look into it and come up with a test! I have no experience with the testing code yet though, so might take me a while to figure out how to write it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:54,testability,test,test,54,"Yes would be happy to look into it and come up with a test! I have no experience with the testing code yet though, so might take me a while to figure out how to write it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:90,testability,test,testing,90,"Yes would be happy to look into it and come up with a test! I have no experience with the testing code yet though, so might take me a while to figure out how to write it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:70,usability,experien,experience,70,"Yes would be happy to look into it and come up with a test! I have no experience with the testing code yet though, so might take me a while to figure out how to write it up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:58,availability,error,errors,58,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:375,deployability,fail,fail,375,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:58,performance,error,errors,58,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:390,performance,time,time,390,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:375,reliability,fail,fail,375,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:58,safety,error,errors,58,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:90,safety,test,tests,90,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:100,safety,test,test,100,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:262,safety,test,tests,262,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:303,safety,test,test,303,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:327,safety,test,tests,327,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:354,safety,test,test,354,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:596,safety,test,tests,596,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:90,testability,test,tests,90,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:100,testability,test,test,100,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:262,testability,test,tests,262,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:303,testability,test,test,303,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:327,testability,test,tests,327,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:354,testability,test,test,354,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:596,testability,test,tests,596,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:58,usability,error,errors,58,"first try the following and check that you don't have any errors. . ```. cd scanpy/scanpy/tests. py.test test_plotting.py. ```. If that is the case, you can go to this line: https://github.com/theislab/scanpy/blob/02fc946a8ce3c2e456dbc6e026ee068734f11e1e/scanpy/tests/test_plotting.py#L36 and add a new test. I usually run the tests after adding the new test case which will fail the first time. But, it generates an image to compare. Then I copy the new image from `./figures/` to `./_images/` and add it to git. Off course you want to check that the image is what you expect. If you re-run the tests they should work now. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:138,performance,time,time,138,"thanks for making the test, was planning to do it today (Friday = scanpy day)! Read through your code, so now I'll know how to do it next time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:22,safety,test,test,22,"thanks for making the test, was planning to do it today (Friday = scanpy day)! Read through your code, so now I'll know how to do it next time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:22,testability,test,test,22,"thanks for making the test, was planning to do it today (Friday = scanpy day)! Read through your code, so now I'll know how to do it next time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:32,testability,plan,planning,32,"thanks for making the test, was planning to do it today (Friday = scanpy day)! Read through your code, so now I'll know how to do it next time.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1512:200,deployability,log,logic,200,"the problem this PR try to address is the following. We construct the spatial graph and put keys of obsp in `adata.uns[""spatial""]`. Problem is that there is also the library id in case of Visium. The logic before would work only if there was a single key in `adata.uns[""spatial""]`. Now instead, we need to account for `adata.uns[""spatial""]` being empty, and also having `adata.uns[""spatial""][""connectivities_key""]` or `adata.uns[""spatial""][""distances_key""]`. It doesn't look really good because of the hard coded keys. Any suggestion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:462,reliability,doe,doesn,462,"the problem this PR try to address is the following. We construct the spatial graph and put keys of obsp in `adata.uns[""spatial""]`. Problem is that there is also the library id in case of Visium. The logic before would work only if there was a single key in `adata.uns[""spatial""]`. Now instead, we need to account for `adata.uns[""spatial""]` being empty, and also having `adata.uns[""spatial""][""connectivities_key""]` or `adata.uns[""spatial""][""distances_key""]`. It doesn't look really good because of the hard coded keys. Any suggestion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:200,safety,log,logic,200,"the problem this PR try to address is the following. We construct the spatial graph and put keys of obsp in `adata.uns[""spatial""]`. Problem is that there is also the library id in case of Visium. The logic before would work only if there was a single key in `adata.uns[""spatial""]`. Now instead, we need to account for `adata.uns[""spatial""]` being empty, and also having `adata.uns[""spatial""][""connectivities_key""]` or `adata.uns[""spatial""][""distances_key""]`. It doesn't look really good because of the hard coded keys. Any suggestion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:200,security,log,logic,200,"the problem this PR try to address is the following. We construct the spatial graph and put keys of obsp in `adata.uns[""spatial""]`. Problem is that there is also the library id in case of Visium. The logic before would work only if there was a single key in `adata.uns[""spatial""]`. Now instead, we need to account for `adata.uns[""spatial""]` being empty, and also having `adata.uns[""spatial""][""connectivities_key""]` or `adata.uns[""spatial""][""distances_key""]`. It doesn't look really good because of the hard coded keys. Any suggestion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:200,testability,log,logic,200,"the problem this PR try to address is the following. We construct the spatial graph and put keys of obsp in `adata.uns[""spatial""]`. Problem is that there is also the library id in case of Visium. The logic before would work only if there was a single key in `adata.uns[""spatial""]`. Now instead, we need to account for `adata.uns[""spatial""]` being empty, and also having `adata.uns[""spatial""][""connectivities_key""]` or `adata.uns[""spatial""][""distances_key""]`. It doesn't look really good because of the hard coded keys. Any suggestion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:166,deployability,log,logic,166,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:166,safety,log,logic,166,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:166,security,log,logic,166,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:166,testability,log,logic,166,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:411,testability,plan,planning,411,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:371,usability,help,help,371,"Question for this, what heuristics have you tried? My guess would be that `min(distances_between_points) / 3` should be fine for an upper bound. Second, I think this logic is a little convoluted, and I don't know that `library_id` will always be associated with visium only. Would a better check be for `[""metadata""][""software_version""]` or something like that? It might help for me to know what exactly you're planning on putting in the `""spatial""` entry.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:899,deployability,log,logic,899,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:472,energy efficiency,measur,measure,472,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:447,interoperability,coordinat,coordinates,447,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:521,interoperability,coordinat,coordinates,521,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:899,safety,log,logic,899,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1827,safety,except,except,1827,"according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances_key""]`. It could also be though that it's empty altogether (e.g. `spatial_connecitivty`) has not been called yet. Then, it should still set `library_id=None`. > It might help for me to know what exactly you're planning on putting in the ""spatial"" entry. 1 milllion dollars question 😅 , for now I would say only `[""connectivities_key"", ""distances_key""]`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:899,security,log,logic,899,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:899,testability,log,logic,899,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2211,testability,plan,planning,2211,"according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances_key""]`. It could also be though that it's empty altogether (e.g. `spatial_connecitivty`) has not been called yet. Then, it should still set `library_id=None`. > It might help for me to know what exactly you're planning on putting in the ""spatial"" entry. 1 milllion dollars question 😅 , for now I would say only `[""connectivities_key"", ""distances_key""]`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:49,usability,clear,clear,49,"all very good points, and I don't think I have a clear solution, it's more that we have to decide how to go about this:. > Question for this, what heuristics have you tried? My guess would be that min(distances_between_points) / 3 should be fine for an upper bound. this indeed could be solved, but we still would have to set this heuristics differently according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1845,usability,Stop,StopIteration,1845,"according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances_key""]`. It could also be though that it's empty altogether (e.g. `spatial_connecitivty`) has not been called yet. Then, it should still set `library_id=None`. > It might help for me to know what exactly you're planning on putting in the ""spatial"" entry. 1 milllion dollars question 😅 , for now I would say only `[""connectivities_key"", ""distances_key""]`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2171,usability,help,help,2171,"according to the spatial data type in question. E.g. for visium `size=1` is correct, because coordinates are in pixel measure. In the dataset I have now (seqFISH) the coordinates are essentially z-score and so would have to change for instance to the one you proposed. However, why would we want to have `circle` at all in that t case, and not just scatterplot? Since there is no real notion of size, I think a scatterplot is actually more appropriate. We discussed this already but back then we didn't have this example. > Second, I think this logic is a little convoluted, and I don't know that library_id will always be associated with visium only. Would a better check be for [""metadata""][""software_version""] or something like that? It definitely is, there might be a better solution but I couldn't come up with it. The problem stems in the fact that we have a `library_id` key in `adata.uns[""spatial""]`. In `spatial` we also put this. ```python. {'connectivities_key': 'spatial_connectivities',. 'distances_key': 'spatial_distances',. 'params': {'n_neighbors': 6, 'coord_type': None, 'radius': None}}. ``` . this is needed for plotting. The default in `sc.pl.spatial` now is that if library_id is `_empty`, then it iteratively search for some keys in `adata.uns[""spatial""]`. ```python. try: # check if key is empty. spatial_data = adata.uns['spatial']. library_id = next(. (. i. for i in spatial_data.keys(). if i not in [""connectivities_key"", ""distances_key""]. ). ). except (KeyError, StopIteration) as e:. 	library_id = None. ```. The point is that it should only assign whatever key it finds that is not `[""connectivities_key"", ""distances_key""]`. It could also be though that it's empty altogether (e.g. `spatial_connecitivty`) has not been called yet. Then, it should still set `library_id=None`. > It might help for me to know what exactly you're planning on putting in the ""spatial"" entry. 1 milllion dollars question 😅 , for now I would say only `[""connectivities_key"", ""distances_key""]`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:115,integrability,transform,transform,115,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:6,interoperability,coordinat,coordinates,6,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:85,interoperability,coordinat,coordinates,85,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:115,interoperability,transform,transform,115,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:230,interoperability,coordinat,coordinates,230,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:436,modifiability,paramet,parameters,436,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:198,safety,compl,completely,198,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:198,security,compl,completely,198,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:968,usability,stop,stop,968,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1221,usability,user,user,1221,"> the coordinates are essentially z-score. I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? -------------------. For spatial neighbour information, I feel like this should go in a separate top level key in `uns`. For example, with `""params""`, it's not obvious to me that the parameters in `""spatial""` should only refer to how neighbours were computed. Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. > for now I would say only [""connectivities_key"", ""distances_key""]. I think once you start adding stuff, it's easy to add more, and this code will stop working if that happens. For example, the `""params""` key. ------------. For figuring out which case this is:. * If no library key was provided:. * If there is only one key, use that one. * If there is more than one key, use none, and warn that the user should pass this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:719,deployability,contain,contains,719,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1580,deployability,automat,automatically,1580,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1864,deployability,log,logic,1864,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:78,energy efficiency,current,current,78,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:333,integrability,wrap,wrap,333,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:456,integrability,transform,transform,456,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:996,integrability,wrap,wrap,996,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1777,integrability,coupl,couple,1777,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:426,interoperability,coordinat,coordinates,426,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:456,interoperability,transform,transform,456,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:571,interoperability,coordinat,coordinates,571,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:685,interoperability,share,share,685,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:728,interoperability,coordinat,coordinates,728,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1186,interoperability,coordinat,coordinate,1186,"ns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1365,interoperability,coordinat,coordinate,1365,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1777,modifiability,coupl,couple,1777,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:206,reliability,doe,does,206,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:168,safety,except,exception,168,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:539,safety,compl,completely,539,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1787,safety,test,tests,1787,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1841,safety,review,review,1841,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1864,safety,log,logic,1864,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:539,security,compl,completely,539,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1864,security,log,logic,1864,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:326,testability,simpl,simply,326,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1580,testability,automat,automatically,1580,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1777,testability,coupl,couple,1777,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1787,testability,test,tests,1787,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1841,testability,review,review,1841,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1864,testability,log,logic,1864,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2314,testability,simpl,simply,2314,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:86,usability,statu,status,86,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:326,usability,simpl,simply,326,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:674,usability,user,users,674,"Thanks for bearing with me Isaac 😅 🙏 took some of your suggestions and here's current status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1078,usability,user,user,1078,"rrent status:. - reverted back to look for `library_id` in spatial, but still added the exception that `adata.uns[""spatial""]` does not exist. This is in order to use `sc.pl.spatial` with non-visium data. - if that's the case, then spatial should simply wrap embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {..",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1873,usability,clear,clearer,1873,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2314,usability,simpl,simply,2314,"p embedding. This also refers to your point. 	> I'm not totally sure what this means. The coordinates have been z-score transform across each axis? How is this useful? In particular, how is it useful to completely replace the original coordinates with this? 	this is very likely to happen for anything that it's not visium. In that case, users will share already processed data that contains coordinates in some type of system, and this is the case for whatever processing they had to undertake (would suggest you to have a look at https://github.com/spacetx/starfish for examples of those processing steps.). Anyway, in short, it's much easier for us to just wrap embedding in that case, and I also think it's more correct cause then is the user to choose whatever heuristics they want for point sizes. - fixed a problem in #1534 , that is that the coordinate systems in non-visium has bottom left origin (whereas in visium is top-left, which makes sense because it's in image pixel coordiantes). For this reason, I added the y coordinate inversion in `sc.pl.spatial`, and only in the case where visium is selected, but with img_key = None. Note that this happens because if an img is plotted (before the spots with `circle`), then the origin automatically swap. But if `img_key` is None, then it reverts to default (bottom left). This made it easier as I could remove it from `def _get_data_points` and from `utils._get_edges`. Also added couple of tests for this case. This should be ready for another review, let me know if logic is clearer or I could add more comments in code. re. > Can the spatial neighbours be based off multiple library ids? If so, could you have:. ```python. uns = {. ""spatial"": {. ""library1"": {...},. ""library2"": {...},. ... },. ""spatial_neighbors"": {. ""library_ids"": [""library1"", ...],. ""connectivities_key"": ...,. ""distances_key"": ...,. ""params"": {...},. },. }. ```. yes indeed, I will change all occurrences in squidpy so that `sc.pl.spatial` can simply work as before.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:324,energy efficiency,current,current,324,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:653,integrability,wrap,wraps,653,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:252,interoperability,coordinat,coordinates,252,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:393,interoperability,coordinat,coordinates,393,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:466,interoperability,coordinat,coordinates,466,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:532,interoperability,coordinat,coordinates,532,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:737,interoperability,specif,specified,737,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:924,interoperability,coordinat,coordinates,924,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:605,usability,support,support,605,"> Do you think you could provide me with some example objects that are giving you trouble? you can take any `sc.datasets.visium_sge` and play around with inverting/not inverting second axis,and plotting using `sc.pl.spatial` or `sc.pl.embedding` where coordinates are in `adata.obsm[""coords""]`. I'll give another summary on current situation and goals:. **Type of spatial data**. 1. data with coordinates centered bottom left and no image (non visium). 2. data with coordinates centered top left and no image (visium). 3. data with coordinates centered top left and image (visium). `sc.pl.spatial` should support all of the above cases. In all cases it wraps embedding but in 1. it uses scatterplot, in 2. and 3. it uses circles (with a specified radius, present only in visium). The inversion is needed in case 2., because in case 3. this is already handled by the image axis plot. My solution for this is to pass inverted coordinates for y axis in 2. to `embedding`, so that everything can be handled by the function independently. . What do you think is a good way to go about this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:482,deployability,api,api,482,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:608,deployability,api,api,608,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:482,integrability,api,api,482,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:608,integrability,api,api,608,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:482,interoperability,api,api,482,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:608,interoperability,api,api,608,"Thanks for the new explanation, this makes much more sense to me now. ----------------------------. For case 1, when there is no image, what is the advantage to using `sc.pl.spatial` over just `sc.pl.embedding`? Also what about non-visium data with an image? -----------------------------. For case 2, I think there are two options. You can plot a blank image of the correct size, or you could invert the y axis manually with something like [`Axes.set_ylim`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.set_ylim.html#matplotlib.axes.Axes.set_ylim) or [`Axes.invert_yaxis`](https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.invert_yaxis.html#matplotlib.axes.Axes.invert_yaxis). I believe this is what `Axes.imshow` is doing internally (see `mpl.image.AxesImage.set_extent`).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:766,availability,mask,mask,766,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:689,deployability,observ,observation,689,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:813,deployability,probe,probes,813,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:836,deployability,observ,observation,836,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1217,deployability,build,building,1217,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1256,deployability,contain,container,1256,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:919,integrability,abstract,abstract,919,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1057,integrability,sub,subcellular,1057,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:743,interoperability,specif,specify,743,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:919,modifiability,abstract,abstract,919,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:894,performance,content,content,894,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:964,performance,content,content,964,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1124,performance,content,content,1124,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:295,safety,test,tests,295,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1029,safety,compl,complicated,1029,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1029,security,compl,complicated,1029,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:34,testability,understand,understand,34,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:295,testability,test,tests,295,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:502,testability,simpl,simple,502,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:689,testability,observ,observation,689,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:836,testability,observ,observation,836,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:848,testability,unit,units,848,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:64,usability,clear,clear,64,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:216,usability,user,user,216,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:447,usability,user,user,447,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:502,usability,simpl,simple,502,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:733,usability,user,user,733,"thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. So now by default everything that calls spatial inverts y axis. I also added two lines in the doc to clarify for user. I think this account for all the cases above, which are also presents in tests. > For case 1, when there is no image, what is the advantage to using sc.pl.spatial over just sc.pl.embedding? indeed none, but I still like that user could use `sc.pl.spatial` which in that case is a simple call `sc.pl.embedding(adata, basis=""spatial"", **kwargs)`. > Also what about non-visium data with an image? in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot) unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units (e.g see [this](https://www.biorxiv.org/content/10.1101/800748v2.abstract) and [this](https://www.biorxiv.org/content/10.1101/2020.02.12.945345v1) paper). It can be also more complicated if the data has subcellular resolution, like [this](https://science.sciencemag.org/content/361/6401/eaar7042). For all these cases, we'll rely on Napari, I'm in the process of building a class that maps anndata+img container to napari https://github.com/theislab/squidpy/pull/184",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:685,availability,mask,mask,685,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:270,deployability,observ,observation,270,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:732,deployability,probe,probes,732,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:755,deployability,observ,observation,755,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:555,interoperability,coordinat,coordinates,555,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:662,interoperability,specif,specify,662,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:406,safety,reme,remember,406,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:36,testability,understand,understand,36,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:270,testability,observ,observation,270,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:755,testability,observ,observation,755,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:767,testability,unit,units,767,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:66,usability,clear,clear,66,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:173,usability,tool,tools,173,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:652,usability,user,user,652,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:788,usability,user,user,788,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:869,usability,workflow,workflow,869,"> thank you for bearing with me 😅 I understand I should have been clear like that from beginning, sorry. No worries! I think communicating about the ideas we have for these tools can be fraught. > in that case, we essentially don't strictly have a direct mapping to our observation uni (i.e. cell/spot). I don't think this is the case. . First, I believe there are non-visium grid based spatial methods (I remember seeing a product page for one, but can't find it atm). Second, I think you don't need segmentation info to use this function. You just need coordinates (probably derived from segmentation) and possibly an image. Like this:. > unless the user also specify a segmentation mask or some other way of annotating molecular probes in the image to observation units. But I think a user already having done the segmentation, then coming to scanpy is a reasonable workflow.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:108,availability,sla,slack,108,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1623,availability,operat,operation,1623,"ge. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2754,availability,avail,available,2754,"0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3005,availability,slo,slows,3005,"present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3011,availability,down,down,3011,"nt in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>De",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:27,deployability,version,version,27,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:348,deployability,scale,scaled,348,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1043,deployability,scale,scalef,1043,"'s the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. ------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1098,deployability,scale,scalefactors,1098,"rom slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is ca",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1196,deployability,scale,scalef,1196,"g_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3312,deployability,scale,scale,3312,"ll trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3362,deployability,fail,failing,3362,"ee following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but inve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4256,deployability,scale,scale,4256,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:348,energy efficiency,scale,scaled,348,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1043,energy efficiency,scale,scalef,1043,"'s the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. ------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1098,energy efficiency,scale,scalefactors,1098,"rom slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is ca",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1196,energy efficiency,scale,scalef,1196,"g_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2459,energy efficiency,draw,drawn,2459,"image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot shoul",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3312,energy efficiency,scale,scale,3312,"ll trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4256,energy efficiency,scale,scale,4256,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4766,energy efficiency,current,current,4766,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:27,integrability,version,version,27,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3281,integrability,event,eventually,3281," with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `cir",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:355,interoperability,coordinat,coordinate,355,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:796,interoperability,coordinat,coordinate,796,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2836,interoperability,coordinat,coordinates,2836,"ubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubuserconte",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3484,interoperability,coordinat,coordinates,3484,"’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4369,interoperability,coordinat,coordinate,4369,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4664,interoperability,coordinat,coordinate,4664,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:27,modifiability,version,version,27,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:348,modifiability,scal,scaled,348,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:861,modifiability,scal,scaling,861,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1043,modifiability,scal,scalef,1043,"'s the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. ------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1098,modifiability,scal,scalefactors,1098,"rom slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is ca",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1196,modifiability,scal,scalef,1196,"g_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3312,modifiability,scal,scale,3312,"ll trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4256,modifiability,scal,scale,4256,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:348,performance,scale,scaled,348,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1043,performance,scale,scalef,1043,"'s the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. ------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1098,performance,scale,scalefactors,1098,"rom slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is ca",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1196,performance,scale,scalef,1196,"g_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3312,performance,scale,scale,3312,"ll trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4256,performance,scale,scale,4256,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:108,reliability,sla,slack,108,"@ivirshup here's the final version, I think it's the best compromise wrt what we discussed (i'll quote from slack the following points). > All image handling moved into the spatial function, e.g. `img_key`, `crop_coord`, `alpha_img`, `bw`, and `library_id` don’t get passed to embedding. Instead just an image array gets passed, potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2754,reliability,availab,available,2754,"0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3005,reliability,slo,slows,3005,"present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3362,reliability,fail,failing,3362,"ee following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but inve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4208,reliability,doe,does,4208,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2754,safety,avail,available,2754,"0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3354,safety,test,test,3354,"axis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4841,safety,test,tests,4841,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2754,security,availab,available,2754,"0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4601,security,modif,modified,4601,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3354,testability,test,test,3354,"axis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3550,testability,simpl,simply,3550,"uld be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments nee",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4450,testability,simpl,simply,4450,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4841,testability,test,tests,4841,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1322,usability,user,user-images,1322," potentially also a scaled coordinate array as basis. this is partially addressed, what is now passed to embedding is the image and a bunch of args that are though relevant to the image itself (so nothing to do with spatial). That is:. ```python. img: Union[np.ndarray, None, Empty] = None, # the image. cmap_img: Optional[str] = None, # cmap for ax.imshow. alpha_img: Optional[float] = 1.0, # alpha for the image. crop_coord: Tuple[int, int, int, int] = None, # crop coordinate for the image. scale_basis: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1826,usability,user,user-images,1826,"s: Optional[float] = None, # scaling of adata.obsm[basis] wrt to image. ```. This for example allows to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2055,usability,behavi,behaviour,2055,"s[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.embedding(. adata,. color=""leiden"",. scale_basis=scalef,. img=img,. basis=""spatial"",. size=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:2232,usability,behavi,behaviour,2232,"=10,. groups=[""0""],. ). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686565-d9f71980-41e8-11eb-8636-27dd4b24fec1.png). </details>. Note that if I was using source image (veryhigh res) I wouldn't need the scale_basis arg (default to None). Also note that in this case the scatterplot is `scatter` and not `circles`. The same operation with spatial would look like this (and here it would be `circles`):. ```python. sc.pl.spatial(adata, color=""leiden"", groups=[""0""]). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102686727-cc8e5f00-41e9-11eb-8d61-5c53700b39d7.png). </details>. Finally, all the image processing part is removed from embedding and only present in spatial. --------------------. > No behaviour changes in embedding if the basis is called ""spatial"" vs anything else, this should be triggered by calling the spatial function. this is addressed, embedding changes behaviour only if img is passed, but has nothing to do with spatial, there is a small trick, and has to do with `ax.invert_yaxis()`. See following point. --------------------. > When spatial is called, it’s always shapes being drawn on an image. If there isn’t an image passed, an empty image would be generated. There would be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3550,usability,simpl,simply,3550,"uld be no scatter plot case here. I played around with this and decided to go against. Here's the following reasons. - if no img is passed, then we should assume that also no `scale_basis` is provided/available. Thus, the empty img to be created has to be of the size of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments nee",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:3815,usability,user,user-images,3815,"of the spatial coordinates system. In the case of visium (but would be even worse for larger field of views) the ""blank source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4047,usability,user,user-images,4047,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4450,usability,simpl,simply,4450,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4457,usability,support,support,4457,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4774,usability,behavi,behaviour,4774,"source image"" would be very often a 10k * 10k empry array. This slows down the plotting and create an unneccesary large object. - if no img is passed, there really shouldn't be any need for using `circles` instead of `scatter` , since there is no notion of ""spot radius"" or ""spot size"" (this was my first idea since the very beginning, but eventually agreed to still use scale factor. This is also the reason why test is failing with empty visium). However, if no img is passed, when calling spatial the scatterplot should still have inverted coordinates (because we assume origin to be top left). I ended up simply setting `img = _empty` and adding it in embedding:. ```python. if img is _empty:. 	ax.invert_yaxis(). ```. This is the behviour. ```python. sc.pl.embedding(adata, color=""leiden"", basis=""spatial""). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687092-e1b8bd00-41ec-11eb-9970-4a9b98a9e68f.png). </details>. ```python. sc.pl.spatial(adata, color=""leiden"", img_key=None). ```. <details>. <summary>Details</summary>. ![image](https://user-images.githubusercontent.com/25887487/102687110-feed8b80-41ec-11eb-9063-3c3167c9b6b7.png). </details>. ----------------. TO summarize, what `sc.pl.spatial` does is:. - if an image is present, process and scale accordingly and use `circles` instead of `scatter`. - if an image is not present, use `scatter` but invert coordinate since expected origin is top left. Furthermore, `sc.pl.embedding` now simply support the possibility to add an image in the background and accepts the relevant arguments needed for the image to be displayed correctly and modified, as well as a scale_basis argument to match the image coordinate if needed. That's it, looking forward to hear what are your thoughts and if you agree with current behaviour I'll go on and changing the docs as well as writing more tests (especially for first example where `groups` is used, where the background color is different)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1012,deployability,scale,scalef,1012,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1067,deployability,scale,scalefactors,1067,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1164,deployability,scale,scalef,1164,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1012,energy efficiency,scale,scalef,1012,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1067,energy efficiency,scale,scalefactors,1067,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1164,energy efficiency,scale,scalef,1164,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:685,integrability,interfac,interface,685,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:685,interoperability,interfac,interface,685,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:685,modifiability,interfac,interface,685,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1012,modifiability,scal,scalef,1012,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1067,modifiability,scal,scalefactors,1067,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1164,modifiability,scal,scalef,1164,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1012,performance,scale,scalef,1012,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1067,performance,scale,scalefactors,1067,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1164,performance,scale,scalef,1164,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1432,safety,test,tests,1432,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:142,security,modif,modify,142,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1432,testability,test,tests,1432,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:645,usability,prefer,prefer,645,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:678,usability,user,users,678,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1252,usability,user,user-images,1252,"> Can scale_factor be removed as an argument to embedding, and instead have that handling occur inside spatial? no, otherwise I would have to modify the adata or pass a copy, and this would break other functionalities (first that come to mind, categorical colors saved in adata.uns). > Otherwise we assume it's already an array, and make sure it's the right shape. what do you mean by that>? What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? Is that possible now>? Would be happy to do that but don't want to create and pass an adata copy. > Can an image be passed directly into spatial? I'd prefer this as being the ""expert users"" interface for plotting over an image, and think passing an image to embedding could be removed altogether in the future. done, also there is no image in embedding now. Everything is handled by spatial. It is possible to do something like this:. ```python. img = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""images""][""hires""]. scalef = adata.uns[""spatial""][""V1_Adult_Mouse_Brain""][""scalefactors""][. ""tissue_hires_scalef"". ]. sc.pl.spatial(. adata,. color=""leiden"",. scale_factor=scalef,. img=img,. size=100,. basis=""spatial"",. groups=[""0""],. ). ```. ![image](https://user-images.githubusercontent.com/25887487/103009720-7eee5b00-4537-11eb-9bbf-39751493890f.png). I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:550,deployability,manag,managed,550,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:550,energy efficiency,manag,managed,550,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:18,safety,compl,completely,18,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:462,safety,test,tests,462,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:550,safety,manag,managed,550,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:18,security,compl,completely,18,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:462,testability,test,tests,462,"Oh, wow, sorry! I completely missed your comment here! > What you are proposing is to pass the adata.obsm as array in question and not as a string basis right? . What I was thinking: if it's a string get the array from `obsm`, if it's an array, check that it's shape is right, then use the array directly. > It is possible to do something like this. That looks great, thanks! > I would still like to have this in 1.7 if possible, I can write docs and additional tests real quick tomorrow early morning. For sure! I was waiting on this actually, just managed to miss any notifications about it. Sorry again about that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:474,interoperability,coordinat,coordinates,474,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:601,safety,test,test,601,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:215,security,modif,modify,215,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:313,security,modif,modify,313,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:431,security,modif,modifying,431,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:601,testability,test,test,601,"> What I was thinking: if it's a string get the array from obsm, if it's an array, check that it's shape is right, then use the array directly. I'm really sorry but I still don't get it 😅 . What I unnderstand is to modify `adata.obsm[spatial]` in `pl.spatial` and pass that to emebdding. However, I don't want to modify the adata in place or pass a copy. Maybe I'm missing something fundamental, but I could see doing this only if modifying the adata or passing the spatial coordinates as array (but is it possible in sc.pl.embedding? I couldn't find a way). For the rest, I've added docs and added a test, should be ready to go (?). Thanks again for bearing with me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:796,availability,consist,consistently,796,"Are the squidpy notebooks ready? It would be good to make sure any changes I make don't mess with how you're using this function over there. ------------------------------. A few changes I would like to get your opinion on:. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1579,deployability,API,API,1579,"y generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1851,deployability,scale,scalefactors,1851,"l had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, cr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1916,deployability,scale,scalefactors,1916,"[image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:573,energy efficiency,Current,Currently,573,"Are the squidpy notebooks ready? It would be good to make sure any changes I make don't mess with how you're using this function over there. ------------------------------. A few changes I would like to get your opinion on:. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1851,energy efficiency,scale,scalefactors,1851,"l had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, cr",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1916,energy efficiency,scale,scalefactors,1916,"[image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size` (and whether it could be found) would control whether `circles` are used. ## Crop coord being in data-space, not pixel space. I feel like it would make sense for these to crop to the same part of the image or embedding:. ```python. crop_coord = (...). sc.pl.spatial(adata, crop_coord=crop_coord, img_key=""hires""). sc.pl.spatial(adata, crop_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1579,integrability,API,API,1579,"y generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=None). ```. This largely follows from the previous, with the exception that if `size` is passed when no image is present, it's the radius. It might actually just make more sense to have a parameter for `spot_size` when I think about it more. The presence or absence of `spot_size`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:1216,interoperability,coordinat,coordinates,1216,":. ## Similar cropping regardless of img (even with img=None). This code:. ```python. with plt.rc_context({""figure.dpi"": 120}):. sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""hires""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=""lowres""). sc.pl.spatial(glio, color=""log1p_total_counts"", img_key=None). ```. <details>. <summary> Currently generates these plots (using this PR) </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884400-a4cc5000-5132-11eb-9e61-f3e9758055ed.png). </details>. Would it be better if the circles were consistently layed out, the plots were the same shape, and all had the same size? <details>. <summary> Like this </summary>. ![image](https://user-images.githubusercontent.com/8238804/103884502-cc231d00-5132-11eb-8967-6751e5e199dd.png). </details>. These changes are:. * Getting the spot size even if the image isn't used. * Using `ax.set_aspect(""equal"")` when there is no image, so that the aspect ratio is equivalent (coordinates are assumed to be pixel space). * If `crop_coords` is not passed, use the cropping matplotlib would have used if there was no image. This is done by getting the axis limits before the image is added. ## Easier manual plotting. I would like it to be reasonable to get similar images via manually passing the img, and not. So would this be a reasonable API:. ```python. adata_no_spatial = adata.copy(). del adata_no_spatial.uns[""spatial""]. library_id = ""Parent_Visium_Human_Glioblastoma"". img_key = ""hires"". spatial_dict = adata.uns[""spatial""][library_id]. img = spatial_dict[""images""][img_key]. scale_factor = spatial_dict[""scalefactors""][f""tissue_{img_key}_scalef""]. size = spatial_dict[""scalefactors""][""spot_diameter_fullres""]. # These are equivalent. sc.pl.spatial(adata_no_spatial, color=""log1p_total_counts"", img=img, scale_factor=scale_factor, size=size). sc.pl.spatial(adata, color=""log1p_total_counts"", img_key=img_key). # As are these. sc.pl.spatial(adata_no_spatial, color=""log1p_total",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
