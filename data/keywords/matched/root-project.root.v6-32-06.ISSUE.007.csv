id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/1677:323,integrability,wrap,wrapper,323,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:761,integrability,interfac,interface,761,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:323,interoperability,wrapper,wrapper,323,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:761,interoperability,interfac,interface,761,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:138,modifiability,pac,package,138,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:248,modifiability,pac,package,248,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:761,modifiability,interfac,interface,761,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:961,reliability,doe,does,961,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:982,safety,log,logical,982,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:982,security,log,logical,982,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:982,testability,log,logical,982,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:126,usability,usab,usable,126,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:779,usability,Minim,MinimumBuilder,779,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1677:1003,usability,Minim,MinimumBuilder,1003,"Minuit2 fixes; Hi, I am one of the iminuit developers (https://github.com/iminuit/iminuit). We are glad that Minuit2 is still usable as a package separate from ROOT and thank the ROOT developers for that. It makes our life much easier. The iminuit package is build by copying the Minuit2 code in ROOT and building a Cython wrapper around it. Because we compile and use the Minuit2 code outside of the ROOT build environment, we found and fixed some bugs, which we would like to merge upstream in ROOT as well. Each of the two commits in this PR fixes one issue. The first is rather trivial, `MnPrint` is used unconditionally, even though the corresponding header `MnPrint.h` is only included if certain compiler flags are set. The second one is a change in the interface of the `MinimumBuilder` base class. We run Minuit using the `MnMigrad` class. Without this change, there is no way to change the print level in a particular instance of MnMigrad. The change does not violate the logical constness of MinimumBuilder.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1677
https://github.com/root-project/root/pull/1679:22,deployability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,integrability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,interoperability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,modifiability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,reliability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,security,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1679:22,testability,integr,integration,22,"[TDF][VecOps] Improve integration of VecOps and TDF; Most importantly, now `std::vector<T>` is read as `TVec<T>` in jitted expressions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1679
https://github.com/root-project/root/pull/1680:1502,availability,Mainten,Maintenence,1502,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:11,deployability,version,version,11,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:52,deployability,build,build,52,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:94,deployability,build,build,94,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:237,deployability,build,build,237,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:367,deployability,build,build,367,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:387,deployability,instal,installing,387,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,deployability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:535,deployability,build,build,535,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:585,deployability,Version,Version,585,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1173,deployability,build,build,1173,"wing features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1284,deployability,build,build,1284," - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1706,deployability,depend,depending,1706,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1835,deployability,instal,installers,1835,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1979,deployability,instal,install,1979,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:2055,deployability,build,build,2055,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:2189,deployability,build,build,2189,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:2238,deployability,build,build,2238,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:2291,deployability,instal,installer,2291,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:11,integrability,version,version,11,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:342,integrability,sub,subdirectory,342,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,integrability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:585,integrability,Version,Version,585,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1706,integrability,depend,depending,1706,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,interoperability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:741,interoperability,platform,platform,741,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1060,interoperability,distribut,distribution,1060,"ds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build direc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1442,interoperability,Standard,Standard,1442,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:11,modifiability,version,version,11,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:470,modifiability,pac,package,470,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,modifiability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:585,modifiability,Version,Version,585,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1402,modifiability,pac,package,1402,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1427,modifiability,pac,package,1427,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1706,modifiability,depend,depending,1706,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:2255,modifiability,pac,package,2255,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,reliability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1502,reliability,Mainten,Maintenence,1502,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1894,reliability,doe,does,1894,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1302,safety,test,testing,1302,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1706,safety,depend,depending,1706,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,security,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:509,testability,integr,integrated,509,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1302,testability,test,testing,1302,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1706,testability,depend,depending,1706,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:318,usability,Support,Support,318,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:439,usability,Support,Support,439,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:544,usability,Support,Support,544,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:621,usability,support,support,621,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:644,usability,support,support,644,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:992,usability,Help,Helpful,992,"Adding new version of Minuit2 standalone with CMake build; This adds a new standalone Minuit2 build system built in CMake to replace the old one that no longer works. The following features are part of the design:. * Full featured CMake build, based on https://github.com/GooFit/Minuit2. - Only requires CMake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1914,usability,support,supported,1914,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1680:1987,usability,Visual,Visual,1987,"ake 3.1+. - Support for adding as a subdirectory, using from build directory, or installing. - Works inside of ROOT or standalone. - Support for CPack binary `make package`. - Options for MPI and OpenMP integrated with main ROOT build. - Support for macOS, Linux, and Windows. - Version captured from ROOT. - CTest support. - `make docs` support (CMake 3.8+ only). * No need for extra ""prepare"" shell scripts, everything is done cross-platform through CMake and CPack. - Files can be copied in to make redistributable source with `-Dminuit2-standalone=ON`. - `make package_source` on Unix creates `.tar.gz` and `.zip` files (non-binary CPack). - `make purge` can remove copied files. * Helpful `README.md` and `DEVELOP.md` files. ### To produce a source distribution:. Make sure you have CMake 3.1+ (ROOT requires 3.4.3+, so that's likely). Then, from `/math/minuit2/build` run:. ```bash. cmake .. -Dminuit2-standalone=ON. make package_source. make purge. ```. ### You can also build Minuit2 for testing (standalone option on or off) with:. ```. make. ```. ### And you can make a prebuilt binary package with:. ```. make package. ```. (Standard CPack option for different generators apply.). ### Maintenence. If new files are needed by Minuit2 due to additions to ROOT, they should be added to the source files lists in `/math/minuit2/src/Math/CMakeLists.txt` and `/math/minuit2/src/CMakeLists.txt` (depending on if it's a new Math or Minuit2 requirement). ### Windows. This works on Windows; and you can even then create binary installers for Windows trivially. (Though ""package_source"" does not seem to be supported on Windows). This is the procedure on Windows:. First, install Visual Studio 17, Git, CMake, and NSIS. Then from the `math/minuit2/build directory` of your ROOT checkout, run:. ```. ""C:\Program Files\CMake\bin\cmake.exe"" .. ""C:\Program Files\CMake\bin\cmake.exe"" --build . ""C:\Program Files\CMake\bin\cmake.exe"" --build . --target package. ```. This creates a `.exe` installer file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1680
https://github.com/root-project/root/pull/1681:96,safety,test,tested,96,Fix missing include for Windows; This missing include breaks Minuit2 standalone on MSVC. Can be tested as part of #1680.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1681
https://github.com/root-project/root/pull/1681:96,testability,test,tested,96,Fix missing include for Windows; This missing include breaks Minuit2 standalone on MSVC. Can be tested as part of #1680.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1681
https://github.com/root-project/root/pull/1683:28,energy efficiency,draw,draw,28,webgui: fix problem with v7 draw options I/O;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1683
https://github.com/root-project/root/pull/1683:41,performance,I/O,I/O,41,webgui: fix problem with v7 draw options I/O;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1683
https://github.com/root-project/root/pull/1684:74,availability,error,error,74,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1684:446,energy efficiency,Draw,Draw,446,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1684:8,modifiability,paramet,parameters,8,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1684:74,performance,error,error,74,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1684:74,safety,error,error,74,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1684:74,usability,error,error,74,"The fit parameters were painted too early. ; With the following macro the error bars overlapped the stat box:. {. vector < float > X, Xerr;. vector < float > Y, Yerr;. for(int i=0 ; i<10 ; ++i) {. X.push_back(i*0.1); Xerr.push_back(1.);. Y.push_back(i*2.2); Yerr.push_back(1.);. }. auto g = new TGraphErrors(X.size(), &(X[0]), &(Y[0]), &(Xerr[0]), &(Yerr[0]));. auto f = new TF1(""f"",""pol1"",0.,1.); g->Fit(""f"",""QR"");. gStyle->SetOptFit(true);. g->Draw();. }",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1684
https://github.com/root-project/root/pull/1687:100,deployability,Updat,Update,100,[TDF] Reload PR1679 with more functionality; - In the jitted case consider vector branches TVecs. - Update tutorial. - In snapshot consider the case where TVecs columns are not Carrays on disk but come from defines or sources,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1687
https://github.com/root-project/root/pull/1687:188,performance,disk,disk,188,[TDF] Reload PR1679 with more functionality; - In the jitted case consider vector branches TVecs. - Update tutorial. - In snapshot consider the case where TVecs columns are not Carrays on disk but come from defines or sources,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1687
https://github.com/root-project/root/pull/1687:100,safety,Updat,Update,100,[TDF] Reload PR1679 with more functionality; - In the jitted case consider vector branches TVecs. - Update tutorial. - In snapshot consider the case where TVecs columns are not Carrays on disk but come from defines or sources,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1687
https://github.com/root-project/root/pull/1687:100,security,Updat,Update,100,[TDF] Reload PR1679 with more functionality; - In the jitted case consider vector branches TVecs. - Update tutorial. - In snapshot consider the case where TVecs columns are not Carrays on disk but come from defines or sources,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1687
https://github.com/root-project/root/pull/1688:45,deployability,log,logic,45,"[TDF] Fix potential nullptr dereference; The logic was such that the function overload that could see the issue. was SFINAE'd out precisely every time the pointer was null, so. we never saw a crash but still had UB there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1688
https://github.com/root-project/root/pull/1688:146,performance,time,time,146,"[TDF] Fix potential nullptr dereference; The logic was such that the function overload that could see the issue. was SFINAE'd out precisely every time the pointer was null, so. we never saw a crash but still had UB there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1688
https://github.com/root-project/root/pull/1688:45,safety,log,logic,45,"[TDF] Fix potential nullptr dereference; The logic was such that the function overload that could see the issue. was SFINAE'd out precisely every time the pointer was null, so. we never saw a crash but still had UB there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1688
https://github.com/root-project/root/pull/1688:45,security,log,logic,45,"[TDF] Fix potential nullptr dereference; The logic was such that the function overload that could see the issue. was SFINAE'd out precisely every time the pointer was null, so. we never saw a crash but still had UB there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1688
https://github.com/root-project/root/pull/1688:45,testability,log,logic,45,"[TDF] Fix potential nullptr dereference; The logic was such that the function overload that could see the issue. was SFINAE'd out precisely every time the pointer was null, so. we never saw a crash but still had UB there.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1688
https://github.com/root-project/root/pull/1689:96,deployability,patch,patch,96,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:227,deployability,patch,patch,227,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:588,energy efficiency,current,current,588,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:17,interoperability,Bind,Bindings,17,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:52,interoperability,bind,bindings,52,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:312,interoperability,bind,bindings,312,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:17,modifiability,Bind,Bindings,17,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:52,modifiability,bind,bindings,52,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:312,modifiability,bind,bindings,312,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:428,modifiability,variab,variables,428,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:96,safety,patch,patch,96,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:227,safety,patch,patch,227,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:372,safety,test,test,372,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:96,security,patch,patch,96,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:227,security,patch,patch,227,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:596,security,hardcod,hardcoded,596,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:372,testability,test,test,372,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1689:292,usability,support,support,292,"WIP: Moving to C Bindings instead of deprecated C++ bindings for MPI; This was applied from a `.patch` from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because apparently MPI 3 no longer even includes support for the C++ bindings. Once #1680 is merged, this will be much easier to test. For future reference, the ugly use of environment variables instead of CMake option for MPI options in the main ROOT::Minuit2 CMakeLists.txt needs to be fixed, and also could be moved to FindMPI instead of the current hardcoded method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1689
https://github.com/root-project/root/pull/1690:134,energy efficiency,draw,draw,134,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:172,energy efficiency,draw,draw,172,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:215,energy efficiency,draw,draw,215,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:231,energy efficiency,draw,draw,231,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:290,energy efficiency,draw,draw,290,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:368,energy efficiency,draw,draw,368,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:414,energy efficiency,draw,draw,414,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:31,integrability,configur,configure,31,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:319,integrability,batch,batch,319,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:31,modifiability,configur,configure,31,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:319,performance,batch,batch,319,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:312,safety,test,test,312,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:31,security,configur,configure,31,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1690:312,testability,test,test,312,"webgui: use --web arguments to configure web window output; Now one can run root in different web modes:. root --web cef tutorials/v7/draw.cxx. root --web qt5 tutorials/v7/draw.cxx. root --web chromium tutorials/v7/draw.cxx. If in draw.cxx one replaces `canv->Show()` with `canvas->SaveAs(""draw.png"");`, one can test . batch mode like:. root -b --web cef tutorials/v7/draw.cxx. root -b --web chromium tutorials/v7/draw.cxx. Now one can check Qt5 on Mac, using normal ROOT macros from tutorials/v7.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1690
https://github.com/root-project/root/pull/1691:20,safety,test,tests,20,[TDF] More snapshot tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1691
https://github.com/root-project/root/pull/1691:20,testability,test,tests,20,[TDF] More snapshot tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1691
https://github.com/root-project/root/pull/1692:12,availability,error,error,12,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:70,availability,error,errors,70,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:161,availability,error,error,161,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:193,availability,operat,operator,193,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:494,availability,Mask,Mask,494,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:530,availability,operat,operator,530,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:547,availability,operat,operator,547,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:849,availability,Mask,Mask,849,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:885,availability,operat,operator,885,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:902,availability,operat,operator,902,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1211,availability,Mask,Mask,1211,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1418,availability,error,error,1418,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:110,deployability,build,build,110,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1272,modifiability,Scal,Scalar,1272,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1291,modifiability,Scal,Scalar,1291,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1310,modifiability,Scal,Scalar,1310,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1323,modifiability,Scal,Scalar,1323,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1452,modifiability,Scal,Scalar,1452,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:12,performance,error,error,12,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:70,performance,error,errors,70,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:161,performance,error,error,161,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1418,performance,error,error,1418,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:12,safety,error,error,12,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:70,safety,error,errors,70,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:161,safety,error,error,161,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1418,safety,error,error,1418,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:12,usability,error,error,12,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:70,usability,error,errors,70,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:161,usability,error,error,161,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1692:1418,usability,error,error,1418,"Fix compile error in GenVector; When you try to use GenVector you get errors like this:. ```. /home/yuka/root-build/include/Math/GenVector/Cartesian3D.h:116:50: error: could not convert Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fX, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0)).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fY, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))).Vc_1::Mask<double, Vc_1::VectorAbi::Avx>::operator&&(Vc_1::operator==<double, Vc_1::VectorAbi::Avx, Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >(((const ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >*)this)->ROOT::Math::Cartesian3D<Vc_1::Vector<double, Vc_1::VectorAbi::Avx> >::fZ, Vc_1::Vector<double, Vc_1::VectorAbi::Avx>(0, 0))) from Vc_1::Mask<double, Vc_1::VectorAbi::Avx> to bool. return (fX == Scalar(0) && fY == Scalar(0) && fZ == Scalar(0)) ? Scalar(0) : atan2(Rho(), Z());. ```. When arguments of atan2 is both 0, it's supporsed to emit error rather. than just returning Scalar(0). Thus it's better just returning atan2. without checking its arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1692
https://github.com/root-project/root/pull/1694:69,deployability,updat,update,69,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:51,integrability,interfac,interfaces,51,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:51,interoperability,interfac,interfaces,51,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:51,modifiability,interfac,interfaces,51,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:69,safety,updat,update,69,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:105,safety,valid,validation,105,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:69,security,updat,update,69,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:105,security,validat,validation,105,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1694:15,usability,usab,usability,15,"[TMVA] Enhance usability of CVResults and Envelope interfaces; Small update. When working with the cross validation manual, I came across these inconveniences.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1694
https://github.com/root-project/root/pull/1695:353,energy efficiency,load,loaded,353,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:403,integrability,configur,configure,403,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:374,modifiability,paramet,parameters,374,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:403,modifiability,configur,configure,403,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:353,performance,load,loaded,353,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:403,security,configur,configure,403,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1695:188,usability,behavi,behavior,188,"http: split TRootSniffer functionality; Basic functionality remains in TRootSniffer class, . extra methods for scanning TH1, TPad, TGraph, TTree classes moved to TRootSnifferFull. Default behavior of THttpServer will remain - it will create TRootSnifferFull. But in webgui only basic functionality is required, therefore all ROOT6 libraries will not be loaded. Also add few parameters in rootrc file to configure THttpServer, used in webgui.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1695
https://github.com/root-project/root/pull/1697:807,availability,avail,available,807,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:26,deployability,modul,modules,26,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:354,deployability,fail,failing,354,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:411,deployability,modul,modules,411,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:656,deployability,modul,modules,656,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:155,energy efficiency,load,loading,155,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:542,energy efficiency,load,loading,542,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:236,integrability,inject,injected,236,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:26,modifiability,modul,modules,26,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:411,modifiability,modul,modules,411,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:656,modifiability,modul,modules,656,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:755,modifiability,pac,packages,755,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:155,performance,load,loading,155,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:542,performance,load,loading,542,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:572,performance,perform,performance,572,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:354,reliability,fail,failing,354,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:807,reliability,availab,available,807,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:26,safety,modul,modules,26,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:362,safety,test,tests,362,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:411,safety,modul,modules,411,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:656,safety,modul,modules,656,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:807,safety,avail,available,807,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:236,security,inject,injected,236,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:807,security,availab,available,807,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:362,testability,test,tests,362,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:559,testability,regress,regressin,559,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1697:572,usability,perform,performance,572,"[cxxmodules] Preload more modules; Rebase PR #1396. Original PR comment:. ""ROOT can't autoparse classes inside namespaces with the rootmap. system (as the loading callbacks don't correctly land where. they are supposed to land with our injected namespaces). As this. turns out to be a feature of some kind, let's preload. TMVA/TreePlayer/Graf to fix all failing tests that are related. to this feature/bug with modules enabled. This commit can be dropped if we solve on of those problems:. figure out how to fix this bug in the rootmap-based loading. without regressin in performance. replace the rootmap system with something else like attaching. all C++ modules on startup. Note that we already do something like this in normal ROOT by. including these packages into the PCH which also makes those. decls available in the normal clang lookup.""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1697
https://github.com/root-project/root/pull/1698:64,modifiability,Scal,Scalar,64,[Math] Do not use type alias for GenVector class members; Using Scalar instead of T directly breaks things for `Double32_t`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1698
https://github.com/root-project/root/pull/1699:14,deployability,Updat,Update,14,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:27,deployability,updat,updates,27,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:43,deployability,build,build,43,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:73,deployability,configurat,configuration,73,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:73,integrability,configur,configuration,73,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:73,modifiability,configur,configuration,73,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:14,safety,Updat,Update,14,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:27,safety,updat,updates,27,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:14,security,Updat,Update,14,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:27,security,updat,updates,27,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1699:73,security,configur,configuration,73,Minuit2 CMake Update; This updates Minuit2 build options and uses proper configuration for OpenMP and MPI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1699
https://github.com/root-project/root/pull/1700:16,availability,sla,slash,16,Support dot and slash separators in TTree:GetLeaf(); See [ROOT-9254](https://sft.its.cern.ch/jira/browse/ROOT-9254) for more information.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1700
https://github.com/root-project/root/pull/1700:16,reliability,sla,slash,16,Support dot and slash separators in TTree:GetLeaf(); See [ROOT-9254](https://sft.its.cern.ch/jira/browse/ROOT-9254) for more information.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1700
https://github.com/root-project/root/pull/1700:0,usability,Support,Support,0,Support dot and slash separators in TTree:GetLeaf(); See [ROOT-9254](https://sft.its.cern.ch/jira/browse/ROOT-9254) for more information.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1700
https://github.com/root-project/root/pull/1701:64,safety,test,test,64,"[TDF] [WIP] Allow to read nested branches/leaves; These changes test and provide the functionality to access quantities called ""mybranch.mysubbranch""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1701
https://github.com/root-project/root/pull/1701:102,security,access,access,102,"[TDF] [WIP] Allow to read nested branches/leaves; These changes test and provide the functionality to access quantities called ""mybranch.mysubbranch""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1701
https://github.com/root-project/root/pull/1701:64,testability,test,test,64,"[TDF] [WIP] Allow to read nested branches/leaves; These changes test and provide the functionality to access quantities called ""mybranch.mysubbranch""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1701
https://github.com/root-project/root/pull/1702:16,energy efficiency,draw,drawing,16,Adjust v7 TText drawing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1702
https://github.com/root-project/root/pull/1703:4,safety,test,test,4,new test for v7 text; Add a test for v7/TText,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1703
https://github.com/root-project/root/pull/1703:28,safety,test,test,28,new test for v7 text; Add a test for v7/TText,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1703
https://github.com/root-project/root/pull/1703:4,testability,test,test,4,new test for v7 text; Add a test for v7/TText,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1703
https://github.com/root-project/root/pull/1703:28,testability,test,test,28,new test for v7 text; Add a test for v7/TText,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1703
https://github.com/root-project/root/pull/1704:4,deployability,fail,failing,4,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:86,deployability,fail,fails,86,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:4,reliability,fail,failing,4,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:86,reliability,fail,fails,86,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:12,safety,test,test,12,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:43,safety,Test,Test,43,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:12,testability,test,test,12,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1704:43,testability,Test,Test,43,Fix failing test with GCC 7.3.0 and C++17; Test `tutorial-roostats-CreateExampleFile` fails for me with GCC 7.3.0 and C++17=ON.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1704
https://github.com/root-project/root/pull/1705:7,energy efficiency,Draw,DrawText,7,Change DrawText to be compatible with v7 TText;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1705
https://github.com/root-project/root/pull/1705:22,interoperability,compatib,compatible,22,Change DrawText to be compatible with v7 TText;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1705
https://github.com/root-project/root/pull/1706:52,availability,operat,operation,52,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:155,availability,operat,operation--the,155,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:307,availability,operat,operation,307,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:864,availability,operat,operation,864,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:952,availability,operat,operations,952,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:984,availability,operat,operation,984,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:1072,availability,operat,operations,1072,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:1118,availability,operat,operation,1118,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:736,deployability,releas,release,736,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:334,energy efficiency,CPU,CPU,334,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:443,energy efficiency,CPU,CPU,443,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:37,integrability,wrap,wrap,37,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:139,integrability,wrap,wraps,139,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:848,integrability,queue,queue,848,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:205,performance,perform,perform,205,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:334,performance,CPU,CPU,334,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:338,performance,time,time,338,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:443,performance,CPU,CPU,443,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:848,performance,queue,queue,848,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:1060,performance,perform,perform,1060,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:911,safety,compl,complete,911,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:71,security,modif,modifies,71,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:583,security,barrier,barrier,583,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:645,security,barrier,barrier,645,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:705,security,barrier,barrier,705,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:745,security,barrier,barrier,745,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:806,security,barrier,barrier,806,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:911,security,compl,complete,911,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:205,usability,perform,perform,205,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1706:1060,usability,perform,perform,1060,"change the TBufferMerger callback to wrap the merge operation; This PR modifies the TBufferMerger callback (that CMS requested) so that it wraps the merge operation--the callback is passed the function to perform the merge and is responsible for calling it. The motivation for this change is that the merge operation is taking enough CPU time that we need it to be executed in the CMSSW framework's TBB task arena so that we don't overrun our CPU commitment. With this change, we can use a callback like. ```. mergeExec_ = [this](const std::function<void()> &f){. std::promise<void> barrier;. auto fwrap = [&]() { . auto set_value = [](decltype(barrier)* b) { b->set_value(); };. std::unique_ptr<decltype(barrier), decltype(set_value)> release(&barrier, set_value);. f();. };. taskArena_->enqueue(fwrap);. barrier.get_future().wait();. };. ```. to queue the merge operation to our task arena and wait for it to complete. This also ensures that any IMT operations invoked by the merge operation are also executed in our task arena. Since the callback can still perform any operations it wants after executing the merge operation, this is a superset of the previous callback functionality.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1706
https://github.com/root-project/root/pull/1707:14,energy efficiency,alloc,alloc,14,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1707:65,energy efficiency,alloc,allocator,65,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1707:38,performance,I/O,I/O,38,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1707:7,usability,custom,custom,7,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1707:58,usability,custom,custom,58,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1707:99,usability,shortcut,shortcuts,99,Vector custom alloc; This enables the I/O for vector with custom allocator by not taking the usual shortcuts.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1707
https://github.com/root-project/root/pull/1708:15,integrability,translat,translation,15,Bessel example translation to python3 and Jupyter notebook;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1708
https://github.com/root-project/root/pull/1708:15,interoperability,translat,translation,15,Bessel example translation to python3 and Jupyter notebook;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1708
https://github.com/root-project/root/pull/1709:0,integrability,Translat,Translate,0,Translate tStudent.C to python;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1709
https://github.com/root-project/root/pull/1709:0,interoperability,Translat,Translate,0,Translate tStudent.C to python;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1709
https://github.com/root-project/root/pull/1712:103,interoperability,platform,platform,103,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1712:119,performance,memor,memory,119,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1712:385,safety,input,input,385,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1712:12,usability,support,support,12,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1712:119,usability,memor,memory,119,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1712:385,usability,input,input,385,"Add initial support for an Apache Arrow based TDataFrame; Apache Arrow is a cross-language development platform for in-memory data. which is backed by a number of opensource projects including Calcite,. Cassandra, Drill, Hadoop, HBase, Ibis, Impala, Kudu, Pandas, Parquet,. Phoenix, Spark, and Storm. This implements a TDataSource which allows. using columns in a `arrow::Table` as an input to a TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1712
https://github.com/root-project/root/pull/1713:346,availability,slo,slower,346,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:248,deployability,patch,patch,248,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:219,energy efficiency,Measur,Measured,219,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:228,performance,perform,performance,228,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:346,reliability,slo,slower,346,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:248,safety,patch,patch,248,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:271,safety,test,testcase,271,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:0,security,Modif,Modified,0,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:248,security,patch,patch,248,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:301,security,sign,significant,301,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:271,testability,test,testcase,271,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:208,usability,efficien,efficient,208,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1713:228,usability,perform,performance,228,"Modified roofit code using TClingTypedefInfo::InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1713
https://github.com/root-project/root/pull/1714:325,availability,slo,slower,325,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:227,deployability,patch,patch,227,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:198,energy efficiency,Measur,Measured,198,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:207,performance,perform,performance,207,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:325,reliability,slo,slower,325,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:227,safety,patch,patch,227,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:250,safety,test,testcase,250,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:227,security,patch,patch,227,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:280,security,sign,significant,280,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:250,testability,test,testcase,250,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:187,usability,efficien,efficient,187,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1714:207,usability,perform,performance,207,"Delete roofit code using InternalNext; Roofit was using TInterpreter::Next, which was actually calling. TClingTypedefInfo::InternalNext. This function is iterating each decls. and is not efficient. Measured performance of this patch on stressRooFit. testcase and it didn't have a significant different but not making roofit. slower as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1714
https://github.com/root-project/root/pull/1715:78,security,token,token,78,"Delete loop from RooCintUtils::isValidEnumValue; We want to compare the first token of typeName separated by "":"" and. value, and we only have to see it once.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1715
https://github.com/root-project/root/pull/1716:161,availability,operat,operator,161,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1716:71,deployability,patch,patch,71,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1716:20,performance,memor,memory,20,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1716:71,safety,patch,patch,71,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1716:71,security,patch,patch,71,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1716:20,usability,memor,memory,20,[cling] Value print memory address of C++ object with oveloaded &; The patch teaches cling to print the proper address of C++ objects with overloaded address-of operator.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1716
https://github.com/root-project/root/pull/1717:53,energy efficiency,alloc,alloc,53,Do not allow emulated of compiled vector with custom alloc;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1717
https://github.com/root-project/root/pull/1717:13,testability,emul,emulated,13,Do not allow emulated of compiled vector with custom alloc;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1717
https://github.com/root-project/root/pull/1717:46,usability,custom,custom,46,Do not allow emulated of compiled vector with custom alloc;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1717
https://github.com/root-project/root/pull/1719:52,deployability,patch,patches,52,Fix rootls with python3 (Fixes ROOT-9299) (v6-12-00-patches); In python 3 'term_width / min_element_width' is a float and can't be passed to. range a few lines below.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1719
https://github.com/root-project/root/pull/1719:52,safety,patch,patches,52,Fix rootls with python3 (Fixes ROOT-9299) (v6-12-00-patches); In python 3 'term_width / min_element_width' is a float and can't be passed to. range a few lines below.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1719
https://github.com/root-project/root/pull/1719:52,security,patch,patches,52,Fix rootls with python3 (Fixes ROOT-9299) (v6-12-00-patches); In python 3 'term_width / min_element_width' is a float and can't be passed to. range a few lines below.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1719
https://github.com/root-project/root/pull/1720:7,availability,redund,redundant,7,Remove redundant RooCintUtils.h; There files were not using RooCintUtils.h which is an implementation for old interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1720
https://github.com/root-project/root/pull/1720:7,deployability,redundan,redundant,7,Remove redundant RooCintUtils.h; There files were not using RooCintUtils.h which is an implementation for old interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1720
https://github.com/root-project/root/pull/1720:7,reliability,redundan,redundant,7,Remove redundant RooCintUtils.h; There files were not using RooCintUtils.h which is an implementation for old interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1720
https://github.com/root-project/root/pull/1720:7,safety,redund,redundant,7,Remove redundant RooCintUtils.h; There files were not using RooCintUtils.h which is an implementation for old interpreter.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1720
https://github.com/root-project/root/pull/1721:123,energy efficiency,Profil,ProfileLikelihoodCalculator,123,"[roofit] Add a non-const overload.; This allows uses such as:. RooMCStudy* mcstudy = new RooMCStudy;. auto var = RooStats::ProfileLikelihoodCalculator(mcstudy->genData(),...);. to compile and work without the users to have to use const_casts.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1721
https://github.com/root-project/root/pull/1721:123,performance,Profil,ProfileLikelihoodCalculator,123,"[roofit] Add a non-const overload.; This allows uses such as:. RooMCStudy* mcstudy = new RooMCStudy;. auto var = RooStats::ProfileLikelihoodCalculator(mcstudy->genData(),...);. to compile and work without the users to have to use const_casts.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1721
https://github.com/root-project/root/pull/1721:209,usability,user,users,209,"[roofit] Add a non-const overload.; This allows uses such as:. RooMCStudy* mcstudy = new RooMCStudy;. auto var = RooStats::ProfileLikelihoodCalculator(mcstudy->genData(),...);. to compile and work without the users to have to use const_casts.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1721
https://github.com/root-project/root/pull/1722:150,integrability,wrap,wrapper,150,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:245,integrability,interfac,interface,245,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:372,integrability,interfac,interface,372,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:150,interoperability,wrapper,wrapper,150,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:245,interoperability,interfac,interface,245,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:372,interoperability,interfac,interface,372,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:245,modifiability,interfac,interface,245,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:372,modifiability,interfac,interface,372,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:406,performance,perform,performance,406,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1722:406,usability,perform,performance,406,"Delete RooCintUtils.h and RooCintUtils.cxx; I know this is not a small change, so any comments are welcome! Background:. RooCintUtils was providing a wrapper between Cint and roofit. This implementation is very old, and is. using Cint iteration interface a lot. Recently we were trying to kill. RooCintUtils code where its using iteration and to change them to new. Cling interface in order to improve the performance. RooCintUtils is an utility class, so this is internal namespace which is only used inside roofit. Since there are just 3 methods left, this RooCintUtils is no longer. worth spending a file. Let's delete this and migrate methods to. RooFactoryWSTool.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1722
https://github.com/root-project/root/pull/1723:255,performance,memor,memory,255,"Use GetListOfClasses instead of iterating over AST; GetListOfClasses is returning fClasses, which is a collection of classes. in TCollection type. If I'm understanding collectly, fClasses in TROOT is initialized at the entry. point so it's already on the memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1723
https://github.com/root-project/root/pull/1723:154,testability,understand,understanding,154,"Use GetListOfClasses instead of iterating over AST; GetListOfClasses is returning fClasses, which is a collection of classes. in TCollection type. If I'm understanding collectly, fClasses in TROOT is initialized at the entry. point so it's already on the memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1723
https://github.com/root-project/root/pull/1723:255,usability,memor,memory,255,"Use GetListOfClasses instead of iterating over AST; GetListOfClasses is returning fClasses, which is a collection of classes. in TCollection type. If I'm understanding collectly, fClasses in TROOT is initialized at the entry. point so it's already on the memory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1723
https://github.com/root-project/root/pull/1724:242,availability,error,error,242,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:228,deployability,patch,patch,228,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:25,integrability,interfac,interface,25,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:25,interoperability,interfac,interface,25,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:25,modifiability,interfac,interface,25,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:152,modifiability,paramet,parameter,152,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:242,performance,error,error,242,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:8,reliability,diagno,diagnostics,8,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:228,safety,patch,patch,228,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:242,safety,error,error,242,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:228,security,patch,patch,228,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:8,testability,diagno,diagnostics,8,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:242,usability,error,error,242,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1724:304,usability,user,user,304,"Improve diagnostics when interface called with wrong arguments.; If we call `gInterpreter->GenerateDictionary(""std::vector<int>"")` with. missing second parameter (which expects to pass the corresponding include). we crash. This patch enables error reporting and removes the default argument to. tell the user that nullptr is not expected.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1724
https://github.com/root-project/root/pull/1726:32,interoperability,semant,semantic,32,Attempt isValidEnumValue to the semantic of TEnum::GetEnum.; And avoid nullptr dereference,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1726
https://github.com/root-project/root/pull/1726:65,safety,avoid,avoid,65,Attempt isValidEnumValue to the semantic of TEnum::GetEnum.; And avoid nullptr dereference,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1726
https://github.com/root-project/root/pull/1727:16,deployability,patch,patch,16,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1727:202,deployability,upgrad,upgrade,202,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1727:202,modifiability,upgrad,upgrade,202,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1727:16,safety,patch,patch,16,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1727:214,safety,accid,accidentally,214,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1727:16,security,patch,patch,16,"Reverting clang patch: ""PCH has partial names (include/TObject.h), us; Was already reverted in the ""Revert ""PCH has partial names (include/TObject.h), use them for full . paths."""" , but with LLVM5.0 upgrade was accidentally returned back.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1727
https://github.com/root-project/root/pull/1728:156,deployability,fail,fails,156,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1728:207,deployability,build,buildid,207,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1728:265,deployability,version,version,265,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1728:265,integrability,version,version,265,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1728:265,modifiability,version,version,265,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1728:156,reliability,fail,fails,156,"Fix the bug in isValidEnumValue; There was a bug in. https://github.com/root-project/root/pull/1715/commits/b2faf2802ee303ff20ca4866b7a3bd235cefa8c3. which fails http://cdash.cern.ch/viewTest.php?onlyfailed&buildid=472876. in this commit, so let's use the previous version instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1728
https://github.com/root-project/root/pull/1730:20,deployability,modul,module,20,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:60,deployability,modul,modules,60,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:121,deployability,build,build,121,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:107,interoperability,standard,standard,107,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:20,modifiability,modul,module,20,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:60,modifiability,modul,modules,60,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:20,safety,modul,module,20,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:60,safety,modul,modules,60,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1730:164,usability,custom,custom,164,Add cwd to prebuilt module path.; This will be able to find modules generated by rootcling outside of. the standard ROOT build. This is often the case when we have custom dictionaries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1730
https://github.com/root-project/root/pull/1731:26,modifiability,paramet,parameters,26,Support r-value reference parameters in TClingCallFunc; This PR adds some functionality to TClingCallFunc in order to handle moves in function parameters. The changes were implemented by Wim Lavrijsen in Cppyy's Cling and requested for ROOT's here:. https://sft.its.cern.ch/jira/browse/ROOT-9075. This PR also incorporates @pcanal's suggestion of using an enum to describe the reference type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1731
https://github.com/root-project/root/pull/1731:143,modifiability,paramet,parameters,143,Support r-value reference parameters in TClingCallFunc; This PR adds some functionality to TClingCallFunc in order to handle moves in function parameters. The changes were implemented by Wim Lavrijsen in Cppyy's Cling and requested for ROOT's here:. https://sft.its.cern.ch/jira/browse/ROOT-9075. This PR also incorporates @pcanal's suggestion of using an enum to describe the reference type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1731
https://github.com/root-project/root/pull/1731:0,usability,Support,Support,0,Support r-value reference parameters in TClingCallFunc; This PR adds some functionality to TClingCallFunc in order to handle moves in function parameters. The changes were implemented by Wim Lavrijsen in Cppyy's Cling and requested for ROOT's here:. https://sft.its.cern.ch/jira/browse/ROOT-9075. This PR also incorporates @pcanal's suggestion of using an enum to describe the reference type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1731
https://github.com/root-project/root/pull/1734:7,energy efficiency,Reduc,Reduce,7,[Math] Reduce to the minimum the usage of R__LOAD_LIBRARY in tutorials;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1734
https://github.com/root-project/root/pull/1734:21,usability,minim,minimum,21,[Math] Reduce to the minimum the usage of R__LOAD_LIBRARY in tutorials;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1734
https://github.com/root-project/root/pull/1736:68,safety,test,tests,68,[VecOps] Add Variance and Std Deviation for TVecs; as well as their tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1736
https://github.com/root-project/root/pull/1736:68,testability,test,tests,68,[VecOps] Add Variance and Std Deviation for TVecs; as well as their tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1736
https://github.com/root-project/root/pull/1737:41,energy efficiency,model,model,41,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1737:51,performance,parallel,parallelism,51,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1737:108,safety,safe,safe,108,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1737:41,security,model,model,41,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1737:34,usability,user,user,34,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1737:134,usability,user,user,134,"Make TBufferMerger agnostic about user's model for parallelism; After ROOT's cleanup has become more thread-safe, we can just let the user decide if they want to use threads or tasks with TBufferMerger. We no longer use a separate thread for merging, which means we do not oversubscribe the machine anymore either.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1737
https://github.com/root-project/root/pull/1738:265,energy efficiency,draw,drawables,265,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:379,energy efficiency,draw,drawables,379,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:4,integrability,sub,sub-pads,4,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:106,integrability,sub,subpads,106,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:292,integrability,sub,sub-pads,292,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:399,integrability,sub,sub-pads,399,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:203,security,ident,identifier,203,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:312,security,ident,identifier,312,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1738:13,usability,support,support,13,"Add sub-pads support in v7 TCanvas; Now one can use TCanvas::Divide() and TPad::Divide() methods. Created subpads will be displayed by the client - including objects in the pads. Introduce unique object identifier inside the canvas - it is just 64-bit counter. All drawables add to canvas or sub-pads get unique identifier, generated by canvas. TPadPainter is class for painting drawables in canvas/sub-pads. TVirtualCanvasPainter derived from TPadPainter and add more methods for canvas display. Provide draw_subpads.cxx tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1738
https://github.com/root-project/root/pull/1740:34,testability,Emul,Emulated,34,Fix cling on Windows (there is no Emulated TLS on Windows);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1740
https://github.com/root-project/root/pull/1741:67,availability,redund,redundant,67,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:35,deployability,depend,depends,35,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:67,deployability,redundan,redundant,67,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:77,deployability,depend,dependencies,77,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:140,deployability,build,builds,140,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:35,integrability,depend,depends,35,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:77,integrability,depend,dependencies,77,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:35,modifiability,depend,depends,35,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:77,modifiability,depend,dependencies,77,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:67,reliability,redundan,redundant,67,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:35,safety,depend,depends,35,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:67,safety,redund,redundant,67,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:77,safety,depend,dependencies,77,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:35,testability,depend,depends,35,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1741:77,testability,depend,dependencies,77,[cmake] Generation of RGitCommit.h depends on nothing.; Remove the redundant dependencies from the target. This fixes a cxxmodules. nightly builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1741
https://github.com/root-project/root/pull/1742:42,interoperability,specif,specific,42,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:131,safety,prevent,prevent,131,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:148,safety,compl,complaining,148,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:131,security,preven,prevent,131,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:148,security,compl,complaining,148,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:222,testability,simpl,simply,222,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1742:222,usability,simpl,simply,222,Fix math on Windows; - Remove old Windows specific limitations (leftover from ROOT 5). - Global namespace in front of ROOT::Fit to prevent compiler complaining about ROOT::Fit::ROOT::Fit::ExecutionPolicy. (maybe we should simply remove ROOT::Fit),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1742
https://github.com/root-project/root/pull/1745:83,integrability,compon,components,83,Add library prefix and suffixes for Windows; This allows to properly find required components on Windows (e.g. roottest couldn't find RIO),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1745
https://github.com/root-project/root/pull/1745:83,interoperability,compon,components,83,Add library prefix and suffixes for Windows; This allows to properly find required components on Windows (e.g. roottest couldn't find RIO),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1745
https://github.com/root-project/root/pull/1745:83,modifiability,compon,components,83,Add library prefix and suffixes for Windows; This allows to properly find required components on Windows (e.g. roottest couldn't find RIO),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1745
https://github.com/root-project/root/pull/1746:0,deployability,Log,Logger,0,"Logger: emit through TError by default, mention MT behavior.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1746
https://github.com/root-project/root/pull/1746:0,safety,Log,Logger,0,"Logger: emit through TError by default, mention MT behavior.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1746
https://github.com/root-project/root/pull/1746:0,security,Log,Logger,0,"Logger: emit through TError by default, mention MT behavior.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1746
https://github.com/root-project/root/pull/1746:0,testability,Log,Logger,0,"Logger: emit through TError by default, mention MT behavior.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1746
https://github.com/root-project/root/pull/1746:51,usability,behavi,behavior,51,"Logger: emit through TError by default, mention MT behavior.;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1746
https://github.com/root-project/root/pull/1747:202,usability,effectiv,effective,202,Resolve ROOT-9283; TChain::RecursiveRemove was not looking at the list of friends. TTree::RecursiveRemove was looking at the list of friends but we needed a TFriendElement::RecursiveRemove for it to be effective.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1747
https://github.com/root-project/root/pull/1748:77,deployability,automat,automatically,77,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:149,deployability,patch,patch,149,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:149,safety,patch,patch,149,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:216,safety,test,test,216,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:453,safety,compl,complete,453,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:149,security,patch,patch,149,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:453,security,compl,complete,453,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:530,security,modif,modify,530,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:77,testability,automat,automatically,77,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1748:216,testability,test,test,216,"Remove unnecessary includes; Thanks to @dpiparo suggestion, I wrote a script automatically removing unnecessary includes under a directory. In. this patch I removed unnecessary includes in roofit/roofitcore/src/ for test, but. you can use this script to any directories. Script:. https://gist.github.com/yamaguchi1024/d95843a5e549fcc6ba0e6e23da5c132a. How to use:. python3 iwyu.py /path/to/directory/you/want/. Limitations:. include-what-you-use is not complete, it sometimes remove *necessary*. includes. So you must compile and modify diff or checkout files if necessary include was. removed. I reccomend to use this script in a directory where you're. familiar with, because you anyway have to check the diff.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1748
https://github.com/root-project/root/pull/1749:6,deployability,updat,update,6,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1749:153,deployability,build,builds,153,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1749:6,safety,updat,update,6,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1749:6,security,updat,update,6,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1749:336,security,Team,Team,336,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1749:453,usability,help,help,453,"Final update to use LZ4 as a default for ROOT; These changes are providing final transition to LZ4. ```. oksana@oksana-ThinkPad-E470:~/CERN_sources/root/builds$ root tutorials/hsimple.root . --------------------------------------------------------------------. | Welcome to ROOT 6.13/01 http://root.cern.ch |. | (c) 1995-2017, The ROOT Team |. | Built for linuxx8664gcc |. | From heads/master@v6-11-02-2061-gbdde402239, Mar 13 2018, 21:27:32 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------------------------------------------------. root [0] . Attaching file tutorials/hsimple.root as _file0... (TFile *) 0x55cd127ea830. root [1] _file0->GetCompressionAlgorithm(). (int) 0. root [2] _file0->GetCompressionSettings(). (int) 4. root [3] _file0->GetCompressionLevel(). (int) 4. root [4]. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1749
https://github.com/root-project/root/pull/1751:100,deployability,releas,release,100,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1751:92,performance,time,time,92,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1751:118,performance,lock,lock,118,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1751:232,performance,deadlock,deadlock,232,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1751:223,reliability,doe,does,223,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1751:118,security,lock,lock,118,"TBufferMerger without separate thread, second take; This adds back commit ff557b3, but this time we release the merge lock before calling a registered callback. That way, if the callback itself triggers another Merge(), it does not deadlock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1751
https://github.com/root-project/root/pull/1752:34,energy efficiency,Load,LoadDictionaryForSTLType,34,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:77,energy efficiency,Load,LoadDictionaryForSTLType,77,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:139,integrability,interfac,interface,139,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:218,integrability,interfac,interface,218,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:139,interoperability,interfac,interface,139,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:218,interoperability,interfac,interface,218,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:139,modifiability,interfac,interface,139,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:218,modifiability,interfac,interface,218,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:34,performance,Load,LoadDictionaryForSTLType,34,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1752:77,performance,Load,LoadDictionaryForSTLType,77,"Use GenerateDictionary instead of LoadDictionaryForSTLType; As said in TODO, LoadDictionaryForSTLType is passing ""#include <...>"" to. CINT interface to parse and process it, and was expensive. In Cling, we. have a new interface GenerateDictionary which we can instead use to. generate dictionary.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1752
https://github.com/root-project/root/pull/1753:437,deployability,depend,dependence,437,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:25,integrability,interfac,interface,25,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:54,integrability,interfac,interface,54,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:437,integrability,depend,dependence,437,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:811,integrability,interfac,interface,811,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:25,interoperability,interfac,interface,25,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:54,interoperability,interfac,interface,54,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:811,interoperability,interfac,interface,811,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:25,modifiability,interfac,interface,25,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:54,modifiability,interfac,interface,54,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:437,modifiability,depend,dependence,437,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:733,modifiability,maintain,maintain,733,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:811,modifiability,interfac,interface,811,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:628,performance,time,time,628,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:437,safety,depend,dependence,437,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:501,safety,test,test,501,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:733,safety,maintain,maintain,733,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:437,testability,depend,dependence,437,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:455,testability,unit,unittest,455,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1753:501,testability,test,test,501,"[PyROOT] Add numpy array interface; Added numpy array interface for. - `TVec`. - `TVector`. - `TMatrix`. - `std::vector`. and data types. - `float`. - `double`. - `int` (only `TVec` and `std::vector`). - `long` (only `TVec` and `std::vector`). - `unsigned int` (only `TVec` and `std::vector`). - `unsigned long` (only `TVec` and `std::vector`). WIP:. - ~~Which classes to be added?~~. - ~~Which data types?~~. - ~~What about the `numpy` dependence of the unittest?~~ I asked for numpy to activate the test. - ~~Segfault for `TMatrixT(""int"")` and `TVectorT(""int"")`?~~ Not a problem of this PR. - ~~Check endianess during compile-time?~~ Checked for `R__BYTESWAP` with pre-compiler. - ~~What about histogram classes?~~ Not possible to maintain same return structure than `numpy.hist` solely by tweaking the array interface (that was the actual idea). - ~~What about the unsigned types?~~ Done for `std::vector` and `TVec`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1753
https://github.com/root-project/root/pull/1755:76,deployability,patch,patch,76,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:16,integrability,messag,messages,16,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:99,integrability,messag,messages,99,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:16,interoperability,messag,messages,16,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:99,interoperability,messag,messages,99,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:76,safety,patch,patch,76,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:49,security,authenticat,authentication,49,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:76,security,patch,patch,76,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1755:64,usability,tool,tools,64,"Add deprecation messages in PQ2, old deamons and authentication tools; This patch adds deprecation messages in the pq2 steering main, in rootd, proofd, ssh2rpd, and in all related man pages. Part of the agreed deprecation campaign.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1755
https://github.com/root-project/root/pull/1756:0,deployability,Updat,Updating,0,Updating release notes;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1756
https://github.com/root-project/root/pull/1756:9,deployability,releas,release,9,Updating release notes;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1756
https://github.com/root-project/root/pull/1756:0,safety,Updat,Updating,0,Updating release notes;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1756
https://github.com/root-project/root/pull/1756:0,security,Updat,Updating,0,Updating release notes;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1756
https://github.com/root-project/root/pull/1758:68,integrability,messag,message,68,[TDF] Replace dots with underscores in snapshotted columns; An Info message is printed when this happens. This resolves [ROOT-9270](https://sft.its.cern.ch/jira/browse/ROOT-9270).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1758
https://github.com/root-project/root/pull/1758:68,interoperability,messag,message,68,[TDF] Replace dots with underscores in snapshotted columns; An Info message is printed when this happens. This resolves [ROOT-9270](https://sft.its.cern.ch/jira/browse/ROOT-9270).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1758
https://github.com/root-project/root/pull/1759:44,energy efficiency,model,models,44,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:107,energy efficiency,model,models,107,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:139,energy efficiency,reduc,reduce,139,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:25,modifiability,variab,variable,25,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:81,modifiability,refact,refactors,81,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:167,modifiability,exten,extends,167,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:81,performance,refactor,refactors,81,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:193,safety,test,test,193,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:44,security,model,models,44,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:107,security,model,models,107,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:175,security,sign,significantly,175,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:126,testability,simpl,simplify,126,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:193,testability,test,test,193,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:198,testability,coverag,coverage,198,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1759:126,usability,simpl,simplify,126,"[TDF] Fix ROOT-9295: fix variable bin sizes models; This PR fixes the jira item, refactors the code of the models in order to simplify and reduce code duplication and extends significantly the test coverage.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1759
https://github.com/root-project/root/pull/1761:57,deployability,modul,module,57,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:131,deployability,build,building,131,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:208,deployability,build,building,208,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:249,deployability,infrastructur,infrastructure,249,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:286,deployability,build,building,286,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:329,deployability,modul,modules,329,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:268,energy efficiency,current,currently,268,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:57,modifiability,modul,module,57,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:329,modifiability,modul,modules,329,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:64,performance,cach,caches,64,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:156,reliability,doe,does,156,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:57,safety,modul,module,57,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1761:329,safety,modul,modules,329,"[cxxmodules] Add LD_LIBRARY_PATH to the list of prebuilt module caches.; We rely on rootcling to put reflection/IO information and building pcms. on demand does not make sense. EDIT: We cannot really disable building implicit pcms as we are missing infrastructure. We currently rely on building libc, stl and _Builtin_intrinsics modules on demand while running rootcling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1761
https://github.com/root-project/root/pull/1762:150,energy efficiency,alloc,allocate,150,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:176,energy efficiency,Profil,Profiled,176,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:62,integrability,interfac,interface,62,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:62,interoperability,interfac,interface,62,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:62,modifiability,interfac,interface,62,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:159,performance,memor,memory,159,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:176,performance,Profil,Profiled,176,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:200,performance,perform,performance,200,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:159,usability,memor,memory,159,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1762:200,usability,perform,performance,200,"Don't make a full list when we just want its size; Add Size() interface to TListOfFunctions and call this from GetNmethods,. so that we don't have to allocate memory for this. Profiled the peak meory performance in valgrind. total(B) . master: 427,544,680. HEAD: 427,542,328",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1762
https://github.com/root-project/root/pull/1764:22,integrability,sub,subbranch,22,"[TDF] Support ""branch.subbranch.leaf"" syntax in JITted expressions; This PR addresses [this ticket](https://sft.its.cern.ch/jira/browse/ROOT-9271).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1764
https://github.com/root-project/root/pull/1764:6,usability,Support,Support,6,"[TDF] Support ""branch.subbranch.leaf"" syntax in JITted expressions; This PR addresses [this ticket](https://sft.its.cern.ch/jira/browse/ROOT-9271).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1764
https://github.com/root-project/root/pull/1765:27,energy efficiency,optim,optimisations,27,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:244,energy efficiency,profil,profiles,244,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:596,energy efficiency,profil,profiles,596,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:611,energy efficiency,optim,optimisations,611,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:397,interoperability,bind,bind,397,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:823,interoperability,bind,binding,823,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:850,interoperability,share,share,850,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:1383,interoperability,Specif,Specify,1383,"derArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the br",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:1406,interoperability,distribut,distribution,1406,"e branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //els",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:1520,interoperability,bind,bind,1520,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:397,modifiability,bind,bind,397,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:823,modifiability,bind,binding,823,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:1520,modifiability,bind,bind,1520,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:145,performance,bottleneck,bottlenecks,145,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:244,performance,profil,profiles,244,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:596,performance,profil,profiles,596,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:865,performance,memor,memory,865,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:2113,performance,time,timer,2113,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:2121,performance,time,timer,2121,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:2433,performance,time,timer,2433,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:2448,performance,time,timer,2448,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:112,security,ident,identified,112,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:103,usability,user,user,103,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:865,usability,memor,memory,865,"[WIP ]Demonstrate possible optimisations of TTreeReaderArray; Following up on a case reported by a CMS user, we identified a series of potential bottlenecks in the present implementation of TTreeReaderArray. An example can be seen bellow*. The profiles can be seen in attachment. One of the symptoms is the presence of multiple deserialisations. The problem appears when several TTreeReaderArrays bind to the same branch. This seems to be an exotic case, but it can happen easily in TDataFrame, for example creating several define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1765:2439,usability,Stop,Stop,2439,"veral define nodes starting from the same column storing a collection. As the profiles show, optimisations for the individual TVirtualCollectionReader implementations: it's a non-negligible amount of work but it can be done. I was wondering if TTreeReaderArray could be really lazy and have all instances binding to the same branch share the same memory for the deserialised collections. For the multi threading, this would not be a problem given that nothing can be done anyway from different threads on a single branch (meaning, the very same one, with the same pointer). *. ```.cpp. #include <TFile.h>. #include <TStopwatch.h>. #include <TTreeReader.h>. #include <TTreeReaderArray.h>. #include <vector>. #include <iostream>. /*. // Dataset created with this function. void createFile(). {. // First create an instance of an engine. random_device rnd_device;. // Specify the engine and distribution. mt19937 mersenne_engine(rnd_device());. uniform_int_distribution<int> dist(1, 42);. auto gen = std::bind(dist, mersenne_engine);. std::vector<int> vec(983);. generate(begin(vec), end(vec), gen);. ROOT::Experimental::TDataFrame d(10000);. d.Define(""v"", [&](){std::shuffle(begin(vec), end(vec), mersenne_engine); return vec;}). .Snapshot<std::vector<int>>(""t"",""mytree.root"",{""v""});. }. */. void checkTTreeReaderArrayCost(). {. TFile f(""mytree.root"");. TTreeReader reader(""t"", &f);. auto nevents = 10000;. auto nreaderarrays = 3000;. std::vector<TTreeReaderArray<int>*> readerarrays(nreaderarrays);. for (auto &&raa : readerarrays) {. raa = new TTreeReaderArray<int>(reader, ""v"");. }. TStopwatch timer;. timer.Start();. // int arrIndex = 123;. while (reader.Next()) {. if (nevents-- == 0) break;. for (auto &&raa : readerarrays) {. auto &ra = *raa;. if(ra[0] < -1000) std::cout << ra[0] << std::endl;. //if (arrIndex == 980) arrIndex =0; // We know the vectors in the branch have size 983. //else arrIndex++;. }. }. timer.Stop();. timer.Print();. }. int main() {. checkTTreeReaderArrayCost();. } . ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1765
https://github.com/root-project/root/pull/1766:0,deployability,Updat,Update,0,Update Davix builtin;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1766
https://github.com/root-project/root/pull/1766:0,safety,Updat,Update,0,Update Davix builtin;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1766
https://github.com/root-project/root/pull/1766:0,security,Updat,Update,0,Update Davix builtin;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1766
https://github.com/root-project/root/pull/1768:1075,availability,degrad,degradation,1075,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:628,deployability,automat,automatically,628,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:642,deployability,manag,manage,642,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:718,deployability,contain,container,718,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1036,deployability,configurat,configuration,1036,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:642,energy efficiency,manag,manage,642,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:694,energy efficiency,adapt,adapted,694,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:694,integrability,adapt,adapted,694,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1036,integrability,configur,configuration,1036,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:24,interoperability,prox,proxies,24,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:694,interoperability,adapt,adapted,694,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:11,modifiability,reu,reuse,11,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:694,modifiability,adapt,adapted,694,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1036,modifiability,configur,configuration,1036,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1063,performance,perform,performance,1063,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1141,performance,time,times,1141,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1075,reliability,degrad,degradation,1075,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:642,safety,manag,manage,642,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:983,safety,input,input,983,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:143,security,Hash,Hash,143,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:277,security,Hash,Hash,277,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:379,security,hash,hash,379,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:863,security,sign,significant,863,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1036,security,configur,configuration,1036,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:628,testability,automat,automatically,628,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:983,usability,input,input,983,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1768:1063,usability,perform,performance,1063,"ROOT-9316: reuse branch proxies for TTreeReader{Value,Array} when they are attached to the same branch.; TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer. These changes will need to be backported at least to ROOT 6.12.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1768
https://github.com/root-project/root/pull/1769:144,availability,restor,restore,144,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1459,deployability,patch,patch,1459,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1386,integrability,buffer,buffer,1386,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:166,interoperability,compatib,compatibility,166,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:265,performance,cach,caches,265,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:311,performance,cach,cache,311,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:582,performance,cach,cache,582,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:765,performance,cach,cache,765,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:842,performance,cach,cache,842,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1020,performance,cach,cached,1020,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1319,performance,deadlock,deadlock,1319,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:144,reliability,restor,restore,144,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:927,reliability,doe,does,927,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1459,safety,patch,patch,1459,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:647,security,access,accessed,647,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1459,security,patch,patch,1459,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1660,testability,simpl,simply,1660,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:21,usability,support,support,21,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1009,usability,clear,clears,1009,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1153,usability,clear,clearing,1153,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1407,usability,clear,cleared,1407,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1555,usability,clear,clearing,1555,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1769:1660,usability,simpl,simply,1660,"add kDoNotDisconnect support to TFilePrefetch; This PR propagates the disconnect action from TFileCacheRead to TFilePrefetch. This is needed to restore TFilePrefetch compatibility with the CMS use of kDoNotDisconnect to swap TTreeCaches. CMS frequently swaps TTree caches with code like. filePtr_->SetCacheRead(cache, nullptr , TFile::kDoNotDisconnect);. branch->GetEntry(entryNumber);. filePtr_->SetCacheRead(nullptr, nullptr , TFile::kDoNotDisconnect);. This is done partially for ownership reasons and partially because CMS uses multiple TTreeCaches for different use cases (one cache for frequently read branches, a second for less frequently accessed branches, and potentially one or two more specialized use cases). kDoNotDisconnect tells the TFile that this cache may later be reconnected to the TFile, so it should not disconnect the cache from the file. TFile propagates the flag to TFileCacheRead, but TFileCacheRead does not propagate it to TFilePrefetch. If pre-fetching is enabled, TFilePrefetch clears its cached blocks due to this commit:. https://github.com/root-project/root/commit/4290bf4942285b754b2edb7bffd122bcf36c979d. which added clearing of the read and pending prefetch lists when SetFile() is called. This violates the assumptions made by TTreeCache in the kDoNotDisconnect case, leading to a deadlock where `TTreeCache::ReadBufferPrefetch` waits forever on a buffer that has been cleared from the prefetched and pending lists. This patch propagates the kDisconnect/kDoNotDisconnect action flag to `TFilePrefetch::SetFile`, only clearing the fetched and pending lists in the kDisconnect case. (The same end could be accomplished more simply by just not calling TFilePrefetch::SetFile() for the kDoNotDisconnect case; propagating the action seems more correct to me, but it is a matter of taste.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1769
https://github.com/root-project/root/pull/1770:160,deployability,contain,containing,160,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:71,energy efficiency,model,models,71,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:208,energy efficiency,model,model,208,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:15,modifiability,variab,variable,15,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:98,safety,avoid,avoiding,98,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:262,safety,Test,Test,262,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:71,security,model,models,71,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:208,security,model,model,208,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:285,security,sign,significantly,285,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:87,testability,simpl,simplified,87,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:235,testability,simpl,simplify,235,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:262,testability,Test,Test,262,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:267,testability,coverag,coverage,267,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:87,usability,simpl,simplified,87,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1770:235,usability,simpl,simplify,235,"[TDF] Backport variable bins fix to v6.12; the implementation of histo models has been simplified avoiding code duplication. The creation of the shared_pointer containing the histogram has been moved to. the model classes, in order to simplify the TDFInterface. Test coverage has been significantly increased.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1770
https://github.com/root-project/root/pull/1772:44,deployability,manag,management,44,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:44,energy efficiency,manag,management,44,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:74,energy efficiency,Profil,Profile,74,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:37,performance,memor,memory,37,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:74,performance,Profil,Profile,74,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:44,safety,manag,management,44,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:137,safety,avoid,avoiding,137,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1772:37,usability,memor,memory,37,"[TDF] Detach TDF results from ROOT's memory management; Histo{1,2,3}D and Profile{1,2}D now return objects whose. fDirectory == nullptr, avoiding the possibility of double deletes. due to fDirectory being deleted before the TResultProxy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1772
https://github.com/root-project/root/pull/1773:6,safety,Test,Test,6,[TDF] Test that we actually read the friend branch; ...even if it has the same name as a branch in the main tree.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1773
https://github.com/root-project/root/pull/1773:6,testability,Test,Test,6,[TDF] Test that we actually read the friend branch; ...even if it has the same name as a branch in the main tree.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1773
https://github.com/root-project/root/pull/1774:12,deployability,releas,release,12,Use -O3 for release. (Accelerates clang by factor 3.6!);,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1774
https://github.com/root-project/root/pull/1775:592,availability,state,statements,592,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:187,deployability,build,build,187,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:347,deployability,instal,installed,347,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:411,deployability,build,build-environment-updates,411,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:501,deployability,instal,installed,501,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:612,deployability,build,build,612,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:592,integrability,state,statements,592,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:473,interoperability,format,format,473,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:529,modifiability,extens,extensive,529,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:429,safety,updat,updates,429,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:583,safety,Avoid,Avoid,583,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:263,security,apt,apt-get,263,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:429,security,updat,updates,429,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:0,testability,Simpl,Simplify,0,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:0,usability,Simpl,Simplify,0,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:406,usability,user,user,406,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1775:641,usability,clear,clearly,641,"Simplify travis runner; This fixes and cleans up the Travis runner; most notably, things like modern CMake and clang 5.0 now come by default (since last December). In theory, this should build much faster since several minutes per job was being spent waiting for apt-get to work. This moves the scripts in `.travis` to `.ci/*`. * CMake 3.9 is now installed by default on Travis: https://docs.travis-ci.com/user/build-environment-updates/2017-12-12/. * Clang 5.0 (and clang-format, clang-tidy) are now installed on Travis. * Move extensive setup to .ci/*. * Fix usage of yaml keys. * Avoid if statements by using build matrix entries. * Note clearly that one block of code will not run. * Remove comments about interleaved macOS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1775
https://github.com/root-project/root/pull/1777:30,integrability,interfac,interface,30,"[PyROOT][WIP] Add numpy array interface (with py3 support); Same than #1753, but fixed the py2/py3 incompatibility (sry for that).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1777
https://github.com/root-project/root/pull/1777:30,interoperability,interfac,interface,30,"[PyROOT][WIP] Add numpy array interface (with py3 support); Same than #1753, but fixed the py2/py3 incompatibility (sry for that).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1777
https://github.com/root-project/root/pull/1777:99,interoperability,incompatib,incompatibility,99,"[PyROOT][WIP] Add numpy array interface (with py3 support); Same than #1753, but fixed the py2/py3 incompatibility (sry for that).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1777
https://github.com/root-project/root/pull/1777:30,modifiability,interfac,interface,30,"[PyROOT][WIP] Add numpy array interface (with py3 support); Same than #1753, but fixed the py2/py3 incompatibility (sry for that).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1777
https://github.com/root-project/root/pull/1777:50,usability,support,support,50,"[PyROOT][WIP] Add numpy array interface (with py3 support); Same than #1753, but fixed the py2/py3 incompatibility (sry for that).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1777
https://github.com/root-project/root/pull/1778:87,availability,cluster,clustered,87,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:136,availability,avail,available,136,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:218,availability,cluster,cluster,218,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:372,availability,cluster,cluster,372,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:514,availability,cluster,cluster,514,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:589,availability,cluster,cluster,589,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:661,availability,cluster,clustered,661,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:904,availability,cluster,cluster,904,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1120,availability,avail,available,1120,"the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1147,availability,avail,available,1147," TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1257,availability,cluster,cluster,1257," situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1738,availability,consist,consist,1738,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1807,availability,cluster,cluster,1807,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1942,availability,degrad,degraded,1942,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:2163,availability,sli,slightly,2163,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:87,deployability,cluster,clustered,87,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:218,deployability,cluster,cluster,218,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:372,deployability,cluster,cluster,372,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:514,deployability,cluster,cluster,514,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:589,deployability,cluster,cluster,589,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:661,deployability,cluster,clustered,661,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:904,deployability,cluster,cluster,904,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:985,deployability,contain,containing,985,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1065,deployability,contain,containing,1065,"en reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer fro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1257,deployability,cluster,cluster,1257," situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1807,deployability,cluster,cluster,1807,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:427,energy efficiency,current,current,427,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:446,energy efficiency,load,loaded,446,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1022,energy efficiency,load,loaded,1022,"adly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:609,integrability,event,events,609,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:732,integrability,event,events,732,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:806,integrability,Event,EventAuxiliary,806,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1041,integrability,Event,EventAuxiliary,1041,"vent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, resta",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1415,integrability,Event,EventAuxiliary,1415,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1570,integrability,event,eventhough,1570,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:2060,integrability,buffer,buffer,2060,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:2123,integrability,event,event,2123,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:129,performance,memor,memory,129,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:446,performance,load,loaded,446,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1022,performance,load,loaded,1022,"adly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1172,performance,time,time,1172,"t the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1375,performance,cach,cache,1375,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1483,performance,cach,cache,1483,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1660,performance,memor,memory,1660,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1952,performance,perform,performance,1952,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:136,reliability,availab,available,136,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1120,reliability,availab,available,1120,"the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1147,reliability,availab,available,1147," TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1942,reliability,degrad,degraded,1942,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:2163,reliability,sli,slightly,2163,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:0,safety,Avoid,Avoid,0,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:45,safety,Prevent,Prevent,45,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:136,safety,avail,available,136,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1120,safety,avail,available,1120,"the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1147,safety,avail,available,1147," TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1461,safety,valid,valid,1461,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1771,safety,valid,valid,1771,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:2081,safety,valid,valid,2081,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:45,security,Preven,Prevent,45,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:136,security,availab,available,136,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1120,security,availab,available,1120,"the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1147,security,availab,available,1147," TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:129,usability,memor,memory,129,"Avoid wild over read in badly clusted files; Prevent wild over-read when reading badly clustered file. . In some cases where the memory available to the TTreeCache can not fit the entirety. of (potentially odd-shaped) cluster, the TTreeCache could end up with a situation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A fu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1660,usability,memor,memory,1660,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1703,usability,behavi,behavior,1703,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1738,usability,consist,consist,1738,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1762,usability,minim,minimum,1762,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1778:1952,usability,perform,performance,1952,"uation. where (starting at some point) it is invalidated at each entry *and* the basket. from the previous cluster boundary up to some entry number less than the current. entry are loaded over and over again (until the entry number reaches the next cluster. boundary). . In a case encountered by CMS, a TTree has a recorded cluster size of 165 events. However the TTree. appears to not have been clustered; most basket size are the same and seem to be flushed at 139 events. interval. A few branches are flushed less frequently, for example EventAuxiliary is flushed every 459. entries. . As a consequence when entry 417 is requested, the cluster boundary is calculated as 330 and. the first end as 495. Then all basket containing entries in that range are loaded, including. EventAuxiliary's basket containing entries 459 to 917. Then 917 is the highest available (partial). entry available. Thus the next time the TTreeCache is invalidated is when entry 918 is requested. As that point the cluster boundary is calculated as 845 and the first end as 495, however. (with the small enough TTreeCache size), the cache is full as soon as the basket for EventAuxiliary. is added. This resulted in a 'valid' range for this cache of 845 to 917 and lead to the reading. all the baskets added so far ... and thus eventhough none of them would be used for reading. and they already had been read once in memory. Then for entry 919, the exact same behavior. repeated. . The solution consist on marking the 'minimum' valid range as being 'at least' one cluster wide. . Thus in the example above for entry 918 through 989, **only** the missing baskets are read. individually resulting in 'degraded' performance but **not** a wild over-read. . A future enhancement would be, in those cases, restart the next buffer from the last valid. entry + 1 rather than the previous event boundary. This would result in a 'slightly' over-read. (some baskets might be read twice) rather than the wild useless over-read we had.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1778
https://github.com/root-project/root/pull/1779:7,deployability,releas,release,7,adjust release notes formatting;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1779
https://github.com/root-project/root/pull/1779:21,interoperability,format,formatting,21,adjust release notes formatting;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1779
https://github.com/root-project/root/pull/1780:46,deployability,log,logic,46,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:6,modifiability,Refact,Refactor,6,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:6,performance,Refactor,Refactor,6,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:46,safety,log,logic,46,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:46,security,log,logic,46,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:46,testability,log,logic,46,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1780:165,usability,support,support,165,"[TDF] Refactor Columnname2columntypename; The logic to get the typename of a TTree leaf/branch is now factored. out into its own function, has been streamlined, and support for. leafnames with multiple dots (""b1.b2.leaf"") has been added.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1780
https://github.com/root-project/root/pull/1781:0,deployability,Updat,Update,0,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:47,deployability,updat,update,47,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:67,deployability,Updat,Update,67,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:105,interoperability,conflict,conflict,105,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:16,performance,parallel,parallelisation,16,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:0,safety,Updat,Update,0,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:47,safety,updat,update,47,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:67,safety,Updat,Update,67,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:0,security,Updat,Update,0,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:47,security,updat,update,47,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1781:67,security,Updat,Update,67,Update TMVA BDT parallelisation PR. This is un update of PR #723 ; Update and replace PR #723 fixing the conflict with master,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1781
https://github.com/root-project/root/pull/1784:1411,availability,degrad,degradation,1411,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:650,deployability,automat,automatically,650,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:664,deployability,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1054,deployability,contain,container,1054,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1372,deployability,configurat,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:664,energy efficiency,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1030,energy efficiency,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1030,integrability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1372,integrability,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:42,interoperability,prox,proxies,42,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:942,interoperability,prox,proxy,942,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:970,interoperability,prox,proxy,970,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1030,interoperability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:29,modifiability,reu,reuse,29,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1030,modifiability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1372,modifiability,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1399,performance,perform,performance,1399,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1477,performance,time,times,1477,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1411,reliability,degrad,degradation,1411,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:664,safety,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:783,safety,input,inputs,783,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:847,safety,except,exception,847,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1319,safety,input,input,1319,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:165,security,Hash,Hash,165,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:299,security,Hash,Hash,299,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:401,security,hash,hash,401,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1199,security,sign,significant,1199,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1372,security,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:650,testability,automat,automatically,650,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:778,usability,user,user,778,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:783,usability,input,inputs,783,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1319,usability,input,input,1319,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1784:1399,usability,perform,performance,1399,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1784
https://github.com/root-project/root/pull/1785:25,integrability,interfac,interface,25,webgui: introduce binary interface for TWebWindow; Now binary data can be send from server to clients. Idea later use this functionality to send large blobs of data like vertices array for geometry display,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1785
https://github.com/root-project/root/pull/1785:25,interoperability,interfac,interface,25,webgui: introduce binary interface for TWebWindow; Now binary data can be send from server to clients. Idea later use this functionality to send large blobs of data like vertices array for geometry display,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1785
https://github.com/root-project/root/pull/1785:25,modifiability,interfac,interface,25,webgui: introduce binary interface for TWebWindow; Now binary data can be send from server to clients. Idea later use this functionality to send large blobs of data like vertices array for geometry display,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1785
https://github.com/root-project/root/pull/1786:1411,availability,degrad,degradation,1411,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:650,deployability,automat,automatically,650,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:664,deployability,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1054,deployability,contain,container,1054,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1372,deployability,configurat,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:664,energy efficiency,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1030,energy efficiency,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1030,integrability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1372,integrability,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:42,interoperability,prox,proxies,42,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:942,interoperability,prox,proxy,942,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:970,interoperability,prox,proxy,970,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1030,interoperability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:29,modifiability,reu,reuse,29,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1030,modifiability,adapt,adapted,1030,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1372,modifiability,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1399,performance,perform,performance,1399,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1477,performance,time,times,1477,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1411,reliability,degrad,degradation,1411,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:664,safety,manag,manage,664,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:783,safety,input,inputs,783,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:847,safety,except,exception,847,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1319,safety,input,input,1319,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:165,security,Hash,Hash,165,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:299,security,Hash,Hash,299,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:401,security,hash,hash,401,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1199,security,sign,significant,1199,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1372,security,configur,configuration,1372,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:650,testability,automat,automatically,650,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:778,usability,user,user,778,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:783,usability,input,inputs,783,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1319,usability,input,input,1319,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1786:1399,usability,perform,performance,1399,"[TTreeReader] Fix ROOT-9316: reuse branch proxies for TTreeReader{Val; ue,Array}. when they are attached to the same branch. TNamedBranchProxy did not implement a Hash method. Therefore when adding TNamedBranchProxy instances to the THashList dedicated to their bookkeping in TTreeReader TObject::Hash was used. Unfortunately when trying to find the TNamedBranchProxies, their name was used and the hash was built differently by THashList (based on the name). In order to fix this the following steps were taken. - THashList was replaced by an unordered_map with names as keys and unique_ptr<TNamedBranchProxy> as values. The unique_ptr is used to automatically manage ownership. - The key is not the name of the branch as known by the branch any more but rather the name the user inputs in the constructor of the TTreeReader{Array,Value}. - An exception is thrown in debug mode if the system tries to push in the TTreeReader collection of proxy with a name held by a proxy in that collection. - The methods of TTreeReader were adapted to use this new container as well as the code in TTreeReaderValue and TTreeReaderArray. A real usecase from CMS where the mass of the W boson is studied shows a significant speedup (30%). The code uses TDataFrame and several nodes are created which read from the same branch in an input tree which holds weights in a collection. This configuration stressed the performance degradation pattern fixed by this commit as it triggered multiple times the deserialisation of the ""weights branch"". Thanks to Elisabetta Manca and Lorenzo Bianchini for providing the bug report and initial reproducer.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1786
https://github.com/root-project/root/pull/1788:6,availability,Restor,Restore,6,[WIP] Restore default CMAKE_BUILD_TYPE to RelWithDebInfo;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1788
https://github.com/root-project/root/pull/1788:6,reliability,Restor,Restore,6,[WIP] Restore default CMAKE_BUILD_TYPE to RelWithDebInfo;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1788
https://github.com/root-project/root/pull/1789:7,integrability,configur,configure,7,Remove configure/make files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1789
https://github.com/root-project/root/pull/1789:7,modifiability,configur,configure,7,Remove configure/make files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1789
https://github.com/root-project/root/pull/1789:7,security,configur,configure,7,Remove configure/make files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1789
https://github.com/root-project/root/pull/1790:2023,availability,slo,slower,2023,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1245,deployability,releas,release,1245,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1253,deployability,build,build,1253,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1813,deployability,modul,modules,1813,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1991,deployability,patch,patch,1991,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1998,deployability,releas,release,1998,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2006,deployability,modul,modules,2006,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2090,deployability,releas,release,2090,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2106,deployability,modul,modules,2106,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:30,energy efficiency,optim,optimization,30,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:428,energy efficiency,reduc,reduce,428,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1146,energy efficiency,cpu,cpu,1146,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1356,energy efficiency,cpu,cpu,1356,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1508,energy efficiency,cpu,cpu,1508,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1642,energy efficiency,cpu,cpu,1642,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1681,energy efficiency,cpu,cpu,1681,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1754,energy efficiency,cpu,cpu,1754,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1848,energy efficiency,cpu,cputime,1848,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1965,energy efficiency,Load,LoadModules,1965,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2033,energy efficiency,cpu,cpu,2033,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:452,modifiability,variab,variables,452,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:513,modifiability,variab,variables,513,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:579,modifiability,variab,variables,579,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:661,modifiability,variab,variables,661,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1813,modifiability,modul,modules,1813,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2006,modifiability,modul,modules,2006,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2106,modifiability,modul,modules,2106,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:14,performance,time,time,14,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:23,performance,memor,memory,23,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:30,performance,optimiz,optimization,30,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:90,performance,time,time,90,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:393,performance,time,time,393,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:808,performance,time,time,808,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1146,performance,cpu,cpu,1146,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1150,performance,time,time,1150,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1177,performance,time,time,1177,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1206,performance,memor,memory,1206,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1237,performance,time,time,1237,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1309,performance,time,time,1309,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1356,performance,cpu,cpu,1356,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1360,performance,time,time,1360,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1405,performance,time,times,1405,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1418,performance,time,time,1418,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1463,performance,time,times,1463,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1475,performance,memor,memory,1475,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1508,performance,cpu,cpu,1508,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1512,performance,time,time,1512,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1549,performance,time,time,1549,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1585,performance,memor,memory,1585,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1642,performance,cpu,cpu,1642,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1646,performance,time,time,1646,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1663,performance,memor,memory,1663,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1681,performance,cpu,cpu,1681,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1685,performance,time,time,1685,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1721,performance,memor,memory,1721,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1754,performance,cpu,cpu,1754,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1758,performance,time,time,1758,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1784,performance,memor,memory,1784,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1848,performance,cpu,cputime,1848,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1866,performance,memor,memory,1866,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1897,performance,memor,memory,1897,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1946,performance,memor,memory,1946,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1965,performance,Load,LoadModules,1965,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2033,performance,cpu,cpu,2033,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2037,performance,time,time,2037,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2071,performance,memor,memory,2071,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2023,reliability,slo,slower,2023,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1813,safety,modul,modules,1813,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1991,safety,patch,patch,1991,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2006,safety,modul,modules,2006,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2106,safety,modul,modules,2106,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1991,security,patch,patch,1991,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:23,usability,memor,memory,23,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:864,usability,hint,hint,864,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:873,usability,tip,tip,873,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:887,usability,minim,minimize,887,"ROOT start up time and memory optimization; There are some codes compiled at the start up time. For example,. - #include \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1206,usability,memor,memory,1206,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1475,usability,memor,memory,1475,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1585,usability,memor,memory,1585,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1663,usability,memor,memory,1663,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1721,usability,memor,memory,1721,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1784,usability,memor,memory,1784,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1866,usability,memor,memory,1866,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1897,usability,memor,memory,1897,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:1946,usability,memor,memory,1946,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1790:2071,usability,memor,memory,2071,"nclude \""cling/Interpreter/RuntimeUniverse.h\"". - #include \""cling/Interpreter/DynamicLookupRuntimeUniverse.h\"". - namespace cling { class Interpreter; namespace runtime { Interpreter* gCling }}}. - PrintValue. These are passed to Cling as string and initialized at the start up time. So I think it makes sense to reduce top-level global variables, #includes and eagerly deserializations. 1. Global variables. If we break at emitModule, we can get a list of global variables and functions which are actually deserialized. These include functions, variables, STL classes and all the functions derives from them. I tried to change them to for example constexpr, so that it's processed at compile time. 2. Eagerly Deserialized decls. Thanks to @Axel 's hint and tip, we could minimize eagerly deserialized decls deserialized in ASTReader::PassInterestingDeclsToConsumer. We already removed most of eagerly deserialized decls (Some are remaining to be removed, some are hard to remove and some don't cost a lot). So far, we got 9.2% of cpu time improvement, 15% real time improvement and 8.8% of memory improvement at start up time in release build. I took an average, but the variation of the real-time was very big. - root.exe -q -l. - master. cpu time = 0.09186914285714286 sec (average of 7 times). real time = 0.18371428571428572 sec (average of 7 times). res memory = 142.008 Mbytes. - HEAD. cpu time = 0.08337842857142856 sec. real time = 0.15685714285714286 sec. res memory = 129.508 Mbytes. - hsimple.C. Improved by 13% of cpu time and 8.5% of memory. - master. cpu time = 0.0954708 sec (average). res memory = 142.891 Mbytes. - HEAD. cpu time = 0.0833258 sec. res memory = 130.73 Mbytes. With modules. - Improvement by 17.7% in cputime and 2% in memory on root.exe -q -l. (For memory, small improvement is because most of the memory is taken by LoadModules). - With this patch, release modules is 11.2% slower in cpu time and 6% better in residential memory compared to release without modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1790
https://github.com/root-project/root/pull/1791:80,energy efficiency,reduc,reduce,80,"For the value printing of tuples, prefer an overload to a template; in order to reduce the deserialisations which happen at ROOT startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1791
https://github.com/root-project/root/pull/1791:34,usability,prefer,prefer,34,"For the value printing of tuples, prefer an overload to a template; in order to reduce the deserialisations which happen at ROOT startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1791
https://github.com/root-project/root/pull/1792:19,availability,error,errors,19,"Edited grammatical errors; Improved documentation, made minor changes to spelling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1792
https://github.com/root-project/root/pull/1792:19,performance,error,errors,19,"Edited grammatical errors; Improved documentation, made minor changes to spelling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1792
https://github.com/root-project/root/pull/1792:19,safety,error,errors,19,"Edited grammatical errors; Improved documentation, made minor changes to spelling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1792
https://github.com/root-project/root/pull/1792:19,usability,error,errors,19,"Edited grammatical errors; Improved documentation, made minor changes to spelling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1792
https://github.com/root-project/root/pull/1792:36,usability,document,documentation,36,"Edited grammatical errors; Improved documentation, made minor changes to spelling.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1792
https://github.com/root-project/root/pull/1794:73,availability,error,error,73,"From Axel: Fix ""cannot mangle this template type parameter type yet"" ; error on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1794
https://github.com/root-project/root/pull/1794:49,modifiability,paramet,parameter,49,"From Axel: Fix ""cannot mangle this template type parameter type yet"" ; error on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1794
https://github.com/root-project/root/pull/1794:73,performance,error,error,73,"From Axel: Fix ""cannot mangle this template type parameter type yet"" ; error on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1794
https://github.com/root-project/root/pull/1794:73,safety,error,error,73,"From Axel: Fix ""cannot mangle this template type parameter type yet"" ; error on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1794
https://github.com/root-project/root/pull/1794:73,usability,error,error,73,"From Axel: Fix ""cannot mangle this template type parameter type yet"" ; error on Windows",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1794
https://github.com/root-project/root/pull/1795:102,availability,sli,slimmed,102,"[TDF][VecOps] Add tutorial with a real analysis usecase; which shows how the programming model can be slimmed down using. TDF and VecOps comparing with the classical PyROOT approach, TTreeReader. and TDF without VecOps.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1795
https://github.com/root-project/root/pull/1795:110,availability,down,down,110,"[TDF][VecOps] Add tutorial with a real analysis usecase; which shows how the programming model can be slimmed down using. TDF and VecOps comparing with the classical PyROOT approach, TTreeReader. and TDF without VecOps.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1795
https://github.com/root-project/root/pull/1795:89,energy efficiency,model,model,89,"[TDF][VecOps] Add tutorial with a real analysis usecase; which shows how the programming model can be slimmed down using. TDF and VecOps comparing with the classical PyROOT approach, TTreeReader. and TDF without VecOps.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1795
https://github.com/root-project/root/pull/1795:102,reliability,sli,slimmed,102,"[TDF][VecOps] Add tutorial with a real analysis usecase; which shows how the programming model can be slimmed down using. TDF and VecOps comparing with the classical PyROOT approach, TTreeReader. and TDF without VecOps.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1795
https://github.com/root-project/root/pull/1795:89,security,model,model,89,"[TDF][VecOps] Add tutorial with a real analysis usecase; which shows how the programming model can be slimmed down using. TDF and VecOps comparing with the classical PyROOT approach, TTreeReader. and TDF without VecOps.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1795
https://github.com/root-project/root/pull/1796:16,deployability,patch,patch,16,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:104,deployability,patch,patch,104,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:189,deployability,deploy,deployed,189,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:231,energy efficiency,load,load,231,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:231,performance,load,load,231,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:16,safety,patch,patch,16,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:82,safety,valid,validate,82,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:104,safety,patch,patch,104,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:16,security,patch,patch,16,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:82,security,validat,validate,82,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1796:104,security,patch,patch,104,"Reverting clang patch 'Work around ROOT-6966 to unblock CMS and ATLAS; : do not validate arch.'. This patch was fixing https://sft.its.cern.ch/jira/browse/ROOT-6966 and real solution was deployed later on cling side, allowing to load target options and etc. from PCH in CIFactory.cpp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1796
https://github.com/root-project/root/pull/1798:143,deployability,contain,contain,143,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:240,deployability,patch,patch,240,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:385,deployability,build,build,385,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:526,deployability,build,builds,526,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:616,deployability,releas,release,616,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:633,deployability,build,build,633,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:707,deployability,build,builds,707,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:1943,deployability,build,build,1943,"lang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of this PR but not in the commit message.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:370,energy efficiency,reduc,reduce,370,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:2031,integrability,messag,message,2031,"lang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of this PR but not in the commit message.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:2031,interoperability,messag,message,2031,"lang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of this PR but not in the commit message.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:391,performance,time,times,391,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:240,safety,patch,patch,240,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1798:240,security,patch,patch,240,"Enable ROOT to be built with prebuilt clang and llvm.; #To do so one needs to pass -Dbuiltin_llvm=Off -Dbuiltin_clang=Off and the. PATH should contain the path to llvm-config. Note this is not enabling ROOT to work with vanilla clang! This patch allows ROOT to be built against a prebuilt clang and llvm from. https://root.cern.ch/git/{llvm.git,clang.git}. It allows to reduce ROOT's. build times (in cases when cmake decides to rebuild the in-tree llvm for. no good reason). It moves the common denominator of different ROOT builds. in one place to save space. It also allows easy switch between LLVM in. debug and release mode. To build the external clang and llvm exactly in the same way as the. in-tree builds use:. CMAKE_FLAGS=""\. -DLLVM_ENABLE_WARNINGS=OFF \. -DLLVM_INCLUDE_TESTS=OFF \. -DCLANG_INCLUDE_TESTS=OFF \. -DLLVM_INCLUDE_EXAMPLES=OFF \. -DCLANG_BUILD_TOOLS=OFF \. -DCLANG_TOOL_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_CHECK_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_BUILD=OFF \. -DCLANG_TOOL_CLANG_FORMAT_VS_BUILD=OFF \. -DCLANG_TOOL_CLANG_FUZZER_BUILD=OFF \. -DCLANG_TOOL_CLANG_IMPORT_TEST_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DCLANG_TOOL_CLANG_RENAME_BUILD=OFF \. -DCLANG_TOOL_C_ARCMT_TEST_BUILD=OFF \. -DCLANG_TOOL_C_INDEX_TEST_BUILD=OFF \. -DCLANG_TOOL_DIAGTOOL_BUILD=OFF \. -DCLANG_TOOL_LIBCLANG_BUILD=OFF \. -DCLANG_TOOL_SCAN_BUILD_BUILD=OFF \. -DCLANG_TOOL_SCAN_VIEW_BUILD=OFF \. -DLLVM_BUILD_TOOLS=ON \. -DLLVM_TOOL_LLVM_AR_BUILD=OFF \. -DCLANG_TOOL_CLANG_OFFLOAD_BUNDLER_BUILD=OFF \. -DLLVM_FORCE_USE_OLD_TOOLCHAIN=ON \. -DCLANG_ENABLE_STATIC_ANALYZER=OFF \. -DCLANG_ENABLE_ARCMT=OFF \. -DCLANG_ENABLE_FORMAT=OFF \. -DLLVM_TARGETS_TO_BUILD=host \. -DLLVM_ABI_BREAKING_CHECKS=FORCE_OFF \. -DLLVM_ENABLE_ABI_BREAKING_CHECKS=OFF \. -DCMAKE_INSTALL_PREFIX=.. \. -DCMAKE_BUILD_TYPE=Debug"". cmake ""$CMAKE_FLAGS"" ../../../sources/root-llvm/. EDIT: We actially need -DLLVM_BUILD_TOOLS=OFF to be ON to build the llvm-config binary. Fixed in the description of",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1798
https://github.com/root-project/root/pull/1799:0,availability,Restor,Restore,0,Restore TTree::Draw ability to use function return a reference to object.; . For example std::vector::at,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1799
https://github.com/root-project/root/pull/1799:15,energy efficiency,Draw,Draw,15,Restore TTree::Draw ability to use function return a reference to object.; . For example std::vector::at,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1799
https://github.com/root-project/root/pull/1799:0,reliability,Restor,Restore,0,Restore TTree::Draw ability to use function return a reference to object.; . For example std::vector::at,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1799
https://github.com/root-project/root/pull/1800:86,availability,cluster,cluster,86,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:86,deployability,cluster,cluster,86,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:114,integrability,discover,discovered,114,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:114,interoperability,discover,discovered,114,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:35,safety,prevent,prevents,35,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:35,security,preven,prevents,35,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1800:114,usability,discov,discovered,114,tree cloner history tracking; This prevents the main issue leading to a file with bad cluster 'history' which was discovered while investigating [ROOT-9318](https://sft.its.cern.ch/jira/browse/ROOT-9318).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1800
https://github.com/root-project/root/pull/1801:96,security,Hash,Hashlist,96,"TFileMerger: search through vector with skip set; Try searching through a vector instead of the Hashlist, making use of a list of elements to skip, then escaping the loop",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1801
https://github.com/root-project/root/pull/1803:14,interoperability,conflict,conflicts,14,"Fix potential conflicts with system headers on Windows; Don't copy the clang headers, which can conflict with the system headers, like for example ""future"" which can now be put back in the pch headers list",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1803
https://github.com/root-project/root/pull/1803:96,interoperability,conflict,conflict,96,"Fix potential conflicts with system headers on Windows; Don't copy the clang headers, which can conflict with the system headers, like for example ""future"" which can now be put back in the pch headers list",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1803
https://github.com/root-project/root/pull/1804:0,integrability,Inject,Inject,0,"Inject the ""_tls_array"" constant (0x2C) symbol to avoid unresolved symbol er; ror when JITting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1804
https://github.com/root-project/root/pull/1804:50,safety,avoid,avoid,50,"Inject the ""_tls_array"" constant (0x2C) symbol to avoid unresolved symbol er; ror when JITting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1804
https://github.com/root-project/root/pull/1804:0,security,Inject,Inject,0,"Inject the ""_tls_array"" constant (0x2C) symbol to avoid unresolved symbol er; ror when JITting",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1804
https://github.com/root-project/root/pull/1805:16,availability,error,error,16,Fix compilation error C2131: expression did not evaluate to a constan; t (on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1805
https://github.com/root-project/root/pull/1805:16,performance,error,error,16,Fix compilation error C2131: expression did not evaluate to a constan; t (on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1805
https://github.com/root-project/root/pull/1805:16,safety,error,error,16,Fix compilation error C2131: expression did not evaluate to a constan; t (on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1805
https://github.com/root-project/root/pull/1805:16,usability,error,error,16,Fix compilation error C2131: expression did not evaluate to a constan; t (on Windows),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1805
https://github.com/root-project/root/pull/1806:16,availability,error,error,16,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:54,availability,error,error,54,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:147,interoperability,specif,specified,147,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:16,performance,error,error,16,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:54,performance,error,error,54,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:16,safety,error,error,16,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:54,safety,error,error,54,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:16,usability,error,error,16,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1806:54,usability,error,error,54,Fix compilation error on Windows; Fix the compilation error C3493: 'everyN' cannot be implicitly captured because no default capture mode has been specified,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1806
https://github.com/root-project/root/pull/1807:9,deployability,patch,patches,9,V6 12 00 patches tree cloner history tracking;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1807
https://github.com/root-project/root/pull/1807:9,safety,patch,patches,9,V6 12 00 patches tree cloner history tracking;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1807
https://github.com/root-project/root/pull/1807:9,security,patch,patches,9,V6 12 00 patches tree cloner history tracking;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1807
https://github.com/root-project/root/pull/1808:8,availability,error,error,8,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1808:274,deployability,fail,failing,274,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1808:8,performance,error,error,8,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1808:274,reliability,fail,failing,274,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1808:8,safety,error,error,8,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1808:8,usability,error,error,8,Fix for error if include_directories are empty; Running ROOT_GENERATE_DICTIONARY when you have not set any global include directories (which will happen if you are using modern CMake principles) and don't have an `inc` dir will cause CMake to crash due to REMOVE_DUPLICATES failing to run on an empty list. . This fixes that crash.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1808
https://github.com/root-project/root/pull/1809:268,availability,error,error,268,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:439,availability,state,statement,439,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:242,deployability,build,build,242,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:122,integrability,standardiz,standardizes,122,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:439,integrability,state,statement,439,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:122,interoperability,standard,standardizes,122,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:178,interoperability,mismatch,mismatch,178,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:268,performance,error,error,268,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:268,safety,error,error,268,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:459,safety,test,tests,459,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:511,safety,test,tests,511,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:459,testability,test,tests,459,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:511,testability,test,tests,511,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1809:268,usability,error,error,268,"MPI and OpenMP Minuit2 fixes; There was some naming inconsistency between `minuit2-*` and `minuit2_*` CMake options; this standardizes that to match ROOT (`minuit2_*`); due to a mismatch, mpi and openmp could not be enabled in the standalone build. This also fixes an error in commit 1a75a687f19 that has incorrect CMake syntax (mixing `set_property` and `set_target_properties` style - would only affect CMake < 3.9 due to surrounding if statement). Running tests with MPI enabled will actually try to run the tests with MPI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1809
https://github.com/root-project/root/pull/1810:95,deployability,patch,patch,95,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:101,energy efficiency,reduc,reduces,101,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:175,energy efficiency,reduc,reduces,175,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:95,safety,patch,patch,95,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:95,security,patch,patch,95,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:187,security,hash,hash,187,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1810:47,usability,Support,Support,47,"[backport][clang] Backport r328404: ""[ODRHash] Support pointer and re; ference types."". This patch reduces deserializing of lazy template specializations from the PCH as it reduces the hash collisions (now we distinguish between pointer and reference types).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1810
https://github.com/root-project/root/pull/1811:225,availability,slo,slot,225,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:308,availability,slo,slot,308,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:101,deployability,BUILD,BUILDTYPE,101,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:111,deployability,Releas,Release,111,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:156,deployability,build,build,156,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:214,modifiability,paramet,parameter,214,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:266,modifiability,paramet,parameter,266,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:140,performance,perform,performance-,140,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:225,reliability,slo,slot,225,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:308,reliability,slo,slot,308,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1811:140,usability,perform,performance-,140,"[TDF] Fix bogus warning in gcc6.2; This warning was first seen in rootbench:. ```c++. root-benchmark/BUILDTYPE/Release/COMPILER/gcc62/LABEL/performance-cc7/build/include/ROOT/TDFActionHelpers.hxx:745:34:. warning: parameter slot set but not used [-Wunused-but-set-parameter]. void SetBranches(unsigned int slot, BranchTypes&... values, StaticSeq<S...> /*dummy*/). ^~~~. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1811
https://github.com/root-project/root/pull/1813:130,availability,failur,failures,130,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:130,deployability,fail,failures,130,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:191,deployability,build,build,191,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:130,performance,failur,failures,130,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:130,reliability,fail,failures,130,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:161,safety,test,testDetails,161,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:177,safety,test,test,177,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:231,safety,test,test-dataframe-snapshot,231,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:161,testability,test,testDetails,161,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:177,testability,test,test,177,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1813:231,testability,test,test-dataframe-snapshot,231,"Revert ""Insure TTreeCloner keep the AutoFlush history.""; This reverts commit 6657223efbc8d356fe3103c7010922dded6791a2. It caused [failures](http://cdash.cern.ch/testDetails.php?test=40653603&build=483771). in gtest-tree-treeplayer-test-dataframe-snapshot (see discussion at #1800 ).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1813
https://github.com/root-project/root/pull/1814:2055,availability,slo,slower,2055,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:17,deployability,fail,failing,17,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:64,deployability,modul,modules,64,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:97,deployability,fail,failing,97,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:117,deployability,modul,modules,117,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:273,deployability,modul,modules,273,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:307,deployability,patch,patch,307,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:341,deployability,modul,modules,341,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:391,deployability,patch,patch,391,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:455,deployability,modul,modules,455,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:722,deployability,modul,modules,722,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:800,deployability,releas,release,800,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:808,deployability,build,build,808,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:822,deployability,modul,modules,822,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:968,deployability,releas,release,968,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:976,deployability,build,build,976,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:987,deployability,modul,modules,987,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1006,deployability,patch,patch,1006,"es] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1175,deployability,modul,modules,1175,"htly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1342,deployability,Releas,Release,1342,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1350,deployability,build,build,1350,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1364,deployability,modul,modules,1364,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1673,deployability,Releas,Release,1673,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1681,deployability,build,build,1681,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1692,deployability,modul,modules,1692,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1711,deployability,patch,patch,1711,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2102,deployability,modul,modules,2102,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2256,deployability,modul,modules,2256,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:73,energy efficiency,Current,Currently,73,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:837,energy efficiency,cpu,cpu,837,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1019,energy efficiency,cpu,cpu,1019,"ing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1450,energy efficiency,Cpu,Cpu,1450,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1549,energy efficiency,cpu,cpu,1549,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1793,energy efficiency,Cpu,Cpu,1793,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1888,energy efficiency,cpu,cpu,1888,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2089,energy efficiency,load,load,2089,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2201,energy efficiency,reduc,reduces,2201,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2248,energy efficiency,load,loading,2248,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:64,modifiability,modul,modules,64,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:117,modifiability,modul,modules,117,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:273,modifiability,modul,modules,273,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:341,modifiability,modul,modules,341,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:455,modifiability,modul,modules,455,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:722,modifiability,modul,modules,722,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:822,modifiability,modul,modules,822,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:987,modifiability,modul,modules,987,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1175,modifiability,modul,modules,1175,"htly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1364,modifiability,modul,modules,1364,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1692,modifiability,modul,modules,1692,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2102,modifiability,modul,modules,2102,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2256,modifiability,modul,modules,2256,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:360,performance,time,time,360,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:745,performance,time,time,745,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:750,performance,perform,performance,750,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:779,performance,memor,memory,779,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:837,performance,cpu,cpu,837,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:841,performance,time,time,841,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:870,performance,time,time,870,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:899,performance,memor,memory,899,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:928,performance,memor,memory,928,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1019,performance,cpu,cpu,1019,"ing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1023,performance,time,time,1023,"runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1052,performance,time,time,1052,"reloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1081,performance,memor,memory,1081,"36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. tr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1110,performance,memor,memory,1110,"ime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1194,performance,time,time,1194,"odules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1203,performance,memor,memory,1203,"e want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1218,performance,time,times,1218,"these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution ti",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1245,performance,time,time,1245," can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1331,performance,memor,memory,1331,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1430,performance,Time,Time,1430,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1450,performance,Cpu,Cpu,1450,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1454,performance,Time,Time,1454,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1535,performance,memor,memory,1535,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1549,performance,cpu,cpu,1549,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1553,performance,time,time,1553,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1583,performance,time,time,1583,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1613,performance,memor,memory,1613,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1642,performance,memor,memory,1642,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1773,performance,Time,Time,1773,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1793,performance,Cpu,Cpu,1793,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1797,performance,Time,Time,1797,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1876,performance,memor,memory,1876,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1888,performance,cpu,cpu,1888,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1892,performance,time,time,1892,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1921,performance,time,time,1921,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1950,performance,memor,memory,1950,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1979,performance,memor,memory,1979,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2070,performance,time,time,2070,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2089,performance,load,load,2089,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2121,performance,time,time,2121,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2209,performance,execution time,execution time,2209,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2248,performance,load,loading,2248,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:17,reliability,fail,failing,17,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:97,reliability,fail,failing,97,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2055,reliability,slo,slower,2055,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:44,safety,test,tests,44,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:64,safety,modul,modules,64,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:87,safety,test,tests,87,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:117,safety,modul,modules,117,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:227,safety,test,test,227,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:273,safety,modul,modules,273,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:307,safety,patch,patch,307,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:341,safety,modul,modules,341,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:391,safety,patch,patch,391,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:406,safety,test,tests,406,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:455,safety,modul,modules,455,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:722,safety,modul,modules,722,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:822,safety,modul,modules,822,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:987,safety,modul,modules,987,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1006,safety,patch,patch,1006,"es] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1175,safety,modul,modules,1175,"htly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1364,safety,modul,modules,1364,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1692,safety,modul,modules,1692,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1711,safety,patch,patch,1711,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2102,safety,modul,modules,2102,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:2256,safety,modul,modules,2256,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:307,security,patch,patch,307,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:391,security,patch,patch,391,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1006,security,patch,patch,1006,"es] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1711,security,patch,patch,1711,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:44,testability,test,tests,44,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:87,testability,test,tests,87,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:227,testability,test,test,227,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:406,testability,test,tests,406,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:543,usability,support,support,543,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:750,usability,perform,performance,750,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:779,usability,memor,memory,779,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:899,usability,memor,memory,899,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:928,usability,memor,memory,928,"[cxxmodules] Fix failing runtime_cxxmodules tests by preloading modules; Currently, 36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbyt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1081,usability,memor,memory,1081,"36 tests are failing for runtime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. tr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1110,usability,memor,memory,1110,"ime modules:. https://epsft-jenkins.cern.ch/view/ROOT/job/root-nightly-runtime-cxxmodules/. We want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1203,usability,memor,memory,1203,"e want to make these test pass so that we can say that the runtime modules is. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1331,usability,memor,memory,1331,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1535,usability,memor,memory,1535,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1613,usability,memor,memory,1613,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1642,usability,memor,memory,1642,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1876,usability,memor,memory,1876,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1950,usability,memor,memory,1950,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1814:1979,usability,memor,memory,1979,"s. finally working. This patch enables ROOT to preload all modules at startup time. In my. environment, this patch fixes 14 tests for runtime cxxmodules. Preloading all the modules has several advantages. 1. We do not have to. rely on rootmap files which don't support some features (namespaces and. templates) 2. Lookup would be faster because we don't have to do. trampoline via rootmap files. The only disadvantage of preloading all the modules is the startup time performance. `root.exe -q -l memory.C`. This is a release build without modules:. ```. cpu time = 0.091694 seconds. sys time = 0.026187 seconds. res memory = 133.008 Mbytes. vir memory = 217.742 Mbytes. ```. This is a release build with modules, with this patch:. ```. cpu time = 0.234134 seconds. sys time = 0.066774 seconds. res memory = 275.301 Mbytes. vir memory = 491.832 Mbytes. ```. As you can see, preloading all the modules makes both time and memory 2. to 3 times worse **at a startup time**. **Edit** : With hsimple.C. `root.exe -l -b tutorials/hsimple.C -q ~/CERN/ROOT/memory.C`. Release build without modules:. ```. Processing tutorials/hsimple.C... . hsimple : Real Time = 0.04 seconds Cpu Time = 0.05 seconds . (TFile *) 0x555ae2a9d560 . Processing /home/yuka/CERN/ROOT/memory.C... . cpu time = 0.173591 seconds . sys time = 0.011835 seconds . res memory = 135.32 Mbytes . vir memory = 209.664 Mbytes . ```. Release build with modules, with this patch:. ```. Processing tutorials/hsimple.C... hsimple : Real Time = 0.04 seconds Cpu Time = 0.04 seconds. (TFile *) 0x55d1b036d230. Processing /home/yuka/CERN/ROOT/memory.C... cpu time = 0.290742 seconds. sys time = 0.043851 seconds. res memory = 256.844 Mbytes. vir memory = 438.484 Mbytes. ```. However, it is a matter of course that we get slower startup time if we. try to load all the modules at startup time, not on-demand. I haven't had a good benchmark for this but, in theory, it reduces execution time instead as we're anyway loading modules after the startup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1814
https://github.com/root-project/root/pull/1815:46,integrability,Sub,Substitution,46,"[TDF] Do not snapshot ""branch."" as ""branch_""; Substitution of '.' with '_' should only happen when the dot is. in the middle of the name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1815
https://github.com/root-project/root/pull/1816:6,availability,Cluster,Cluster,6,TTree Cluster improvement;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1816
https://github.com/root-project/root/pull/1816:6,deployability,Cluster,Cluster,6,TTree Cluster improvement;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1816
https://github.com/root-project/root/pull/1817:194,integrability,configur,configurable,194,"Derived TBufferSQL from TBufferText; Use TBufferText instead of TBufferFile as base class for TBufferSQL. One can benefit from some definitions, done in TBufferText. For instance, one could use configurable float format there in the future. From other side, it is not really necessary. TBufferSQL works only with TBasketSQL and basic data types. Seems to be, object streaming not supported anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1817
https://github.com/root-project/root/pull/1817:213,interoperability,format,format,213,"Derived TBufferSQL from TBufferText; Use TBufferText instead of TBufferFile as base class for TBufferSQL. One can benefit from some definitions, done in TBufferText. For instance, one could use configurable float format there in the future. From other side, it is not really necessary. TBufferSQL works only with TBasketSQL and basic data types. Seems to be, object streaming not supported anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1817
https://github.com/root-project/root/pull/1817:194,modifiability,configur,configurable,194,"Derived TBufferSQL from TBufferText; Use TBufferText instead of TBufferFile as base class for TBufferSQL. One can benefit from some definitions, done in TBufferText. For instance, one could use configurable float format there in the future. From other side, it is not really necessary. TBufferSQL works only with TBasketSQL and basic data types. Seems to be, object streaming not supported anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1817
https://github.com/root-project/root/pull/1817:194,security,configur,configurable,194,"Derived TBufferSQL from TBufferText; Use TBufferText instead of TBufferFile as base class for TBufferSQL. One can benefit from some definitions, done in TBufferText. For instance, one could use configurable float format there in the future. From other side, it is not really necessary. TBufferSQL works only with TBasketSQL and basic data types. Seems to be, object streaming not supported anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1817
https://github.com/root-project/root/pull/1817:380,usability,support,supported,380,"Derived TBufferSQL from TBufferText; Use TBufferText instead of TBufferFile as base class for TBufferSQL. One can benefit from some definitions, done in TBufferText. For instance, one could use configurable float format there in the future. From other side, it is not really necessary. TBufferSQL works only with TBasketSQL and basic data types. Seems to be, object streaming not supported anyway",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1817
https://github.com/root-project/root/pull/1818:364,deployability,updat,update,364,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:101,integrability,pub,published,101,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:386,performance,lock,lock,386,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:0,safety,Avoid,Avoid,0,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:320,safety,valid,valid,320,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:364,safety,updat,update,364,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:6,security,access,access,6,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:364,security,updat,update,364,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1818:386,security,lock,lock,386,"Avoid access to deleted object (indirectly) from TH1::Clone.; TH1::Clone calls TH1::Copy which might published the copy-into object. to the ListOfCleanups. Clone can call RecursiveRemove, for example via TCheckHashRecursiveRemoveConsistency. when dictionary information is initialized, so we need to keep obj->fFunction valid. during its execution and protect the update with the write lock. This issues was seen as a crash in roottest-root-multicore-threadExecutor.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1818
https://github.com/root-project/root/pull/1819:6,availability,Cluster,Cluster,6,TTree Cluster Improvements.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1819
https://github.com/root-project/root/pull/1819:6,deployability,Cluster,Cluster,6,TTree Cluster Improvements.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1819
https://github.com/root-project/root/pull/1820:0,deployability,Updat,Update,0,"Update R__DEPRECATED macros.; Remove 6.12, add 6.16, 6.18, 6.20",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1820
https://github.com/root-project/root/pull/1820:0,safety,Updat,Update,0,"Update R__DEPRECATED macros.; Remove 6.12, add 6.16, 6.18, 6.20",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1820
https://github.com/root-project/root/pull/1820:0,security,Updat,Update,0,"Update R__DEPRECATED macros.; Remove 6.12, add 6.16, 6.18, 6.20",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1820
https://github.com/root-project/root/pull/1821:97,availability,failur,failure,97,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:69,deployability,patch,patch,69,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:97,deployability,fail,failure,97,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:147,deployability,fail,failing,147,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:155,deployability,modul,modules,155,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:266,deployability,build,build,266,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:304,deployability,Releas,Release,304,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:312,deployability,build,build,312,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:327,deployability,modul,modules,327,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:349,deployability,patch,patch,349,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:713,deployability,Releas,Release,713,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:721,deployability,build,build,721,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:736,deployability,modul,modules,736,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:755,deployability,patch,patch,755,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1192,deployability,Releas,Release,1192,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1200,deployability,build,build,1200,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1215,deployability,modul,modules,1215,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1237,deployability,patch,patch,1237,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1299,deployability,Releas,Release,1299,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1307,deployability,build,build,1307,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1322,deployability,modul,modules,1322,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1341,deployability,patch,patch,1341,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:442,energy efficiency,CPU,CPU,442,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:848,energy efficiency,CPU,CPU,848,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:155,modifiability,modul,modules,155,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:327,modifiability,modul,modules,327,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:736,modifiability,modul,modules,736,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1215,modifiability,modul,modules,1215,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1322,modifiability,modul,modules,1322,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:97,performance,failur,failure,97,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:231,performance,Perform,Performance,231,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:437,performance,Time,Time,437,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:442,performance,CPU,CPU,442,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:843,performance,Time,Time,843,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:848,performance,CPU,CPU,848,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1113,performance,Memor,Memory,1113,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1142,performance,time,time,1142,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:97,reliability,fail,failure,97,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:147,reliability,fail,failing,147,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:69,safety,patch,patch,69,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:91,safety,test,tests,91,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:155,safety,modul,modules,155,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:163,safety,test,test,163,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:327,safety,modul,modules,327,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:349,safety,patch,patch,349,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:736,safety,modul,modules,736,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:755,safety,patch,patch,755,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1150,safety,test,test,1150,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1215,safety,modul,modules,1215,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1237,safety,patch,patch,1237,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1322,safety,modul,modules,1322,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1341,safety,patch,patch,1341,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:69,security,patch,patch,69,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:349,security,patch,patch,349,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:755,security,patch,patch,755,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1237,security,patch,patch,1237,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1341,security,patch,patch,1341,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:91,testability,test,tests,91,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:163,testability,test,test,163,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1150,testability,test,test,1150,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:231,usability,Perform,Performance,231,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1821:1113,usability,Memor,Memory,1113,"Use GetMethodAny instead of GetListOfGlobalFunctions; **Edit**: This patch fixes cxxmodule tests failure. GetListOfGlobalFunctions were fine, what failing modules test was GetListOfAllPublicMethods. Let's use GetMethodAny instead. Performance benchmark:. `rootbench-build/root/hist/hist/HistBenchmarks`. Release build, without modules, without this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations . --------------------------------------------------------------- . BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000 . BM_TFormula_Math_Sin 221061 ns 220326 ns 3118. BM_TFormula_Pow 19896 ns 19843 ns 34679 . BM_TFormula_Std_Pow 262071 ns 261083 ns 2592 . ```. Release build, without modules, with this patch:. ```. ---------------------------------------------------------------. Benchmark Time CPU Iterations. ---------------------------------------------------------------. BM_TFormula_CreateEmpty 0 ns 0 ns 1000000000. BM_TFormula_Math_Sin 197420 ns 196728 ns 3384. BM_TFormula_Pow 20003 ns 19949 ns 34502. BM_TFormula_Std_Pow 27867 ns 27778 ns 25631. ```. Memory benchmark:. `/usr/bin/time -v test/TFormulaTests 2>&1 | grep resident`. Release build, without modules, without this patch:. ```. Maximum resident set size (kbytes): 208144. ```. Release build, without modules, with this patch:. ```. Maximum resident set size (kbytes): 178772. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1821
https://github.com/root-project/root/pull/1822:6,availability,Cluster,Cluster,6,TTree Cluster Enhancement v6-08;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1822
https://github.com/root-project/root/pull/1822:6,deployability,Cluster,Cluster,6,TTree Cluster Enhancement v6-08;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1822
https://github.com/root-project/root/pull/1823:177,availability,avail,available,177,"[Core] Backport std::integer_sequence & co. from libstdc++; ~~or, if __cplusplus > 201103L, just #include <utility>~~. or just include `<utility>` if `std::integer_sequence` is available.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1823
https://github.com/root-project/root/pull/1823:1,energy efficiency,Core,Core,1,"[Core] Backport std::integer_sequence & co. from libstdc++; ~~or, if __cplusplus > 201103L, just #include <utility>~~. or just include `<utility>` if `std::integer_sequence` is available.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1823
https://github.com/root-project/root/pull/1823:177,reliability,availab,available,177,"[Core] Backport std::integer_sequence & co. from libstdc++; ~~or, if __cplusplus > 201103L, just #include <utility>~~. or just include `<utility>` if `std::integer_sequence` is available.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1823
https://github.com/root-project/root/pull/1823:177,safety,avail,available,177,"[Core] Backport std::integer_sequence & co. from libstdc++; ~~or, if __cplusplus > 201103L, just #include <utility>~~. or just include `<utility>` if `std::integer_sequence` is available.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1823
https://github.com/root-project/root/pull/1823:177,security,availab,available,177,"[Core] Backport std::integer_sequence & co. from libstdc++; ~~or, if __cplusplus > 201103L, just #include <utility>~~. or just include `<utility>` if `std::integer_sequence` is available.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1823
https://github.com/root-project/root/pull/1824:678,availability,error,errors,678,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:689,deployability,modul,modules,689,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:722,deployability,modul,modules,722,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:193,interoperability,bind,binding,193,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:621,interoperability,conflict,conflicting,621,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:85,modifiability,variab,variables,85,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:193,modifiability,bind,binding,193,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:689,modifiability,modul,modules,689,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:722,modifiability,modul,modules,722,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:35,performance,time,time,35,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:678,performance,error,errors,678,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:515,reliability,doe,doesn,515,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:678,safety,error,errors,678,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:689,safety,modul,modules,689,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:722,safety,modul,modules,722,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:6,security,barrier,barrier,6,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:678,usability,error,errors,678,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1824:838,usability,user,users,838,"Add a barrier to PI at the startup time; In ROOT, we should be able to lookup global variables, macros, and functions defined in external AST source. (For example gROOT, std::vector..). When R binding is On, we import R related header files such as TRInterface.h and RExports.h. These header files include Constants.h, which defines `PI` like this:. ```. # define M_PI 3.14159265358979323846 /* pi */. # define PI M_PI. ```. In theory, we should be able to lookup this as well, but rootmap files are. broken and it doesn't have information about macros. So what happened. were tutorials define PI by themselves (which is conflicting with above. definition) but ROOT didn't emit errors. In modules, we're trying to preload modules so that we don't miss these namespaces and macros. PI is also visible from ROOT and. treated as a macro, so users don't have to define it themselves.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1824
https://github.com/root-project/root/pull/1825:102,deployability,log,logN,102,"[TDF] Use std::index_sequence instead of TDF::StaticSeq; ROOT's backport of std::index_sequence has O(logN) instantiation. depth, versus StaticSeq's O(N). This guarantees that very large. sequences can be instantiated without exceeding default template. instantiation depths (900 for gcc, 1024 for clang). std::index_sequence has also noticeably faster compile times. To be merged after #1823",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1825
https://github.com/root-project/root/pull/1825:361,performance,time,times,361,"[TDF] Use std::index_sequence instead of TDF::StaticSeq; ROOT's backport of std::index_sequence has O(logN) instantiation. depth, versus StaticSeq's O(N). This guarantees that very large. sequences can be instantiated without exceeding default template. instantiation depths (900 for gcc, 1024 for clang). std::index_sequence has also noticeably faster compile times. To be merged after #1823",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1825
https://github.com/root-project/root/pull/1825:102,safety,log,logN,102,"[TDF] Use std::index_sequence instead of TDF::StaticSeq; ROOT's backport of std::index_sequence has O(logN) instantiation. depth, versus StaticSeq's O(N). This guarantees that very large. sequences can be instantiated without exceeding default template. instantiation depths (900 for gcc, 1024 for clang). std::index_sequence has also noticeably faster compile times. To be merged after #1823",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1825
https://github.com/root-project/root/pull/1825:102,security,log,logN,102,"[TDF] Use std::index_sequence instead of TDF::StaticSeq; ROOT's backport of std::index_sequence has O(logN) instantiation. depth, versus StaticSeq's O(N). This guarantees that very large. sequences can be instantiated without exceeding default template. instantiation depths (900 for gcc, 1024 for clang). std::index_sequence has also noticeably faster compile times. To be merged after #1823",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1825
https://github.com/root-project/root/pull/1825:102,testability,log,logN,102,"[TDF] Use std::index_sequence instead of TDF::StaticSeq; ROOT's backport of std::index_sequence has O(logN) instantiation. depth, versus StaticSeq's O(N). This guarantees that very large. sequences can be instantiated without exceeding default template. instantiation depths (900 for gcc, 1024 for clang). std::index_sequence has also noticeably faster compile times. To be merged after #1823",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1825
https://github.com/root-project/root/pull/1826:43,deployability,Modul,Module,43,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,deployability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,integrability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,interoperability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:43,modifiability,Modul,Module,43,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,modifiability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,reliability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:148,reliability,doe,does,148,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:43,safety,Modul,Module,43,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,security,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:72,testability,Integr,Integrate,72,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:34,usability,Learn,Learning,34,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1826:55,usability,support,support,55,Add CNN in TMVA; Include New Deep Learning Module with support for CNN. Integrate the development of the 2017 GSOC students. For the moment this PR does not include the RNN and the DAE,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1826
https://github.com/root-project/root/pull/1827:279,deployability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:35,energy efficiency,core,core,35,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,integrability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,interoperability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:9,modifiability,Refact,Refactor,9,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:184,modifiability,refact,refactoring,184,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,modifiability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:9,performance,Refactor,Refactor,9,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:184,performance,refactor,refactoring,184,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,reliability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,security,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:265,testability,context,context,265,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1827:279,testability,integr,integration,279,"[VecOps] Refactor code and move to core/foundation and math/vecops; This change reflects the nature of vecops, which have nothing to do with treeplayer in principle. In addition, this refactoring paves the way for the future evolution of vecops, for example in the context of an integration with VDT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1827
https://github.com/root-project/root/pull/1828:60,interoperability,conflict,conflicts,60,Instruct CMake to look for Arrow by default now that naming conflicts are fixed;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1828
https://github.com/root-project/root/pull/1830:25,deployability,API,API,25,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:274,deployability,manag,managed,274,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:274,energy efficiency,manag,managed,274,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:25,integrability,API,API,25,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:125,integrability,sub,submitted,125,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:263,integrability,event,event,263,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:25,interoperability,API,API,25,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:6,modifiability,Exten,Extend,6,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:274,safety,manag,managed,274,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1830:161,security,team,team,161,"[TDF] Extend TDataSource API to allow skipping of entries; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9328 , submitted on behalf of the Alice O2 team. The TDataSource::SetEntry method now returns a boolean. If true, the entry is considered in the event loop managed by TDataFrame, if false, the entry is skipped.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1830
https://github.com/root-project/root/pull/1831:27,safety,input,input,27,[TDF] Allow TCsvDS to read input in bunches; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9165,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1831
https://github.com/root-project/root/pull/1831:27,usability,input,input,27,[TDF] Allow TCsvDS to read input in bunches; This PR addresses https://sft.its.cern.ch/jira/browse/ROOT-9165,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1831
https://github.com/root-project/root/pull/1832:55,deployability,fail,fail-on-missing,55,"Enable arrow with all=ON, but not by default; We have `fail-on-missing=ON` in our builds, and arrow is not installed [everywhere](http://cdash.cern.ch/viewConfigure.php?buildid=487012).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1832
https://github.com/root-project/root/pull/1832:82,deployability,build,builds,82,"Enable arrow with all=ON, but not by default; We have `fail-on-missing=ON` in our builds, and arrow is not installed [everywhere](http://cdash.cern.ch/viewConfigure.php?buildid=487012).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1832
https://github.com/root-project/root/pull/1832:107,deployability,instal,installed,107,"Enable arrow with all=ON, but not by default; We have `fail-on-missing=ON` in our builds, and arrow is not installed [everywhere](http://cdash.cern.ch/viewConfigure.php?buildid=487012).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1832
https://github.com/root-project/root/pull/1832:169,deployability,build,buildid,169,"Enable arrow with all=ON, but not by default; We have `fail-on-missing=ON` in our builds, and arrow is not installed [everywhere](http://cdash.cern.ch/viewConfigure.php?buildid=487012).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1832
https://github.com/root-project/root/pull/1832:55,reliability,fail,fail-on-missing,55,"Enable arrow with all=ON, but not by default; We have `fail-on-missing=ON` in our builds, and arrow is not installed [everywhere](http://cdash.cern.ch/viewConfigure.php?buildid=487012).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1832
https://github.com/root-project/root/pull/1836:69,deployability,version,version,69,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:95,deployability,API,API,95,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:128,energy efficiency,load,load,128,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:69,integrability,version,version,69,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:95,integrability,API,API,95,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:95,interoperability,API,API,95,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:302,interoperability,standard,standard,302,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:69,modifiability,version,version,69,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:280,modifiability,variab,variable,280,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:128,performance,load,load,128,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:54,safety,Detect,Detect,54,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:54,security,Detect,Detect,54,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1836:133,security,ssl,ssl,133,http: correctly compile civetweb with OpenSSL 1.1; 1. Detect OpenSSL version and activate v1.1 API when required. 2. Do not let load ssl libraries by civetweb - they already linked to libRHTTP.so. 3. Suppress compiler warnings in civetweb.c. 4. Use upper case for OPENSSL_VERSION variable - same as in standard FindOpenSSL.cmake script.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1836
https://github.com/root-project/root/pull/1837:79,security,Hash,Hash,79,From Axel: Short-circuit for TObject-derived classes: they have Streamer() and Hash().;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1837
https://github.com/root-project/root/pull/1838:23,integrability,queue,queue,23,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:181,integrability,sub,subsequent,181,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:23,performance,queue,queue,23,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:281,reliability,doe,does,281,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:17,security,token,token,17,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:129,security,token,token,129,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1838:219,security,token,token,219,"From Axel: Empty token queue for late parsed templates also for pending instantiations.; Late parsed templated are parsed from a token chain, as if expanding a macro. This confuses subsequent parses. Make sure that the token quere is emptied, which is exactly what ParseInternal() does after parsing.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1838
https://github.com/root-project/root/pull/1841:82,availability,failur,failures,82,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:82,deployability,fail,failures,82,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:98,deployability,modul,modules,98,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:98,modifiability,modul,modules,98,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:82,performance,failur,failures,82,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:82,reliability,fail,failures,82,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:77,safety,test,test,77,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:98,safety,modul,modules,98,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1841:77,testability,test,test,77,Change DynamicExprInfo.h from forward decl to include; This was causing some test failures in cxx modules and in cling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1841
https://github.com/root-project/root/pull/1842:14,availability,Error,Error,14,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:437,availability,error,error,437,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:481,availability,Error,Error,481,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:619,availability,Error,Error,619,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:759,availability,Error,Error,759,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:940,availability,Error,Error,940,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:584,deployability,contain,contains,584,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:682,deployability,contain,contains,682,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:443,integrability,messag,messages,443,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:443,interoperability,messag,messages,443,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:185,modifiability,variab,variable,185,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:14,performance,Error,Error,14,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:437,performance,error,error,437,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:481,performance,Error,Error,481,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:619,performance,Error,Error,619,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:759,performance,Error,Error,759,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:940,performance,Error,Error,940,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:236,reliability,doe,does,236,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:731,reliability,doe,does,731,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:14,safety,Error,Error,14,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:222,safety,compl,complains,222,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:437,safety,error,error,437,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:481,safety,Error,Error,481,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:619,safety,Error,Error,619,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:759,safety,Error,Error,759,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:842,safety,reme,remember,842,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:920,safety,avoid,avoid,920,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:940,safety,Error,Error,940,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:222,security,compl,complains,222,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:14,usability,Error,Error,14,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:437,usability,error,error,437,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:481,usability,Error,Error,481,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:619,usability,Error,Error,619,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:759,usability,Error,Error,759,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1842:940,usability,Error,Error,940,"[TTreeReader] Error out if TTreeReaderValue is reading an array; This fixes [ROOT-9322](https://sft.its.cern.ch/jira/browse/ROOT-9322). If a `TTreeReaderValue` is used to read fixed or variable size array, TTreeReader now complains and does not finish construction successfully (rather than successfully construct and read only the first element of the array). When such a (wrongly constructed) `TTreeReaderValue `is used, the following error messages are printed on screen:. ```. Error in <TTreeReaderValueBase::GetBranchDataType()>: Must use TTreeReaderArray to read branch arr: it contains an array or a collection. Error in <TTreeReaderValueBase::CreateProxy()>: The branch arr contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. Error in <TTreeReaderValue::Get()>: Value reader not properly initialized, did you remember to call TTreeReader.Set(Next)Entry()? ```. I could not find a way to avoid the last two `Error`s and still have `TTreeReaderValue::IsValid` return `false`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1842
https://github.com/root-project/root/pull/1843:62,deployability,patch,patch,62,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:192,deployability,patch,patch,192,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:27,interoperability,bind,bindings,27,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:266,interoperability,bind,bindings,266,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:27,modifiability,bind,bindings,27,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:266,modifiability,bind,bindings,266,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:62,safety,patch,patch,62,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:192,safety,patch,patch,192,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:62,security,patch,patch,62,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:192,security,patch,patch,192,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1843:246,usability,support,support,246,"WIP: Minuit2 MPI move to C bindings; This was applied from a .patch from the PR GooFit/Minuit2#1 from @gudlaugu. All credit/blame should be directed to @gudlaugu, I'm just the middleman. This patch is useful because MPI 3 no longer even includes support for the C++ bindings. I've added one small obvious fix to warnings, but otherwise all credit/blame should be directed to @gudlaugu. Original discussion in #1689.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1843
https://github.com/root-project/root/pull/1844:407,availability,sli,slightly,407,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:45,integrability,Filter,Filter,45,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:178,integrability,event,event,178,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:288,integrability,Filter,Filter,288,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:366,interoperability,share,share,366,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:489,performance,time,time,489,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:407,reliability,sli,slightly,407,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:507,safety,compl,completed,507,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:507,security,compl,completed,507,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:473,testability,simpl,simpler,473,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:380,usability,help,helper,380,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1844:473,usability,simpl,simpler,473,"[TDF] Split jitting of Define and jitting of Filter; Resolves point 1. of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349): ""[TDF] Only invoke the interpreter once per event loop"". Instead of having one single `JitTransformation` function with two entry points (`CallJit{Define,Filter}`) we now have two separate functions `JitDefine` and `JitFilter` that share several helper functions. There is slightly more code repetition than before, but the code is _much_ simpler. By the time ROOT-9849 is completed `JitDefine` and `JitFilter` will be different enough to justify this separation.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1844
https://github.com/root-project/root/pull/1845:0,deployability,Updat,Update,0,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:74,deployability,updat,update,74,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:111,deployability,releas,release,111,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:0,safety,Updat,Update,0,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:74,safety,updat,update,74,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:0,security,Updat,Update,0,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1845:74,security,updat,update,74,Update builtin Davix and OpenSSL; Move Davix to new builtin mechanism and update OpenSSL to 1.0.2o (latest LTS release).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1845
https://github.com/root-project/root/pull/1846:85,usability,custom,custom,85,"[TDF] Let Define alias its return typename, use that alias everywhere when reading a custom column; This resolves points 2 and 3 of [ROOT-9349](https://sft.its.cern.ch/jira/browse/ROOT-9349).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1846
https://github.com/root-project/root/pull/1847:12,deployability,depend,dependency,12,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:12,integrability,depend,dependency,12,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:12,modifiability,depend,dependency,12,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:66,modifiability,refact,refactoring,66,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:66,performance,refactor,refactoring,66,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:12,safety,depend,dependency,12,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1847:12,testability,depend,dependency,12,Remove Tree dependency from libMultiProc; Not necessary since the refactoring done by Gerri.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1847
https://github.com/root-project/root/pull/1849:21,usability,user,user,21,Implement setting of user axis range from TPad.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1849
https://github.com/root-project/root/pull/1850:203,usability,guid,guide,203,Implement the possibility to generate high definition bitmap picture.; This is done in TImageDump via gStyle->SetImageScaling(x); x being a multiplication factor. This new feature is now used in the ref guide generation with x=3. Pictures in the ref guide are now much shaper and the text is as clear the rest of the text in the doc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1850
https://github.com/root-project/root/pull/1850:250,usability,guid,guide,250,Implement the possibility to generate high definition bitmap picture.; This is done in TImageDump via gStyle->SetImageScaling(x); x being a multiplication factor. This new feature is now used in the ref guide generation with x=3. Pictures in the ref guide are now much shaper and the text is as clear the rest of the text in the doc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1850
https://github.com/root-project/root/pull/1850:295,usability,clear,clear,295,Implement the possibility to generate high definition bitmap picture.; This is done in TImageDump via gStyle->SetImageScaling(x); x being a multiplication factor. This new feature is now used in the ref guide generation with x=3. Pictures in the ref guide are now much shaper and the text is as clear the rest of the text in the doc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1850
https://github.com/root-project/root/pull/1851:0,deployability,Updat,Update,0,Update TMVA documentation for CV + more; - Add chapter on CV. - Add additional information on multiclass gui. - Bugfixes. Realised I still have a few references to fix in the CV chapter before merging is ok.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1851
https://github.com/root-project/root/pull/1851:0,safety,Updat,Update,0,Update TMVA documentation for CV + more; - Add chapter on CV. - Add additional information on multiclass gui. - Bugfixes. Realised I still have a few references to fix in the CV chapter before merging is ok.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1851
https://github.com/root-project/root/pull/1851:0,security,Updat,Update,0,Update TMVA documentation for CV + more; - Add chapter on CV. - Add additional information on multiclass gui. - Bugfixes. Realised I still have a few references to fix in the CV chapter before merging is ok.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1851
https://github.com/root-project/root/pull/1851:12,usability,document,documentation,12,Update TMVA documentation for CV + more; - Add chapter on CV. - Add additional information on multiclass gui. - Bugfixes. Realised I still have a few references to fix in the CV chapter before merging is ok.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1851
https://github.com/root-project/root/pull/1852:65,integrability,interfac,interface,65,webgui: support https for TWebWindow; Plus additional cleanup of interface in THttpServer class. Changing arguments order in TWebWindow::Send() methods. Address most comments from #1785,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1852
https://github.com/root-project/root/pull/1852:65,interoperability,interfac,interface,65,webgui: support https for TWebWindow; Plus additional cleanup of interface in THttpServer class. Changing arguments order in TWebWindow::Send() methods. Address most comments from #1785,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1852
https://github.com/root-project/root/pull/1852:65,modifiability,interfac,interface,65,webgui: support https for TWebWindow; Plus additional cleanup of interface in THttpServer class. Changing arguments order in TWebWindow::Send() methods. Address most comments from #1785,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1852
https://github.com/root-project/root/pull/1852:8,usability,support,support,8,webgui: support https for TWebWindow; Plus additional cleanup of interface in THttpServer class. Changing arguments order in TWebWindow::Send() methods. Address most comments from #1785,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1852
https://github.com/root-project/root/pull/1853:18,integrability,filter,filter,18,[TDF] Lazy jitted filter;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1853
https://github.com/root-project/root/pull/1854:41,integrability,sub,subfolder,41,"json: move json.hpp parser to io/io/res/ subfolder; Is it really a solution, which allows to use such parser from other sub-projects?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1854
https://github.com/root-project/root/pull/1854:120,integrability,sub,sub-projects,120,"json: move json.hpp parser to io/io/res/ subfolder; Is it really a solution, which allows to use such parser from other sub-projects?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1854
https://github.com/root-project/root/pull/1856:512,availability,error,error-handling,512,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:856,availability,error,error-handling,856,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:1057,availability,error,error-handling,1057,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:774,deployability,depend,dependent,774,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:199,energy efficiency,power,powered,199,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:351,energy efficiency,current,currently,351,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:673,energy efficiency,Current,Currently,673,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:774,integrability,depend,dependent,774,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:401,interoperability,convers,conversion,401,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:889,interoperability,format,format,889,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:774,modifiability,depend,dependent,774,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:164,performance,content,content,164,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:231,performance,memor,memory,231,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:512,performance,error,error-handling,512,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:791,performance,memor,memory,791,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:856,performance,error,error-handling,856,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:1057,performance,error,error-handling,1057,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:496,safety,test,tests,496,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:512,safety,error,error-handling,512,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:571,safety,test,tests,571,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:774,safety,depend,dependent,774,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:856,safety,error,error-handling,856,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:1057,safety,error,error-handling,1057,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:496,testability,test,tests,496,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:571,testability,test,tests,571,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:774,testability,depend,dependent,774,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:231,usability,memor,memory,231,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:512,usability,error,error-handling,512,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:652,usability,support,supported,652,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:791,usability,memor,memory,791,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:856,usability,error,error-handling,856,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1856:1057,usability,error,error-handling,1057,"[PyROOT][WIP] `TTree.AsMatrix(columns)` functionality; This PR is on top of #1777 and adds the method `TTree.AsMatrix(columns)` as pythonization, which returns the content of the tree as numpy array powered by `TDataFrame` and the memory adption with the `__array_interface__`. TODO:. - ~~Infere the final datatype of the numpy array in a clever way (currently `double` is the default). Implicit type conversion is done by the lambda passed to `TDataFrame` in the backend.~~ Done in python, with tests. - ~~More error-handling?~~ Can't think of any more checks. - ~~More tests? Corner-cases missed?~~ Ideas? Any corner-cases missed? - ~~What about not supported datatypes? Currently implemented for `float`, `double`, `int`, `unsigned int`, `long`, `unsigned long`. This is dependent on the memory adption feature of #1777 for `std.vector`.~~ Added proper error-handling. - ~~Apply `clang-format`~~ ~~ Let's travis do this. - ~~Shall we provide a `TTree.AsMatrix()` without given columns, which defaults to all columns? -> Most likely: Yes (but with proper error-handling!) -> White-listing branch types?~~ Done.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1856
https://github.com/root-project/root/pull/1857:68,deployability,contain,contains,68,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:195,integrability,Filter,Filters,195,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:161,modifiability,variab,variable,161,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:363,modifiability,refact,refactoring,363,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:363,performance,refactor,refactoring,363,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:553,reliability,doe,does,553,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:207,safety,avoid,avoid,207,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:411,safety,test,test,411,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:675,safety,compl,complains,675,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:130,security,modif,modified,130,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:268,security,modif,modified,268,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:675,security,compl,complains,675,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1857:411,testability,test,test,411,"[TDF] Fix clashing of ""a.b"" and ""a_b"" columns; When the column name contains a dot, we replace it with an underscore. and use the modified name as corresponding variable name for jitted. Defines/Filters. To avoid potential name clashes with pre-existing columns, the. modified name is now prefixed with ""__tdf_arg_"", as it was already. the case before the latest refactoring of jitting. I'd like to introduce a test for this case, but I can't because of a different issue:. given a branch defined as `t.Branch(""v"", &v, ""a/I:b/I"")`, `Define(""a"", ""v.a"")` does not work: `""v""` comes before than `""v.a""` in the list of branches that we create, so it matches first, and later TDF complains that `""v""` is not a branch. @etejedor this is in the new `GetBranchNames`, do you think it might be an easy fix?",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1857
https://github.com/root-project/root/pull/1858:72,deployability,log,logic,72,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:41,integrability,filter,filters,41,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:65,integrability,filter,filter,65,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:124,integrability,filter,filter,124,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:72,safety,log,logic,72,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:98,safety,valid,validity,98,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:72,security,log,logic,72,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1858:72,testability,log,logic,72,[TDF] Also define DS columns from jitted filters; The new jitted filter logic mistakingly skipped validity checks over. the filter lambda and TDataSource column Define-ition. This should fix the crashes in tutorial `tdf014_CSVDataSource`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1858
https://github.com/root-project/root/pull/1859:46,deployability,log,log,46,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1859:50,integrability,messag,message,50,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1859:50,interoperability,messag,message,50,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1859:46,safety,log,log,46,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1859:46,security,log,log,46,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1859:46,testability,log,log,46,closing parenthesis in tmva/tmva/src/PDF.cxx; log message was missing a closing parenthesis,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1859
https://github.com/root-project/root/pull/1861:12,availability,Restor,Restoring,12,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:119,availability,Failur,Failure,119,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:337,availability,Error,Error,337,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:61,deployability,build,build,61,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:119,deployability,Fail,Failure,119,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:188,deployability,build,build,188,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:243,deployability,build,building,243,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:252,deployability,modul,module,252,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:275,deployability,build,build,275,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:305,deployability,build,build,305,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:351,deployability,build,build,351,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:368,deployability,modul,module,368,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:460,deployability,modul,module,460,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:480,deployability,modul,module,480,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:519,deployability,modul,modulemap,519,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:252,modifiability,modul,module,252,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:368,modifiability,modul,module,368,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:460,modifiability,modul,module,460,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:480,modifiability,modul,module,480,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:519,modifiability,modul,modulemap,519,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:119,performance,Failur,Failure,119,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:337,performance,Error,Error,337,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:12,reliability,Restor,Restoring,12,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:119,reliability,Fail,Failure,119,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:252,safety,modul,module,252,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:337,safety,Error,Error,337,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:368,safety,modul,module,368,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:460,safety,modul,module,460,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:480,safety,modul,module,480,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:519,safety,modul,modulemap,519,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1861:337,usability,Error,Error,337,"[cxxmodules]Restoring back compilation of runtime cxxmodules build after af5a2b4f; 338974e4f0763a66506bbc54fe80e3cb. Failure in CDash:. ```. In file included from input_line_13:8:. /.../build/include/ROOT/TProcessExecutor.hxx:19:10: remark: building module 'Tree' as '/.../build/lib/Tree.pcm' [-Rmodule-build]. #include ""TChain.h"". ^. Error: Had to build non-system module Tree implicitly. You first need to. generate the dictionary for Tree or mark the C++ module as a system. module if you provided your own system modulemap file:. Tree [system] { ... }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1861
https://github.com/root-project/root/pull/1863:196,reliability,doe,does,196,"[TDF] Check whether the top-level branch has 1 leaf with the same name; This fixes the case of the example shown by @bluehood in #1857 , when the top-level branch has just one leaf, but that leaf does not have the same name as the top-level branch. In that case, the name of the top-level branch should not appear in the list (TTreeReader is not able to process it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1863
https://github.com/root-project/root/pull/1864:14,safety,test,test,14,Cling fix abi test;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1864
https://github.com/root-project/root/pull/1864:14,testability,test,test,14,Cling fix abi test;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1864
https://github.com/root-project/root/pull/1868:7,availability,failur,failure,7,Report failure for missing symbols!;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1868
https://github.com/root-project/root/pull/1868:7,deployability,fail,failure,7,Report failure for missing symbols!;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1868
https://github.com/root-project/root/pull/1868:7,performance,failur,failure,7,Report failure for missing symbols!;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1868
https://github.com/root-project/root/pull/1868:7,reliability,fail,failure,7,Report failure for missing symbols!;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1868
https://github.com/root-project/root/pull/1869:254,energy efficiency,cpu,cpu,254,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:347,energy efficiency,cpu,cpu,347,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:604,energy efficiency,cpu,cpu,604,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:701,energy efficiency,cpu,cpu,701,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:798,energy efficiency,cpu,cpu,798,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:149,integrability,event,events,149,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:376,integrability,translat,translates,376,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:272,interoperability,Standard,Standard,272,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:376,interoperability,translat,translates,376,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:30,performance,parallel,parallelise,30,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:115,performance,perform,performance,115,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:254,performance,cpu,cpu,254,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:347,performance,cpu,cpu,347,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:502,performance,time,time,502,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:604,performance,cpu,cpu,604,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:701,performance,cpu,cpu,701,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:798,performance,cpu,cpu,798,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:1102,reliability,Pra,Pray,1102,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:115,usability,perform,performance,115,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:231,usability,user,user,231,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:325,usability,user,user,325,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:582,usability,user,user,582,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:678,usability,user,user,678,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1869:775,usability,user,user,775,"[TMVA] Add multiprocessing to parallelise CV; Based on PR #858. Implements only parts relevant for CV. Rudimentary performance benchmark with ~60000 events with 2-fold CV. ```. Multiproc: root -l -b -q TMVACrossValidation.C 15.82s user 0.46s system 152% cpu 10.679 total. Standard: root -l -b -q TMVACrossValidation.C 14.31s user 0.25s system 99% cpu 14.652 total. ```. Which translates into a 4 second speed up. A different example, with a deeper bdt forest and 10-fold CV, almost halves the required time on my machine :). ```. Single : root -l -b -q TMVACrossValidation.C 33.66s user 1.99s system 98% cpu 36.369 total. Multiproc 2: root -l -b -q TMVACrossValidation.C 39.14s user 2.68s system 167% cpu 25.016 total. Multiproc 4: root -l -b -q TMVACrossValidation.C 46.52s user 3.50s system 233% cpu 21.420 total. ```. For the second example, these changes to `TMVACrossValidation.C` were used. ```. /* ...snip... */. TString cvOptions = Form(""!V:NumWorkerProcs=4"". /* ...snip... */. cv.BookMethod(TMVA::Types::kBDT, ""BDTG"",. ""!H:!V:NTrees=1000:MinNodeSize=2.5%:BoostType=Grad"". "":NegWeightTreatment=Pray:Shrinkage=0.10:nCuts=20"". "":MaxDepth=6"");. /* ...snip... */. // cv.BookMethod(TMVA::Types::kFisher, ""Fisher"",. // ""!H:!V:Fisher:VarTransform=None"");. /* ...snip... */. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1869
https://github.com/root-project/root/pull/1870:272,energy efficiency,adapt,adapted,272,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:272,integrability,adapt,adapted,272,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:272,interoperability,adapt,adapted,272,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:62,modifiability,paramet,parameter,62,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:272,modifiability,adapt,adapted,272,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:252,safety,Test,Tests,252,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:287,safety,test,test,287,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:252,testability,Test,Tests,252,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1870:287,testability,test,test,287,"[TDF] ROOT-9357: Implement Snapshot as a lazy action; - A new parameter, the lazyness of the snapshot, has been added to the TSnapshotOptions. - The Snapshot methods return a TResultPtr<TInteface<TLoopManager>> rather than a TInteface<TLoopManager>. - Tests and tutorials adapted. - New test for lazy snapshot added",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1870
https://github.com/root-project/root/pull/1871:25,integrability,interfac,interface,25,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1871:25,interoperability,interfac,interface,25,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1871:25,modifiability,interfac,interface,25,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1871:136,performance,memor,memory,136,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1871:95,usability,clear,clearly,95,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1871:136,usability,memor,memory,136,"[PyROOT] Add numpy array interface to TVec and STL vector; Similar to #1777 but cleaned up and clearly separated from #1856. Implements memory adoption of `TVec` and `std.vector` for data-types `int`, `unsigned int`, `long`, `unsigned long`, `float` and `double` with numpy arrays using `numpy.asarray(root_obj)`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1871
https://github.com/root-project/root/pull/1872:310,availability,error,error-handling,310,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:283,integrability,interfac,interface,283,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:283,interoperability,interfac,interface,283,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:283,modifiability,interfac,interface,283,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:310,performance,error,error-handling,310,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:310,safety,error,error-handling,310,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:260,usability,support,supported,260,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1872:310,usability,error,error-handling,310,"[PyROOT] Add `TTree.AsMatrix` funtionality; This PR sits on top of #1871. Adds pythonization `TTree.Asmatrix(columns, dtype)`. `columns` can be `None`, which results in taking all branches. `dtype` is by default `double` but can be set to all types, which are supported by the array interface of `std.vector` (error-handling provided).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1872
https://github.com/root-project/root/pull/1873:0,testability,Simpl,Simple,0,Simple mods for TText.hxx;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1873
https://github.com/root-project/root/pull/1873:0,usability,Simpl,Simple,0,Simple mods for TText.hxx;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1873
https://github.com/root-project/root/pull/1877:335,availability,consist,consistent,335,"[TDF] Add Initialize method to TAction(Base) and invoke it before the evt loop; for each action. Leverage this new functionality, invisible to the user, to properly delay the snapshot,. not writing an empty output file during the construction of the action but rather. delay it to the beginning of the event loop. This somehow is more consistent with the overall laziness in TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1877
https://github.com/root-project/root/pull/1877:302,integrability,event,event,302,"[TDF] Add Initialize method to TAction(Base) and invoke it before the evt loop; for each action. Leverage this new functionality, invisible to the user, to properly delay the snapshot,. not writing an empty output file during the construction of the action but rather. delay it to the beginning of the event loop. This somehow is more consistent with the overall laziness in TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1877
https://github.com/root-project/root/pull/1877:147,usability,user,user,147,"[TDF] Add Initialize method to TAction(Base) and invoke it before the evt loop; for each action. Leverage this new functionality, invisible to the user, to properly delay the snapshot,. not writing an empty output file during the construction of the action but rather. delay it to the beginning of the event loop. This somehow is more consistent with the overall laziness in TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1877
https://github.com/root-project/root/pull/1877:335,usability,consist,consistent,335,"[TDF] Add Initialize method to TAction(Base) and invoke it before the evt loop; for each action. Leverage this new functionality, invisible to the user, to properly delay the snapshot,. not writing an empty output file during the construction of the action but rather. delay it to the beginning of the event loop. This somehow is more consistent with the overall laziness in TDataFrame.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1877
https://github.com/root-project/root/pull/1882:792,availability,servic,services,792,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:72,deployability,contain,contains,72,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:364,deployability,modul,modules,364,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:661,deployability,modul,modules,661,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:792,deployability,servic,services,792,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:939,deployability,depend,dependency,939,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:13,energy efficiency,Load,Load,13,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:428,energy efficiency,Load,Load,428,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:601,energy efficiency,load,loads,601,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:806,energy efficiency,load,loading,806,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:932,energy efficiency,reduc,reduce,932,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:792,integrability,servic,services,792,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:939,integrability,depend,dependency,939,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:860,interoperability,semant,semantic,860,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:185,modifiability,inherit,inherited,185,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:364,modifiability,modul,modules,364,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:661,modifiability,modul,modules,661,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:792,modifiability,servic,services,792,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:939,modifiability,depend,dependency,939,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:13,performance,Load,Load,13,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:317,performance,time,time,317,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:428,performance,Load,Load,428,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:601,performance,load,loads,601,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:806,performance,load,loading,806,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:364,safety,modul,modules,364,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:661,safety,modul,modules,661,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:939,safety,depend,dependency,939,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1882:939,testability,depend,dependency,939,"[cxxmodules] Load libraries for each deserialized decls; This PR change contains:. - Registering DeserializationListener to ASTReader and get callbacks. when decls are deserialized. We inherited ASTDeserializationListener in DeclCollector and register. DeserializationListener to our ASTReader at DeclCollector setup time. In the callback(DeclRead), we get owning modules from decls and store. the information in Transaction. - Load libraies for deserialized decls. Before executeTransaction(where linking happens) we put our callback. beforeEmittingModuleForTransaction in InterpreterCallbacks. This loads. libraries when it wasn't in its first run, and store modules if it's. in its first run. This is because Interpreter is not yet initialized. at first run but we need to use Interpreter services when loading. libraries. I think this is the last piece of semantic change related to runtime. cxxmodules. This also enables us to reduce dependency on rootmap files.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1882
https://github.com/root-project/root/pull/1883:37,safety,avoid,avoid,37,Make this loop var size_t; This will avoid compiler warnings when compiling with option -Wsign-compare,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1883
https://github.com/root-project/root/pull/1884:16,performance,Cach,Cache,16,[TDF] Implement Cache in terms of TLazyDS (ROOT-9226); And simplify the code whenever possible.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1884
https://github.com/root-project/root/pull/1884:59,testability,simpl,simplify,59,[TDF] Implement Cache in terms of TLazyDS (ROOT-9226); And simplify the code whenever possible.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1884
https://github.com/root-project/root/pull/1884:59,usability,simpl,simplify,59,[TDF] Implement Cache in terms of TLazyDS (ROOT-9226); And simplify the code whenever possible.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1884
https://github.com/root-project/root/pull/1885:5,reliability,doe,doesn,5,span doesn't need to be passed by reference;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1885
https://github.com/root-project/root/pull/1886:237,availability,error,error,237,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:347,energy efficiency,reduc,reduce,347,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:14,integrability,batch,batch,14,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:171,integrability,messag,messaging,171,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:338,integrability,batch,batch,338,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:411,integrability,batch,batch,411,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:601,integrability,configur,configure,601,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:171,interoperability,messag,messaging,171,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:601,modifiability,configur,configure,601,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:647,modifiability,paramet,parameters,647,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:14,performance,batch,batch,14,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:237,performance,error,error,237,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:338,performance,batch,batch,338,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:411,performance,batch,batch,411,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:561,performance,time,timeout,561,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:237,safety,error,error,237,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:254,safety,avoid,avoid,254,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:480,safety,compl,completely,480,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:561,safety,timeout,timeout,561,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:480,security,compl,completely,480,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:601,security,configur,configure,601,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:925,security,ident,identification,925,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:510,testability,simpl,simple,510,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:914,testability,simpl,simple,914,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:1011,testability,simpl,simplify,1011,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:67,usability,support,support,67,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:237,usability,error,error,237,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:454,usability,support,support,454,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:510,usability,simpl,simple,510,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:531,usability,stop,stop,531,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:586,usability,command,command,586,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:611,usability,custom,custom,611,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:624,usability,command,commands,624,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:759,usability,user,user,759,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:914,usability,simpl,simple,914,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1886:1011,usability,simpl,simplify,1011,"webgui: CEF + batch mode improvments; Many improvements in CEF:. - support POST requests, let transfer arbitrary data from client to server. - replace text-based cefQuery messaging by longpoll, required for binary transfer. - assign X11 error handler to avoid application abort in case of minor X11 warnings. - use single-process mode in batch to reduce number of running processes. Provide special handling of batch mode for Chrome and Firefox:. - both support `--headless` mode completely without X . - very simple workaround to stop browser after 30 s with `timeout 30 chromium ...` command. - let configure custom shell commands via `.rootrc` parameters. Changes in http and webgui libraries:. - ""hide"" TCivetweb, TFastCgi, THttpWSEngine classes from end-user (@Axel-Naumann). - remove some comments from civetweb.c (@amadio). - use std::copy() instead of memcpy() for std::string (@Axel-Naumann). - introduce simple key identification of clients, let recognize which client starts by TWebWindow::Show(). - simplify cmake files, separate v7 code in FitPanel",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1886
https://github.com/root-project/root/pull/1887:290,availability,error,error,290,"[ROOT-9364] Fix typename of gVirtualX in list of globals; As pointed out by a user in this forum post:. https://root-forum.cern.ch/t/pyroot-6-and-gvirtualx-eeventtype-etc/28702/9. and explained in:. https://sft.its.cern.ch/jira/browse/ROOT-9364. importing gVirtualX from PyROOT leads to an error. This PR fixes the issue, which is due to gVirtualX being added to the list of globals with a wrong type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1887
https://github.com/root-project/root/pull/1887:290,performance,error,error,290,"[ROOT-9364] Fix typename of gVirtualX in list of globals; As pointed out by a user in this forum post:. https://root-forum.cern.ch/t/pyroot-6-and-gvirtualx-eeventtype-etc/28702/9. and explained in:. https://sft.its.cern.ch/jira/browse/ROOT-9364. importing gVirtualX from PyROOT leads to an error. This PR fixes the issue, which is due to gVirtualX being added to the list of globals with a wrong type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1887
https://github.com/root-project/root/pull/1887:290,safety,error,error,290,"[ROOT-9364] Fix typename of gVirtualX in list of globals; As pointed out by a user in this forum post:. https://root-forum.cern.ch/t/pyroot-6-and-gvirtualx-eeventtype-etc/28702/9. and explained in:. https://sft.its.cern.ch/jira/browse/ROOT-9364. importing gVirtualX from PyROOT leads to an error. This PR fixes the issue, which is due to gVirtualX being added to the list of globals with a wrong type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1887
https://github.com/root-project/root/pull/1887:78,usability,user,user,78,"[ROOT-9364] Fix typename of gVirtualX in list of globals; As pointed out by a user in this forum post:. https://root-forum.cern.ch/t/pyroot-6-and-gvirtualx-eeventtype-etc/28702/9. and explained in:. https://sft.its.cern.ch/jira/browse/ROOT-9364. importing gVirtualX from PyROOT leads to an error. This PR fixes the issue, which is due to gVirtualX being added to the list of globals with a wrong type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1887
https://github.com/root-project/root/pull/1887:290,usability,error,error,290,"[ROOT-9364] Fix typename of gVirtualX in list of globals; As pointed out by a user in this forum post:. https://root-forum.cern.ch/t/pyroot-6-and-gvirtualx-eeventtype-etc/28702/9. and explained in:. https://sft.its.cern.ch/jira/browse/ROOT-9364. importing gVirtualX from PyROOT leads to an error. This PR fixes the issue, which is due to gVirtualX being added to the list of globals with a wrong type.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1887
https://github.com/root-project/root/pull/1888:1,deployability,BUILD,BUILD,1,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:29,deployability,depend,dependencies,29,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:224,deployability,build,builds,224,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:246,energy efficiency,green,green,246,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:29,integrability,depend,dependencies,29,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:29,modifiability,depend,dependencies,29,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:29,safety,depend,dependencies,29,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1888:29,testability,depend,dependencies,29,[BUILD] Add libVecOps to the dependencies of libTreePlayer; This should solve some problems with TDF jitting. To be removed when TDataFrame moves out of libTreePlayer. The change is fairly trivial. Will merge if the jenkins builds are reasonably green.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1888
https://github.com/root-project/root/pull/1889:109,deployability,Depend,Dependent,109,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:33,integrability,interfac,interface,33,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:109,integrability,Depend,Dependent,109,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:33,interoperability,interfac,interface,33,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:33,modifiability,interfac,interface,33,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:109,modifiability,Depend,Dependent,109,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:109,safety,Depend,Dependent,109,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1889:109,testability,Depend,Dependent,109,[PyROOT] Add tutorials for array interface and TTree.AsMatrix features; Examples for the mentioned features. Dependent on PR #1872.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1889
https://github.com/root-project/root/pull/1890:0,deployability,Updat,Updates,0,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1890:53,deployability,version,version,53,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1890:53,integrability,version,version,53,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1890:53,modifiability,version,version,53,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1890:0,safety,Updat,Updates,0,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1890:0,security,Updat,Updates,0,"Updates to builtin Davix, including moving to latest version (0.6.7);",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1890
https://github.com/root-project/root/pull/1891:23,integrability,Filter,Filters,23,"[TDF] Jit Defines with Filters/Actions, right before the event loop;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1891
https://github.com/root-project/root/pull/1891:57,integrability,event,event,57,"[TDF] Jit Defines with Filters/Actions, right before the event loop;",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1891
https://github.com/root-project/root/pull/1892:4,deployability,updat,update,4,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:218,integrability,interfac,interface,218,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:218,interoperability,interfac,interface,218,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:218,modifiability,interfac,interface,218,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:4,safety,updat,update,4,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:53,safety,detect,detectors,53,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:123,safety,detect,detectors,123,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:255,safety,detect,detector,255,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:4,security,updat,update,4,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:53,security,detect,detectors,53,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:123,security,detect,detectors,123,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:255,security,detect,detector,255,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:18,usability,support,support,18,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:30,usability,user,user,30,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:88,usability,Support,Support,88,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:100,usability,user,user,100,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1892:240,usability,user,user,240,"VMC update: Added support for user defined sensitive detectors; plus few more features; Support for user defined sensitive detectors; new TVirtualMC::NIELEdep(); clean-up:. Details:. o TVirtualMCSensitiveDetector: the interface class for a user sensitive detector. o New functions in TVirtualMC:. void SetSensitiveDetector(const TString &volName, TVirtualMCSensitiveDetector *sd);. TVirtualMCSensitiveDetector *GetSensitiveDetector(const TString &volName) const;. void SetExclusiveSDScoring(Bool_t exclusiveSDScoring);. o New function in TVirtualMCApplication:. void ConstructSensitiveDetectors();. - Added new TVirtualMC::NIELEdep() function. - Removed default implementation for TVirtualMC::TrackPosition/Momentum with Float_t arguments",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1892
https://github.com/root-project/root/pull/1894:31,performance,memor,memory,31,[TDF] Read into TVec also when memory of TTreeReaderArray is not contiguous; this is https://sft.its.cern.ch/jira/browse/ROOT-9366,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1894
https://github.com/root-project/root/pull/1894:31,usability,memor,memory,31,[TDF] Read into TVec also when memory of TTreeReaderArray is not contiguous; this is https://sft.its.cern.ch/jira/browse/ROOT-9366,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1894
https://github.com/root-project/root/pull/1895:59,deployability,build,builds,59,[TDF] Fix ambiguous namespace; @bluehood On my system ROOT builds only with this namespace declaration. Otherwise the compiler says it is ambiguous. Why does this fail only on my system (currently ubuntu1604).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1895
https://github.com/root-project/root/pull/1895:163,deployability,fail,fail,163,[TDF] Fix ambiguous namespace; @bluehood On my system ROOT builds only with this namespace declaration. Otherwise the compiler says it is ambiguous. Why does this fail only on my system (currently ubuntu1604).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1895
https://github.com/root-project/root/pull/1895:187,energy efficiency,current,currently,187,[TDF] Fix ambiguous namespace; @bluehood On my system ROOT builds only with this namespace declaration. Otherwise the compiler says it is ambiguous. Why does this fail only on my system (currently ubuntu1604).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1895
https://github.com/root-project/root/pull/1895:153,reliability,doe,does,153,[TDF] Fix ambiguous namespace; @bluehood On my system ROOT builds only with this namespace declaration. Otherwise the compiler says it is ambiguous. Why does this fail only on my system (currently ubuntu1604).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1895
https://github.com/root-project/root/pull/1895:163,reliability,fail,fail,163,[TDF] Fix ambiguous namespace; @bluehood On my system ROOT builds only with this namespace declaration. Otherwise the compiler says it is ambiguous. Why does this fail only on my system (currently ubuntu1604).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1895
https://github.com/root-project/root/pull/1896:0,deployability,Updat,Updates,0,Updates to VecOps library to use pre-compiled templates for common types;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1896
https://github.com/root-project/root/pull/1896:0,safety,Updat,Updates,0,Updates to VecOps library to use pre-compiled templates for common types;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1896
https://github.com/root-project/root/pull/1896:0,security,Updat,Updates,0,Updates to VecOps library to use pre-compiled templates for common types;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1896
https://github.com/root-project/root/pull/1897:24,integrability,buffer,buffer,24,[cling] Also reset (and buffer) Sema::PendingInstantiations in ClingRAII; Fixes 'XYZ not defined until final }' during autoparse.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1897
https://github.com/root-project/root/pull/1898:200,reliability,doe,does,200,"webgui: use fork() on Linux/Mac to start browsers in headless mode; Both chrome and firefox browsers can be started, using fork(). One gets process id, which can be used later to kill browser when it does not required. Special solution for Windows need to be provided.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1898
https://github.com/root-project/root/pull/1901:12,usability,Custom,Customizable,12,[ROOT-8844] Customizable precision via TGeoManager::SetExportPrecisio; n for geometry ASCII exports. This fixes part of ROOT-8844,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1901
https://github.com/root-project/root/pull/1902:6,deployability,Updat,Update,6,[TDF] Update/improve naming of internal variables and methods; Also make a (human-checked) `clang-format` pass on all TDF files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1902
https://github.com/root-project/root/pull/1902:98,interoperability,format,format,98,[TDF] Update/improve naming of internal variables and methods; Also make a (human-checked) `clang-format` pass on all TDF files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1902
https://github.com/root-project/root/pull/1902:40,modifiability,variab,variables,40,[TDF] Update/improve naming of internal variables and methods; Also make a (human-checked) `clang-format` pass on all TDF files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1902
https://github.com/root-project/root/pull/1902:6,safety,Updat,Update,6,[TDF] Update/improve naming of internal variables and methods; Also make a (human-checked) `clang-format` pass on all TDF files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1902
https://github.com/root-project/root/pull/1902:6,security,Updat,Update,6,[TDF] Update/improve naming of internal variables and methods; Also make a (human-checked) `clang-format` pass on all TDF files.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1902
https://github.com/root-project/root/pull/1903:321,safety,valid,valid,321,"[TDF] Do not keep dot-less branch name if it was part of a longer one; For example, in an expression string such as ""el.px > 0"", it could. happen that both ""el.px"" and ""el"" were recognized as columns used. inside the expression. Even after ""el.px"" was replaced with ""el_px"". ""el"" matched the expression and was kept as a valid, used column name. This commit adds an extra check to verify that ""el"" still appears as. a standalone column name, even after ""el.px"" has been replaced. Note that it's guaranteed that ""el.px"" will always match before ""el"" because. our generation of all possible branchnames is depth-first.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1903
https://github.com/root-project/root/pull/1903:381,testability,verif,verify,381,"[TDF] Do not keep dot-less branch name if it was part of a longer one; For example, in an expression string such as ""el.px > 0"", it could. happen that both ""el.px"" and ""el"" were recognized as columns used. inside the expression. Even after ""el.px"" was replaced with ""el_px"". ""el"" matched the expression and was kept as a valid, used column name. This commit adds an extra check to verify that ""el"" still appears as. a standalone column name, even after ""el.px"" has been replaced. Note that it's guaranteed that ""el.px"" will always match before ""el"" because. our generation of all possible branchnames is depth-first.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1903
https://github.com/root-project/root/pull/1904:29,interoperability,Coordinat,Coordinate,29,Changes in TDrawable-Get/Set Coordinate System; Set and Get Native Coordinate System functions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1904
https://github.com/root-project/root/pull/1904:67,interoperability,Coordinat,Coordinate,67,Changes in TDrawable-Get/Set Coordinate System; Set and Get Native Coordinate System functions,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1904
https://github.com/root-project/root/pull/1905:1073,availability,slo,slot,1073,"cumentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1248,availability,slo,slot,1248," object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1480,availability,slo,slot,1480,"erit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1872,availability,operat,operations,1872,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2063,availability,slo,slot,2063,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2208,availability,slo,slot,2208,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2303,availability,slo,slot,2303,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:226,deployability,depend,dependent,226,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:226,integrability,depend,dependent,226,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:303,integrability,interfac,interface,303,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:470,integrability,pub,publicly,470,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1163,integrability,event,event-loop,1163,"n for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the parti",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1541,integrability,event,event,1541,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1574,integrability,batch,batch,1574,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1725,integrability,batch,batch,1725,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1843,integrability,event,event-loop,1843,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1957,integrability,event,event,1957,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:303,interoperability,interfac,interface,303,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:695,interoperability,specif,specifies,695,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:226,modifiability,depend,dependent,226,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:303,modifiability,interfac,interface,303,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:479,modifiability,inherit,inherit,479,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1267,modifiability,paramet,parameter,1267,"e caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, b",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1184,performance,concurren,concurrently,1184,"ehavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this acti",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1574,performance,batch,batch,1574,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1725,performance,batch,batch,1725,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1999,performance,content,contents,1999,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2257,performance,concurren,concurrently,2257,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1073,reliability,slo,slot,1073,"cumentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1248,reliability,slo,slot,1248," object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1480,reliability,slo,slot,1480,"erit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2063,reliability,slo,slot,2063,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2208,reliability,slo,slot,2208,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:2303,reliability,slo,slot,2303,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:127,safety,review,review,127,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:215,safety,compl,completely,215,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:226,safety,depend,dependent,226,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1315,safety,safe,safe,1315,"the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:215,security,compl,completely,215,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:127,testability,review,review,127,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:226,testability,depend,dependent,226,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:41,usability,user,users,41,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:58,usability,custom,custom,58,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:73,usability,Document,Documentation,73,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:156,usability,custom,custom,156,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:189,usability,behavi,behavior,189,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:244,usability,Help,Helper,244,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:286,usability,minim,minimum,286,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:321,usability,help,helper,321,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:458,usability,Help,Helper,458,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:523,usability,Help,Helper,523,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:534,usability,Help,Helper,534,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:541,usability,Help,Helper,541,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:759,usability,help,helper,759,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:827,usability,help,helper,827,"[TDF] Add TInterface::Book method to let users register a custom action; Documentation of the method reported here for ease of review:. This method books a custom action for execution. The behavior of the action is completely dependent on the. Helper object provided by the caller. The minimum required interface for the helper is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1320,usability,help,helpers,1320,"per is the following (more. methods can be present, e.g. a constructor that takes the number of worker threads is usually useful):. * Helper must publicly inherit from ROOT::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1905:1705,usability,help,helper,1705,"::Detail::TDF::TActionImpl<Helper>. * Helper(Helper &&): a move-constructor is required. Copy-constructors are discouraged. * ColumnTypes_t: alias for a ROOT::TypeTraits::TypeList instantiation that specifies the types of the. columns to be passed to this action helper. * Result_t: alias for the type of the result of this action helper. Must be default-constructible. * ROOT::Detail::TDF::ColumnNames_t GetColumnNames() const: return the names of the columns processed by this. action. The number of names must be equal to the size of ColumnTypes_t. * void Exec(unsigned int slot, ColumnTypes...columnValues): each working thread shall call this method. during the event-loop, possibly concurrently. No two threads will ever call Exec with the same 'slot' value:. this parameter is there to facilitate writing thread-safe helpers. The other arguments will be the values of. the requested columns for the particular entry being processed. * void InitTask(TTreeReader *, unsigned int slot): each working thread shall call this method during the event. loop, before processing a batch of entries (possibly read from the TTreeReader passed as argument, if not null). This method can be used e.g. to prepare the helper to process a batch of entries in a given thread. Can be no-op. * void Initialize(): this method is called once before starting the event-loop. Useful for setup operations. Can be no-op. * void Finalize(): this method is called at the end of the event loop. Commonly used to finalize the contents. of the result. * Result_t &PartialUpdate(unsigned int slot): this method is optional, i.e. can be omitted. If present, it should. return the value of the partial result of this action for the given 'slot'. Different threads might call this. method concurrently, but will always pass different 'slot' numbers. * std::shared_ptr<Result_t> GetResultPtr() const: return a shared_ptr to the result of this action (of type. Result_t). The TResultPtr returned by Book will point to this object.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1905
https://github.com/root-project/root/pull/1906:36,integrability,interfac,interface,36,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:36,interoperability,interfac,interface,36,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:36,modifiability,interfac,interface,36,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:54,safety,test,tests,54,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:46,testability,simpl,simple,46,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:54,testability,test,tests,54,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1906:46,usability,simpl,simple,46,"[TDF][TO REVERT] Disable dataframe_{interface,simple} tests; To revert when we are ready for debugging.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1906
https://github.com/root-project/root/pull/1907:183,availability,error,error,183,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:0,deployability,Updat,Update,0,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:29,deployability,version,version,29,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:158,deployability,build,build,158,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:29,integrability,version,version,29,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:29,modifiability,version,version,29,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:183,performance,error,error,183,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:0,safety,Updat,Update,0,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
https://github.com/root-project/root/pull/1907:183,safety,error,error,183,"Update builtin Davix back to version 0.6.7; This reverts commit 2ecf45e5a37ab3f1108c5a9068b3cf330242b9dd, and makes some extra adjustments for Davix 0.6.7 to build or provide a clear error if something is missing in the system.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/1907
