id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/546:907,performance,gpu,gpu,907,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1064,performance,parallel,parallelized,1064,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:104,reliability,fail,failed,104,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:679,reliability,availab,available,679,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:87,safety,error,error,87,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:264,safety,ERROR,ERROR,264,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:679,safety,avail,available,679,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:679,security,availab,available,679,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:731,security,ssh,ssh,731,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1138,security,configur,configuration,1138,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:58,usability,command,command,58,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:87,usability,error,error,87,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:264,usability,ERROR,ERROR,264,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:288,usability,statu,status,288,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:528,usability,interact,interaction,528,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:601,usability,interact,interactive,601,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:759,usability,interact,interactive,759,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:983,usability,command,command,983,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1254,usability,close,close,1254,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1288,usability,help,help,1288,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,availability,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,deployability,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:120,energy efficiency,cpu,cpus-per-task,120,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:533,energy efficiency,cpu,cpus-per-task,533,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:609,energy efficiency,cpu,cpus,609,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,energy efficiency,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1052,energy efficiency,alloc,allocation,1052,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1152,energy efficiency,alloc,allocating,1152,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1163,energy efficiency,CPU,CPUs,1163,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:782,integrability,sub,submitting,782,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:972,integrability,sub,submitting,972,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:707,interoperability,specif,specific,707,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:120,performance,cpu,cpus-per-task,120,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:533,performance,cpu,cpus-per-task,533,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:609,performance,cpu,cpus,609,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:936,performance,parallel,parallelism,936,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1163,performance,CPU,CPUs,1163,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:558,reliability,doe,does,558,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,reliability,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,safety,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1006,testability,monitor,monitoring,1006,"ah good catch sorry I missed the image! It has been a while since I have used slurm, but you could try:. ```. #SBATCH --cpus-per-task=28. #SBATCH --ntasks-per-node=1 # Or don't set this. ```. See the explanation for `--ntasks-per-node`:. `--ntasks-per-node=<ntasks>`. > Request that ntasks be invoked on each node. If used with the --ntasks option, the --ntasks option will take precedence and the --ntasks-per-node will be treated as a maximum count of tasks per node. Meant to be used with the --nodes option. This is related to --cpus-per-task=ncpus, but does not require knowledge of the actual number of cpus on each node. In some cases, it is more convenient to be able to request that no more than a specific number of tasks be invoked on each node. Examples of this include submitting a hybrid MPI/OpenMP app where only one MPI ""task/rank"" should be assigned to each node while allowing the OpenMP portion to utilize all of the parallelism present in the node, or submitting a single setup/cleanup/monitoring job to each node of a pre-existing allocation as one step in a larger job script. I think the issue is that `--ntasks-per-node` is not allocating CPUs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:27,energy efficiency,cpu,cpus-per-task,27,"Thanks, Daniel. Setting `--cpus-per-task=28` (or just not setting --ntasks at all) did the trick. I'll go ahead and close this. Thanks! Dave",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:27,performance,cpu,cpus-per-task,27,"Thanks, Daniel. Setting `--cpus-per-task=28` (or just not setting --ntasks at all) did the trick. I'll go ahead and close this. Thanks! Dave",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:116,usability,close,close,116,"Thanks, Daniel. Setting `--cpus-per-task=28` (or just not setting --ntasks at all) did the trick. I'll go ahead and close this. Thanks! Dave",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/547:226,deployability,observ,observation,226,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:256,energy efficiency,measur,measures,256,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:801,energy efficiency,measur,measure,801,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:710,integrability,filter,filtering,710,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:226,testability,observ,observation,226,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:459,usability,clear,clearly,459,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/547:776,usability,prefer,preferable,776,"Hi @elcortegano . Just to clarify, are you referring to the QUAL field of the VCF (the 6th column of tab-file itself), or the GQ field (the 10th column of a single sample). If you are referring to QUAL as the 6th column, this observation is expected. QUAL measures the probability that the ALT field has at least one allele with the ALT base. So you can think of it as p(HET) + p(HOM), or alternatively as 1 - p(REF). For homozygous positions, they look more clearly non-reference as in many cases they may not have any reference bases. . Heterozygous positions likely have at least some evidence for the Ref allele, which suggests a higher probability that the position might be Ref. If you are interested in filtering, we often recommend that the GQ field in the samples is preferable, as this is a measure of the genotype call itself being correct. There may be some differences between HET and HOM for this due to differences in difficulty in making those types of calls. However, it should be lower.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/547
https://github.com/google/deepvariant/issues/548:5,availability,error,error,5,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:125,modifiability,interm,intermediate,125,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:5,performance,error,error,5,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:5,safety,error,error,5,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:227,testability,simul,simultaneously,227,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:5,usability,error,error,5,This error is most likely due to the corrupted tf records file which is the output of call_variants step. In your set up the intermediate results are dumped into /tmp. Could it be that you ran multiple instances of deepvariant simultaneously with the same output directory?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:86,usability,help,help,86,"Yes, you are right. Running each job one-by-one solves the problem! . Thanks for your help and for developing this nice tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/548:120,usability,tool,tool,120,"Yes, you are right. Running each job one-by-one solves the problem! . Thanks for your help and for developing this nice tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/548
https://github.com/google/deepvariant/issues/549:140,deployability,version,version,140,"Hi @amyhouseman ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:140,integrability,version,version,140,"Hi @amyhouseman ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:140,modifiability,version,version,140,"Hi @amyhouseman ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:863,deployability,version,version,863,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:268,integrability,Sub,Subject,268,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:863,integrability,version,version,863,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:2395,integrability,Messag,Message,2395,"A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FANUP4ZC4YG3AONVCKJ7RT53VW27C7ANCNFSM55E3G3QA&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Ci6wL9MBJUn9xtmb4eLWiMAZi%2BFEFI03EvFd2jZp0rc%3D&reserved=0>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:2395,interoperability,Messag,Message,2395,"A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FANUP4ZC4YG3AONVCKJ7RT53VW27C7ANCNFSM55E3G3QA&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Ci6wL9MBJUn9xtmb4eLWiMAZi%2BFEFI03EvFd2jZp0rc%3D&reserved=0>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:863,modifiability,version,version,863,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:375,safety,safe,safelinks,375,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:986,safety,safe,safelinks,986,"Amazing, thank you! Amy. Get Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. From: Kishwar Shafin ***@***.***>. Sent: Sunday, July 31, 2022 7:15:11 PM. To: google/deepvariant ***@***.***>. Cc: Amy Houseman ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] What hg38 would you suggest? (Issue #549). Hi @amyhouseman<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscri",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:1464,safety,safe,safelinks,1464,"A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FANUP4ZC4YG3AONVCKJ7RT53VW27C7ANCNFSM55E3G3QA&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Ci6wL9MBJUn9xtmb4eLWiMAZi%2BFEFI03EvFd2jZp0rc%3D&reserved=0>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:1910,safety,safe,safelinks,1910,"A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FANUP4ZC4YG3AONVCKJ7RT53VW27C7ANCNFSM55E3G3QA&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Ci6wL9MBJUn9xtmb4eLWiMAZi%2BFEFI03EvFd2jZp0rc%3D&reserved=0>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/549:2003,security,auth,auth,2003,"A%2F%2Fgithub.com%2Famyhouseman&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=r2WZK5XXX5pgimGQX1ckdqp3N6Cyk1wXH92kGK00jKA%3D&reserved=0> ,. Please use: GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz. You can read further explanation of why this is the best version to use in this blog by Heng Li: https://lh3.github.io/2017/11/13/which-human-reference-genome-to-use<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Flh3.github.io%2F2017%2F11%2F13%2Fwhich-human-reference-genome-to-use&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=eEiHxUnxYv8doc%2F5aVYE%2BH0tGcKjhXbXSsKtMkSBbUQ%3D&reserved=0>. . Reply to this email directly, view it on GitHub<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgoogle%2Fdeepvariant%2Fissues%2F549%23issuecomment-1200473679&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=oDUjWabQjt0eM86LLzt%2BsJ5ERoJ0BBRm5863uX0qH4w%3D&reserved=0>, or unsubscribe<https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FANUP4ZC4YG3AONVCKJ7RT53VW27C7ANCNFSM55E3G3QA&data=05%7C01%7C%7C2692a76d3d554223df0208da73209c7f%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637948881139900777%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=Ci6wL9MBJUn9xtmb4eLWiMAZi%2BFEFI03EvFd2jZp0rc%3D&reserved=0>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/549
https://github.com/google/deepvariant/issues/550:123,safety,avoid,avoid,123,"hi @IndyHouseGuy ,. You can add . ```. docker run -it -v /data:/data \. -u `id -u`:`id -g`. ```. to your docker command to avoid this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:112,usability,command,command,112,"hi @IndyHouseGuy ,. You can add . ```. docker run -it -v /data:/data \. -u `id -u`:`id -g`. ```. to your docker command to avoid this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1818,availability,echo,echo,1818,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:2513,integrability,Messag,Message,2513,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:2513,interoperability,Messag,Message,2513,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:453,safety,input,input,453,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:723,safety,input,input,723,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1360,safety,input,input,1360,"curity purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <htt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1619,safety,input,input,1619,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:2183,safety,avoid,avoid,2183,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:361,security,secur,security,361,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1252,security,secur,security,1252,"/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitH",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:2405,security,auth,auth,2405,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:96,usability,ui,uid,96,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:185,usability,command,command,185,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:453,usability,input,input,453,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:723,usability,input,input,723,"Thank you for the quick response. I tried that and still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1046,usability,command,command,1046," still got files by root. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://gith",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1068,usability,command,command,1068,"ot. I tried setting the uid and. groupid explicitly and using the dynamic method you recommended. Please advise. command:. deep_dir=deep_variant_id80429g20. mkdir -p XXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # This was ran, XXXXXXX are directories marked out for security purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1360,usability,input,input,1360,"curity purposes. docker run -it -u 80429:20 -v. XXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. XXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXXXXXXXXXXX/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <htt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1619,usability,input,input,1619,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:2172,usability,command,command,2172,"X/analysis/deepvariant/data:/data -v. XXXXXXXXXXXXXXXXXX/bed:/bed google/deepvariant:0.9.0. /opt/deepvariant/bin/run_deepvariant --model_type=WES. --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. Results:. ls -ltrh deep_variant_id80429g20/. drwxr-sr-x 2 root root 4.0K Aug 4 12:15 xGENIDTn2_DeepVariant. And I've set the command dynamically:. command:. deep_dir=deep_variant_dynamic1b. mkdir -p /XXXXXXXXXXXXXXXXXXXXX/$deep_dir. docker pull google/deepvariant:0.9.0. # this was ran, some directories censored by XXXXXXXXXX for security reasons. LINE='docker run -it -u `id -u`:`id -g` -v. /XXXXXXXXXXXXXXXXXXXXX/gatk_align_metrics_t/:/input -v. /XXXXXXXXXXXXXXXXXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v. /XXXXXXXXX/deepvariant/data:/data -v /XXXXXXXXXXXXXXXXXXXXX/bed:/bed. google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant. --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam. --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed. --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz. --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12'. echo ""$LINE"". eval $LINE. Results:. ls -ltrh deep_variant_dynamic1b. drwxr-sr-x 2 root root 4.0K Aug 4 12:24 xGENIDTn2_DeepVariant. On Thu, Aug 4, 2022 at 1:59 PM Kishwar Shafin ***@***.***>. wrote:. > hi @IndyHouseGuy <https://github.com/IndyHouseGuy> ,. >. > You can add. >. > docker run -it -v /data:/data \. > -u `id -u`:`id -g`. >. > to your docker command to avoid this issue. >. > . > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/550#issuecomment-1205591500>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/A2LCPRQWWLAYOZXICW5LXSDVXQAGNANCNFSM55QXIB6A>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:665,safety,input,input,665,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:896,safety,input,input,896,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1410,safety,input,input,1410,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1641,safety,input,input,1641,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:84,usability,effectiv,effective,84,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:116,usability,user,user,116,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:142,usability,user,user,142,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:347,usability,command,commands,347,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:366,usability,user,user,366,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:510,usability,Statu,Status,510,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:665,usability,input,input,665,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:896,usability,input,input,896,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1104,usability,user,user,1104,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1248,usability,Statu,Status,1248,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1410,usability,input,input,1410,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1641,usability,input,input,1641,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:1868,usability,help,help,1868,Trying to make this more legible. Replying via email is convenient but not the most effective:. I've tried using `--user`. ```. docker --rm --user $CURRENT_UID. ```. and the `-u` function recommended but dynamic:. ```. docker run -it -u `id -u`:`id -g`. ```. And explicit:. ```. docker run -it -u 80429:20. ```. Both output root owned files. Full commands. Explicit user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u 80429:20 -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. Dynamic user assignment:. ```. 0.9.0: Pulling from google/deepvariant. Digest: sha256:831ca296035d5317d98cb33034b484cabccc3c7210c5353c8f132c52a7705046. Status: Image is up to date for google/deepvariant:0.9.0. docker.io/google/deepvariant:0.9.0. docker run -it -u `id -u`:`id -g` -v /XXXXXX/gatk_align_metrics_t/:/input -v /XXXXXX/$deep_dir/xGENIDTn2_DeepVariant:/output -v /XXXXXX/analysis/deepvariant/data:/data -v /XXXXXX/bed:/bed google/deepvariant:0.9.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=/data/hg38.fa.gz --reads=/input/xGENIDTn2.bam --regions=/bed/xgen-exome-hyb-panel-v2-targets-hg38.bed --output_vcf=/output/xGENIDTn2_DeepVariant.vcf.gz --output_gvcf=/output/xGENIDTn2_DeepVariant.gvcf.gz --num_shards=12. ```. All create root files. Any help is most welcome.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:80,deployability,stack,stackoverflow,80,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:124,deployability,contain,container-creating-directories-owned-by-root-i-need-them-owned-by-,124,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:379,performance,time,time,379,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:46,safety,test,test,46,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:333,safety,test,test,333,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:38,testability,simpl,simpler,38,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:46,testability,test,test,46,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:333,testability,test,test,333,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:38,usability,simpl,simpler,38,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:252,usability,behavi,behavior,252,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:351,usability,behavi,behavior,351,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:368,usability,Command,Command,368,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:487,usability,Command,Command,487,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:804,usability,behavi,behavior,804,"@IndyHouseGuy , . Can you please do a simpler test? According to [this](https://stackoverflow.com/questions/50317119/docker-container-creating-directories-owned-by-root-i-need-them-owned-by-10001), there can be a number of things that might cause this behavior, including implicitly running docker as root in the system. In my local test, I have this behavior. ```. # Command 1. time docker run -it -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker. # Command 2. docker run -it -u `id -u`:`id -g` -v /data:/data \. google/deepvariant:0.9.0 \. mkdir /data/kishwar/test_ubuntu_docker_u. ```. Output:. ```. root root 4.0K Aug 5 14:55 test_ubuntu_docker/. shafin primarygroup 4.0K Aug 5 14:55 test_ubuntu_docker_u/. ```. Can you please run this and see if you get the same behavior?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:178,security,access,access,178,"I've got it working now. What I reported earlier was correct and I'm happy to explore this further. Oddly enough, I now have a bed file owned by root as well. I do not have root access on this machine which explains why some HPC's have banned docker. I'll investigate the differences and report back. Good new is I have it working so there is no action need on your end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/550:7,usability,close,close,7,I will close this for now given that it seems to be resolved. Feel free to reopen later if needed.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/550
https://github.com/google/deepvariant/issues/552:40,availability,error,error,40,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:56,deployability,stack,stackoverflow,56,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:277,deployability,version,version,277,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:340,deployability,build,build,340,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:277,integrability,version,version,277,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:113,interoperability,architectur,architectures-support-,113,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:244,interoperability,incompatib,incompatible,244,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:277,modifiability,version,version,277,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:40,performance,error,error,40,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:40,safety,error,error,40,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:40,usability,error,error,40,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:127,usability,support,support-,127,"@Argonvi here is some background on the error:. https://stackoverflow.com/questions/28185844/do-all-64-bit-intel-architectures-support-ssse3-sse4-1-sse4-2-instructions. My guess here is that the processor being used is either (a) older, or (b) incompatible with the dockerized version of DeepVariant. One way around this might be to try to build DeepVariant yourself.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:167,availability,error,error,167,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3757,availability,ERROR,ERROR,3757,"allation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4254,availability,ERROR,ERROR,4254,"ual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into ac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4770,availability,ERROR,ERROR,4770,"endency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5193,availability,ERROR,ERROR,5193,"15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6741,availability,Down,Download,6741,"rereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7203,availability,down,download,7203,"do unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7278,availability,down,downloaded,7278,"ge 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ==",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10248,availability,ERROR,ERROR,10248,"pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13071,availability,ERROR,ERROR,13071,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:98,deployability,build,building,98,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:136,deployability,build,build-prereq,136,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:208,deployability,depend,dependencies,208,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:359,deployability,Stage,Stage,359,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:366,deployability,Instal,Install,366,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:542,deployability,Stage,Stage,542,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:996,deployability,Stage,Stage,996,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1003,deployability,Updat,Update,1003,"lecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNIN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1459,deployability,Stage,Stage,1459,"04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1481,deployability,Instal,Install,1481,"fig settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1592,deployability,Stage,Stage,1592,"://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1599,deployability,Instal,Install,1599,"ntray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1625,deployability,infrastructur,infrastructure,1625,"-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distributio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2678,deployability,Instal,Installing,2678,"ge Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2756,deployability,instal,installation,2756," 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2891,deployability,instal,installed,2891,"t-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3072,deployability,instal,installed,3072,"ges). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3217,deployability,manag,manager,3217," (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protob",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3714,deployability,Stage,Stage,3714,"empting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Ins",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3721,deployability,Instal,Install,3721,"uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3770,deployability,depend,dependency,3770,"2.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3853,deployability,instal,installed,3853,"scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3910,deployability,depend,dependency,3910,"al/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4150,deployability,api,api-core,4150," permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4267,deployability,depend,dependency,4267," instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4350,deployability,instal,installed,4350," -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependenc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4407,deployability,depend,dependency,4407,"NG: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4665,deployability,Stage,Stage,4665,"). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4672,deployability,Instal,Install,4672,"===== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4714,deployability,Instal,Installing,4714," 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4783,deployability,depend,dependency,4783,"r does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [ju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4866,deployability,instal,installed,4866,"haviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obte",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4923,deployability,depend,dependency,4923,"ts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5078,deployability,Stage,Stage,5078,">=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5085,deployability,Instal,Install,5085,", but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5152,deployability,Stage,Stage,5152,"ore 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5159,deployability,Instal,Install,5159,"2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5206,deployability,depend,dependency,5206,"ave protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5289,deployability,instal,installed,5289,"t currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5346,deployability,depend,dependency,5346,"nstalled. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5586,deployability,api,api-core,5586,"ng 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ====",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5733,deployability,Stage,Stage,5733,"-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5817,deployability,Stage,Stage,5817,"y take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5824,deployability,Updat,Update,5824,"into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6280,deployability,Stage,Stage,6280,"t are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6287,deployability,build,build-prereq,6287,"alled. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Ple",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6304,deployability,Instal,Install,6304,"aviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify opt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6415,deployability,Stage,Stage,6415," pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6422,deployability,Instal,Install,6422,"ng 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6542,deployability,instal,installed,6542,"f 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for An",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6629,deployability,Stage,Stage,6629,"15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by addi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6636,deployability,Instal,Install,6636,"t you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6680,deployability,instal,installed,6680,"ble. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6734,deployability,Stage,Stage,6734,"e 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL su",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6927,deployability,updat,update-relnotes,6927,"Release Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6965,deployability,instal,installed,6965,"94.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_ker",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6991,deployability,build,build,6991,"al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Bu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7097,deployability,build,build,7097,".194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7220,deployability,releas,release,7220,"en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7496,deployability,build,builds,7496,"re_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7553,deployability,build,builds,7553,"he machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7581,deployability,build,build,7581,". ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7657,deployability,build,build,7657,"rting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring inv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7720,deployability,Build,Build,7720,"1:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7769,deployability,Build,Build,7769,"ow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -ypa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7899,deployability,build,build,7899,"52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7924,deployability,Build,Build,7924,"update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7992,deployability,Build,Build,7992,"d TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully un",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8052,deployability,Build,Build,8052,"be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8076,deployability,API,API,8076,"ow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in br",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8096,deployability,API,API,8096,"uild TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8121,deployability,build,build,8121,"support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour wit",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8257,deployability,Configurat,Configuration,8257,"g will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8324,deployability,Stage,Stage,8324,"use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8918,deployability,instal,installation,8918,Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9145,deployability,manag,manager,9145,ault on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9942,deployability,Instal,Installing,9942,". Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10261,deployability,depend,dependency,10261," /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10344,deployability,instal,installed,10344,"id distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10401,deployability,depend,dependency,10401,"ackages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10590,deployability,instal,installed,10590,"cting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -ypa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10740,deployability,manag,manager,10740,"thon3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing ins",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11147,deployability,Stage,Stage,11147,"ist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11741,deployability,instal,installation,11741,. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11968,deployability,manag,manager,11968,arsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12765,deployability,Instal,Installing,12765,". Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13084,deployability,depend,dependency,13084,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13167,deployability,instal,installed,13167,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13224,deployability,depend,dependency,13224,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13413,deployability,instal,installed,13413,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13563,deployability,manag,manager,13563,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13970,deployability,Stage,Stage,13970,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13977,deployability,build,build-prereq,13977,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:294,energy efficiency,Load,Load,294,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:477,energy efficiency,Load,Load,477,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1707,energy efficiency,Current,Current,1707,"l obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3217,energy efficiency,manag,manager,3217," (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protob",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3799,energy efficiency,current,currently,3799,"2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4154,energy efficiency,core,core,4154,"ermissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4296,energy efficiency,current,currently,4296,"/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4733,energy efficiency,CPU,CPU-only,4733,"packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4812,energy efficiency,current,currently,4812,"o account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5235,energy efficiency,current,currently,5235,"incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ===",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5590,energy efficiency,core,core,5590," 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ======",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6807,energy efficiency,core,core,6807,"9 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7305,energy efficiency,optim,optimization,7305," development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9145,energy efficiency,manag,manager,9145,ault on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10290,energy efficiency,current,currently,10290,"ite-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10740,energy efficiency,manag,manager,10740,"thon3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing ins",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11968,energy efficiency,manag,manager,11968,arsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13113,energy efficiency,current,currently,13113,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13563,energy efficiency,manag,manager,13563,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:185,integrability,messag,messages,185,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:208,integrability,depend,dependencies,208,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3770,integrability,depend,dependency,3770,"2.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3910,integrability,depend,dependency,3910,"al/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4150,integrability,api,api-core,4150," permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4267,integrability,depend,dependency,4267," instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4407,integrability,depend,dependency,4407,"NG: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4783,integrability,depend,dependency,4783,"r does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [ju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4923,integrability,depend,dependency,4923,"ts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5206,integrability,depend,dependency,5206,"ave protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5346,integrability,depend,dependency,5346,"nstalled. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5586,integrability,api,api-core,5586,"ng 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ====",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6754,integrability,configur,configure,6754,"ete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7462,integrability,configur,configure,7462,"bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7515,integrability,configur,configuring,7515," Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8076,integrability,API,API,8076,"ow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in br",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8096,integrability,API,API,8096,"uild TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8257,integrability,Configur,Configuration,8257,"g will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10261,integrability,depend,dependency,10261," /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10401,integrability,depend,dependency,10401,"ackages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13084,integrability,depend,dependency,13084,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13224,integrability,depend,dependency,13224,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:185,interoperability,messag,messages,185,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1845,interoperability,distribut,distribution,1845,"o descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNIN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1935,interoperability,distribut,distribution,1935,"n su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2026,interoperability,distribut,distribution,2026,". W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2109,interoperability,distribut,distribution,2109,"elease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2199,interoperability,distribut,distribution,2199,"/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the sys",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2290,interoperability,distribut,distribution,2290,"W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2440,interoperability,distribut,distribution,2440,":11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2530,interoperability,distribut,distribution,2530,"r_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2621,interoperability,distribut,distribution,2621,"frastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3171,interoperability,conflict,conflicting,3171,"ING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires pro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3343,interoperability,distribut,distribution,3343,"llecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3433,interoperability,distribut,distribution,3433," distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3524,interoperability,distribut,distribution,3524,"distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3921,interoperability,conflict,conflicts,3921,"ch is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4008,interoperability,incompatib,incompatible,4008,"this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 wh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4129,interoperability,incompatib,incompatible,4129,"an result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 202",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4150,interoperability,api,api-core,4150," permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] St",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4240,interoperability,incompatib,incompatible,4240," use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4418,interoperability,conflict,conflicts,4418,"g invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pypa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4518,interoperability,incompatib,incompatible,4518,"distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4608,interoperability,incompatib,incompatible,4608,"oot/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires prot",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4934,interoperability,conflict,conflicts,4934,"0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRele",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5021,interoperability,incompatib,incompatible,5021,"eapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5357,interoperability,conflict,conflicts,5357,"his behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5444,interoperability,incompatib,incompatible,5444,"quires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WAR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5565,interoperability,incompatib,incompatible,5565,"ut you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5586,interoperability,api,api-core,5586,"ng 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ====",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5676,interoperability,incompatib,incompatible,5676,"nsorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7297,interoperability,specif,specify,7297,"h: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7386,interoperability,specif,specified,7386,"ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignorin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7819,interoperability,Architectur,Architecture,7819,"generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8020,interoperability,share,shared,8020,"rt? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8076,interoperability,API,API,8076,"ow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in br",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8096,interoperability,API,API,8096,"uild TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8401,interoperability,distribut,distribution,8401," -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8491,interoperability,distribut,distribution,8491,"uilds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8582,interoperability,distribut,distribution,8582,"onfigs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8665,interoperability,distribut,distribution,8665, See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (5,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8755,interoperability,distribut,distribution,8755,ch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-pack,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8846,interoperability,distribut,distribution,8846,olithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-pack,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9099,interoperability,conflict,conflicting,9099,onfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distr,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9352,interoperability,distribut,distribution,9352,CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. Thi,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9442,interoperability,distribut,distribution,9442,/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9533,interoperability,distribut,distribution,9533,"/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9704,interoperability,distribut,distribution,9704,".8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting beha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9794,interoperability,distribut,distribution,9794,"3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment inst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9885,interoperability,distribut,distribution,9885,"-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10010,interoperability,distribut,distribution,10010,".0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10100,interoperability,distribut,distribution,10100,"ting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ==",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10191,interoperability,distribut,distribution,10191,"ent instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10412,interoperability,conflict,conflicts,10412,"ARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10563,interoperability,incompatib,incompatible,10563,"n3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10694,interoperability,conflict,conflicting,10694,"lid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10866,interoperability,distribut,distribution,10866,"ring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10956,interoperability,distribut,distribution,10956," packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11047,interoperability,distribut,distribution,11047,"n3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11224,interoperability,distribut,distribution,11224,"8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11314,interoperability,distribut,distribution,11314,"l the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11405,interoperability,distribut,distribution,11405," conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11488,interoperability,distribut,distribution,11488,"2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11578,interoperability,distribut,distribution,11578,fully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-pack,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11669,interoperability,distribut,distribution,11669,en permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-pack,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11922,interoperability,conflict,conflicting,11922,. WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distr,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12175,interoperability,distribut,distribution,12175,CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. Thi,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12265,interoperability,distribut,distribution,12265,/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12356,interoperability,distribut,distribution,12356,"/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12527,interoperability,distribut,distribution,12527,".8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting beha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12617,interoperability,distribut,distribution,12617,"3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment inst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12708,interoperability,distribut,distribution,12708,"-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12833,interoperability,distribut,distribution,12833,".2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12923,interoperability,distribut,distribution,12923,"ting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ==",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13014,interoperability,distribut,distribution,13014,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13235,interoperability,conflict,conflicts,13235,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13386,interoperability,incompatib,incompatible,13386,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13517,interoperability,conflict,conflicting,13517,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13689,interoperability,distribut,distribution,13689,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13779,interoperability,distribut,distribution,13779,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13870,interoperability,distribut,distribution,13870,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:208,modifiability,depend,dependencies,208,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:254,modifiability,maintain,maintained,254,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:386,modifiability,pac,packages,386,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:437,modifiability,maintain,maintained,437,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1010,modifiability,pac,package,1010,"han you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1501,modifiability,pac,packages,1501,"==== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1615,modifiability,pac,packaging,1615,"ce/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1898,modifiability,pac,packages,1898,"ido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1989,modifiability,pac,packages,1989,"T] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2072,modifiability,pac,packages,2072,"basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully inst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2162,modifiability,pac,packages,2162," Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2253,modifiability,pac,packages,2253,"l la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2336,modifiability,pac,packages,2336,"os de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring inval",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2493,modifiability,pac,packages,2493,"ent packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2584,modifiability,pac,packages,2584,"ST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2667,modifiability,pac,packages,2667," Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2699,modifiability,pac,packages,2699,"ime Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3209,modifiability,pac,package,3209,"yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you hav",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3396,modifiability,pac,packages,3396,"whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fol",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3487,modifiability,pac,packages,3487,"t-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you hav",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3570,modifiability,pac,packages,3570,"n3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3644,modifiability,pac,packages,3644,"lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 202",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3737,modifiability,pac,packages,3737,"Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3770,modifiability,depend,dependency,3770,"2.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3835,modifiability,pac,packages,3835,".2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3910,modifiability,depend,dependency,3910,"al/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4267,modifiability,depend,dependency,4267," instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4332,modifiability,pac,packages,4332,"nvalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4407,modifiability,depend,dependency,4407,"NG: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4695,modifiability,pac,package,4695,"14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. =========",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4783,modifiability,depend,dependency,4783,"r does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [ju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4848,modifiability,pac,packages,4848," installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' startin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4923,modifiability,depend,dependency,4923,"ts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5173,modifiability,pac,packages,5173,"tobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5206,modifiability,depend,dependency,5206,"ave protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5271,modifiability,pac,packages,5271,"cy resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5346,modifiability,depend,dependency,5346,"nstalled. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5831,modifiability,pac,package,5831,"ount all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6324,modifiability,pac,packages,6324," of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6754,modifiability,configur,configure,6754,"ete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7462,modifiability,configur,configure,7462,"bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7515,modifiability,configur,configuring,7515," Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8257,modifiability,Configur,Configuration,8257,"g will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8454,modifiability,pac,packages,8454,"ely configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8545,modifiability,pac,packages,8545,"oid builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8628,modifiability,pac,packages,8628,"ng ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8718,modifiability,pac,packages,8718,ild with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -pars,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8809,modifiability,pac,packages,8809,e Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -ypars,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8892,modifiability,pac,packages,8892,ic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distributio,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9137,modifiability,pac,package,9137,ABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/py,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9299,modifiability,pac,packages,9299, 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently tak,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9405,modifiability,pac,packages,9405,tion -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependen,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9496,modifiability,pac,packages,9496,"ion -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9579,modifiability,pac,packages,9579,"istribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Succes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9757,modifiability,pac,packages,9757,"bution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recomm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9848,modifiability,pac,packages,9848,"bution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ign",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9931,modifiability,pac,packages,9931,"arsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9963,modifiability,pac,packages,9963,"sing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distributio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10063,modifiability,pac,packages,10063,"esult in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10154,modifiability,pac,packages,10154,"s recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10237,modifiability,pac,packages,10237,"nv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -par",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10261,modifiability,depend,dependency,10261," /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10326,modifiability,pac,packages,10326,"ING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10401,modifiability,depend,dependency,10401,"ackages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10732,modifiability,pac,package,10732,"l/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found exis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10919,modifiability,pac,packages,10919,".8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11010,modifiability,pac,packages,11010,"ribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual en",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11093,modifiability,pac,packages,11093,"id distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11277,modifiability,pac,packages,11277,"does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11368,modifiability,pac,packages,11368," the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11451,modifiability,pac,packages,11451,"ng!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11541,modifiability,pac,packages,11541,ng 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -pars,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11632,modifiability,pac,packages,11632,p as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -ypars,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11715,modifiability,pac,packages,11715,h the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distributio,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11960,modifiability,pac,package,11960,tion -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/py,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12122,modifiability,pac,packages,12122, 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently tak,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12228,modifiability,pac,packages,12228,tion -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependen,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12319,modifiability,pac,packages,12319,"ion -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2;",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12402,modifiability,pac,packages,12402,"istribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Succes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12580,modifiability,pac,packages,12580,"bution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recomm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12671,modifiability,pac,packages,12671,"bution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ign",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12754,modifiability,pac,packages,12754,"arsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12786,modifiability,pac,packages,12786,"sing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distributio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12886,modifiability,pac,packages,12886,"esult in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12977,modifiability,pac,packages,12977,"s recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'buil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13060,modifiability,pac,packages,13060,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13084,modifiability,depend,dependency,13084,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13149,modifiability,pac,packages,13149,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13224,modifiability,depend,dependency,13224,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13555,modifiability,pac,package,13555,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13742,modifiability,pac,packages,13742,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13833,modifiability,pac,packages,13833,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13916,modifiability,pac,packages,13916,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:167,performance,error,error,167,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:294,performance,Load,Load,294,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:477,performance,Load,Load,477,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1692,performance,Time,Time,1692,"9 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing colle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1697,performance,Time,Time,1697,". W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1702,performance,Time,Time,1702,"Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2369,performance,cach,cached,2369,"se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3757,performance,ERROR,ERROR,3757,"allation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4254,performance,ERROR,ERROR,4254,"ual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into ac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4733,performance,CPU,CPU-only,4733,"packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4770,performance,ERROR,ERROR,4770,"endency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5193,performance,ERROR,ERROR,5193,"15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7305,performance,optimiz,optimization,7305," development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9625,performance,cach,cached,9625,"packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Ru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10248,performance,ERROR,ERROR,10248,"pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:12448,performance,cach,cached,12448,"packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Ru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13071,performance,ERROR,ERROR,13071,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3790,reliability,doe,does,3790,"ng pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependenc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4287,reliability,doe,does,4287,"/pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4803,reliability,doe,does,4803,"tly take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5226,reliability,doe,does,5226,".0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10281,reliability,doe,does,10281,"/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13104,reliability,doe,does,13104,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:167,safety,error,error,167,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:208,safety,depend,dependencies,208,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:254,safety,maintain,maintained,254,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:437,safety,maintain,maintained,437,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1003,safety,Updat,Update,1003,"lecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNIN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3155,safety,permiss,permissions,3155,"-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3217,safety,manag,manager,3217," (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protob",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3757,safety,ERROR,ERROR,3757,"allation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3770,safety,depend,dependency,3770,"2.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3910,safety,depend,dependency,3910,"al/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4254,safety,ERROR,ERROR,4254,"ual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into ac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4267,safety,depend,dependency,4267," instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4407,safety,depend,dependency,4407,"NG: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4770,safety,ERROR,ERROR,4770,"endency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4783,safety,depend,dependency,4783,"r does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [ju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4923,safety,depend,dependency,4923,"ts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5193,safety,ERROR,ERROR,5193,"15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5206,safety,depend,dependency,5206,"ave protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5346,safety,depend,dependency,5346,"nstalled. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5754,safety,compl,complete,5754,".7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and conf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5824,safety,Updat,Update,5824,"into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6927,safety,updat,update-relnotes,6927,"Release Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9083,safety,permiss,permissions,9083,f TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignori,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9145,safety,manag,manager,9145,ault on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10248,safety,ERROR,ERROR,10248,"pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10261,safety,depend,dependency,10261," /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10401,safety,depend,dependency,10401,"ackages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10678,safety,permiss,permissions,10678,"G: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10740,safety,manag,manager,10740,"thon3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing ins",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11906,safety,permiss,permissions,11906,8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignori,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11968,safety,manag,manager,11968,arsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13071,safety,ERROR,ERROR,13071,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13084,safety,depend,dependency,13084,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13224,safety,depend,dependency,13224,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13501,safety,permiss,permissions,13501,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13563,safety,manag,manager,13563,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13993,safety,compl,complete,13993,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:1003,security,Updat,Update,1003,"lecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNIN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5754,security,compl,complete,5754,".7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and conf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5824,security,Updat,Update,5824,"into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_ge",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6754,security,configur,configure,6754,"ete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:6927,security,updat,update-relnotes,6927,"Release Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7413,security,sign,sign-compare,7413,"e 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -pars",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7462,security,configur,configure,7462,"bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7515,security,configur,configuring,7515," Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8257,security,Configur,Configuration,8257,"g will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13993,security,compl,complete,13993,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:208,testability,depend,dependencies,208,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3770,testability,depend,dependency,3770,"2.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3910,testability,depend,dependency,3910,"al/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4267,testability,depend,dependency,4267," instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4407,testability,depend,dependency,4407,"NG: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but yo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4783,testability,depend,dependency,4783,"r does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [ju",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4923,testability,depend,dependency,4923,"ts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5206,testability,depend,dependency,5206,"ave protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5346,testability,depend,dependency,5346,"nstalled. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10261,testability,depend,dependency,10261," /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10401,testability,depend,dependency,10401,"ackages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13084,testability,depend,dependency,13084,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13224,testability,depend,dependency,13224,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:167,usability,error,error,167,"@danielecook than you for your answer. I tried the solution you suggested but I am having trouble building DeepVariant. After executing build-prereq.sh I get multiple error and warning messages regarding pip dependencies. `========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [jue 18 ago 2022 14:10:53 CEST] Stage 'Misc setup' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:00 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:03 CEST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:05 CEST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2500k 100 2500k 0 0 21.8M 0 --:--:-- --:--:-- --:--:-- 21.8M. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:2995,usability,prefer,prefer,2995,". WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3129,usability,user,user,3129,"(/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3183,usability,behavi,behaviour,3183,"ng invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pip. Using cached pip-22.2.2-py3-none-any.whl (2.0 MB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pip. Attempting uninstall: pip. Found existing installation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3757,usability,ERROR,ERROR,3757,"allation: pip 22.2.2. Uninstalling pip-22.2.2:. Successfully uninstalled pip-22.2.2. WARNING: The scripts pip, pip3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:3869,usability,behavi,behaviour,3869,"3 and pip3.8 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-22.2.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4254,usability,ERROR,ERROR,4254,"ual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into ac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4366,usability,behavi,behaviour,4366,"local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Python 3.8.10. pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). ========== [jue 18 ago 2022 14:11:12 CEST] Stage 'Install python3 packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4770,usability,ERROR,ERROR,4770,"endency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:4882,usability,behavi,behaviour,4882,"ource of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5193,usability,ERROR,ERROR,5193,"15.0, but you have protobuf 3.13.0 which is incompatible. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:5305,usability,behavi,behaviour,5305," into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.5 which is incompatible. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:43 CEST] Stage 'Install TensorFlow pip package' starting. Installing Intel's CPU-only MKL TensorFlow 2.7.0 wheel. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install CUDA' starting. ========== [jue 18 ago 2022 14:11:45 CEST] Stage 'Install other packages' starting. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. pyclif 0.4 requires pyparsing==2.2.0, but you have pyparsing 3.0.9 which is incompatible. googleapis-common-protos 1.56.4 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. google-api-core 2.8.2 requires protobuf<5.0.0dev,>=3.15.0, but you have protobuf 3.13.0 which is incompatible. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'run-prereq.sh complete' starting. ========== [jue 18 ago 2022 14:11:49 CEST] Stage 'Update package list' starting. W: Fallo al obtener http://dl.bintray.com/basespace/BaseMount-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: Fallo al obtener http://dl.bintray.com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7018,usability,support,support,7018,".com/basespace/BaseSpaceFS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7042,usability,support,support,7042,"FS-DEB/dists/saucy/InRelease Fall la conexin [IP: 18.194.81.109 80]. W: No se han podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7124,usability,support,support,7124,"n podido descargar algunos archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7148,usability,support,support,7148,"os archivos de ndice, se han omitido, o se han utilizado unos antiguos en su lugar. ========== [jue 18 ago 2022 14:11:52 CEST] Stage 'build-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install bazel' starting. WARNING: Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE defaul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7448,usability,interact,interactively,7448," Value of --bazelrc is ignored, since --ignore_all_rc_files is on. Bazel 3.7.2 already installed on the machine, not reinstalling. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Install CLIF binary' starting. CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7663,usability,command,command,7663,"CLIF already installed. ========== [jue 18 ago 2022 14:11:53 CEST] Stage 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7735,usability,support,support,7735," 'Download and configure TensorFlow sources' starting. M	tensorflow/core/kernels/mlir_generated/build_defs.bzl. HEAD est ahora en c256c071bb2 Merge pull request #52891 from tensorflow/mm-update-relnotes. You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:7940,usability,support,support,7940,"You have bazel 3.7.2 installed. Do you wish to build TensorFlow with ROCm support? [y/N]: No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: No CUDA support will be enabled for TensorFlow. Do you wish to download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8199,usability,support,support,8199,"download a fresh release of clang? (Experimental) [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:8248,usability,support,support,8248," [y/N]: Clang will not be downloaded. Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]: . Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details. 	--config=mkl 	# Build with MKL support. 	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	--config=monolithic 	# Config for mostly static monolithic build. 	--config=numa 	# Build with NUMA support. 	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects. 	--config=v1 	# Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9057,usability,user,user,9057,ith TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/d,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:9111,usability,behavi,behaviour,9111,azel build configs to DISABLE default on features:. 	--config=nogcp 	# Disable GCP support. 	--config=nonccl 	# Disable NVIDIA NCCL support. Configuration finished. ========== [jue 18 ago 2022 14:11:54 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 3.0.9. Uninstalling pyparsing-3.0.9:. Successfully uninstalled pyparsing-3.0.9. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yp,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10248,usability,ERROR,ERROR,10248,"pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10360,usability,behavi,behaviour,10360,"-parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/di",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10652,usability,user,user,10652,"3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ig",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:10706,usability,behavi,behaviour,10706,"ution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11880,usability,user,user,11880,rsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/d,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:11934,usability,behavi,behaviour,11934,Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:55 CEST] Stage 'Set pyparsing to 2.2.0 for CLIF.' starting. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Found existing installation: pyparsing 2.2.0. Uninstalling pyparsing-2.2.0:. Successfully uninstalled pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yp,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13071,usability,ERROR,ERROR,13071,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13183,usability,behavi,behaviour,13183,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13475,usability,user,user,13475,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:13529,usability,behavi,behaviour,13529,"environment instead: https://pip.pypa.io/warnings/venv. Using pip 22.2.2 from /root/.local/lib/python3.8/site-packages/pip (python 3.8). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Collecting pyparsing==2.2.0. Using cached pyparsing-2.2.0-py2.py3-none-any.whl (56 kB). WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). Installing collected packages: pyparsing. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. httplib2 0.20.4 requires pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2; python_version > ""3.0"", but you have pyparsing 2.2.0 which is incompatible. Successfully installed pyparsing-2.2.0. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. WARNING: Ignoring invalid distribution -parsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution -yparsing (/usr/local/lib/python3.8/dist-packages). WARNING: Ignoring invalid distribution - (/usr/local/lib/python3.8/dist-packages). ========== [jue 18 ago 2022 14:11:58 CEST] Stage 'build-prereq.sh complete' starting`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:61,availability,avail,available,61,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:80,energy efficiency,CPU,CPUs,80,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:241,energy efficiency,Cloud,Cloud,241,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:80,performance,CPU,CPUs,80,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:61,reliability,availab,available,61,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:61,safety,avail,available,61,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/552:61,security,availab,available,61,@Argonvi What hardware do you have? SSE4.1 instructions were available on Intel CPUs since 2009 (https://en.wikipedia.org/wiki/SSE4). If you have a very old hardware it might not be possible compile DeepVariant. Could you try to run it on a Cloud virtual machine?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/552
https://github.com/google/deepvariant/issues/554:112,availability,avail,available,112,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:31,energy efficiency,model,model,31,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:80,energy efficiency,current,currently,80,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:101,energy efficiency,model,model,101,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:51,modifiability,Pac,PacBio,51,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:112,reliability,availab,available,112,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:112,safety,avail,available,112,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:31,security,model,model,31,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:101,security,model,model,101,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:112,security,availab,available,112,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/554:127,usability,support,supports,127,"hello @imdanique ,. The hybrid model is trained on PacBio HiFi + Illumina data, currently there's no model/mode available that supports ONT+Illumina data in the manner this hybrid mode is used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/554
https://github.com/google/deepvariant/issues/555:421,availability,error,error,421,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:148,deployability,version,version,148,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:368,deployability,instal,install,368,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:391,deployability,version,version,391,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:275,energy efficiency,gpu,gpu,275,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:148,integrability,version,version,148,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:391,integrability,version,version,391,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:148,modifiability,version,version,148,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:391,modifiability,version,version,391,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:275,performance,gpu,gpu,275,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:421,performance,error,error,421,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:19,reliability,doe,does,19,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:421,safety,error,error,421,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:421,usability,error,error,421,"Hi @tahashmi ,. It does look like a TensorFlow issue as described here: https://github.com/tensorflow/text/issues/385. You can check the tensorflow version of DeepVariant this way:. ```bash. singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3 -c 'import tensorflow as tf; print(tf.__version__)'. ```. And then please try to install the tensorflow version locally to see if the error gets fixed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:103,deployability,contain,container,103,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:653,deployability,modul,module,653,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:755,deployability,modul,module,755,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:229,energy efficiency,gpu,gpu,229,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:1052,energy efficiency,core,core,1052,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:499,interoperability,platform,platform,499,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:1419,interoperability,platform,platform,1419,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:653,modifiability,modul,module,653,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:707,modifiability,pac,packages,707,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:755,modifiability,modul,module,755,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:838,modifiability,pac,packages,838,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:1032,modifiability,pac,packages,1032,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:229,performance,gpu,gpu,229,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:254,performance,cach,cached,254,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:653,safety,modul,module,653,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:755,safety,modul,module,755,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:589,testability,Trace,Traceback,589,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:348,usability,help,help,348,"Thanks @kishwarshafin . . But I think I am not even able to import TF in Python environment through DV container. . ```. (base) [tahmad@gcn4 ~]$ singularity run --nv -B /usr/lib/locale/ docker://google/deepvariant:${BIN_VERSION}-gpu python3. INFO: Using cached SIF image. Python 3.8.10 (default, Mar 15 2022, 12:22:08). [GCC 9.4.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import tensorflow as tf. 2022-08-28 09:48:47.608744: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/__init__.py"", line 444, in <module>. _ll.load_library(_main_dir). File ""/home/tahmad/.local/lib/python3.8/site-packages/tensorflow/python/framework/load_library.py"", line 154, in load_library. py_tf.TF_LoadLibrary(lib). tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow14kernel_factory17OpKernelRegistrar12InitInternalEPKNS_9KernelDefEN4absl12lts_2021032411string_viewESt10unique_ptrINS0_15OpKernelFactoryESt14default_deleteIS9_EE. ```. on my local system, I have TF 2.5.2. ```. >>> import tensorflow as tf. 2022-08-28 09:51:55.901400: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0. >>> print(tf.__version__). 2.5.2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:52,deployability,updat,updating,52,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:102,deployability,contain,container,102,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:118,deployability,instal,install,118,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:8,performance,time,time,8,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:52,safety,updat,updating,52,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/555:52,security,updat,updating,52,"For the time being, this issue has been resolved by updating my local TF to 2.7.0 which is used in DV container. `pip install -U tensorflow==2.7.0`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/555
https://github.com/google/deepvariant/issues/556:124,performance,parallel,parallelization,124,"@dennishendriksen ,. Sorry, I want to make sure that I understand you question correctly. Are you trying to set up your own parallelization scheme or you are having this issue with the scheme we have already set up for DeepVariant?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:55,testability,understand,understand,55,"@dennishendriksen ,. Sorry, I want to make sure that I understand you question correctly. Are you trying to set up your own parallelization scheme or you are having this issue with the scheme we have already set up for DeepVariant?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:89,availability,cluster,cluster,89,"hello @kishwarshafin, thank you for your quick reply. I'm trying to run DeepVariant on a cluster of compute nodes and in order to benefit from that I indeed parallelize the work on the different nodes by using the `--regions` command-line argument of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:89,deployability,cluster,cluster,89,"hello @kishwarshafin, thank you for your quick reply. I'm trying to run DeepVariant on a cluster of compute nodes and in order to benefit from that I indeed parallelize the work on the different nodes by using the `--regions` command-line argument of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:157,performance,parallel,parallelize,157,"hello @kishwarshafin, thank you for your quick reply. I'm trying to run DeepVariant on a cluster of compute nodes and in order to benefit from that I indeed parallelize the work on the different nodes by using the `--regions` command-line argument of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:226,security,command-lin,command-line,226,"hello @kishwarshafin, thank you for your quick reply. I'm trying to run DeepVariant on a cluster of compute nodes and in order to benefit from that I indeed parallelize the work on the different nodes by using the `--regions` command-line argument of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:226,usability,command,command-line,226,"hello @kishwarshafin, thank you for your quick reply. I'm trying to run DeepVariant on a cluster of compute nodes and in order to benefit from that I indeed parallelize the work on the different nodes by using the `--regions` command-line argument of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:120,interoperability,specif,specification,120,"@dennishendriksen ,. You can possibly achieve this by converting your regions from string to a bed file. Please see the specification of the regions parameter:. `--regions`: Optional. Space-separated list of regions we want to process. . Elements can be region literals (e.g., chr20:10-20) or **paths to BED/BEDPE files.**. (default: '').",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/556:149,modifiability,paramet,parameter,149,"@dennishendriksen ,. You can possibly achieve this by converting your regions from string to a bed file. Please see the specification of the regions parameter:. `--regions`: Optional. Space-separated list of regions we want to process. . Elements can be region literals (e.g., chr20:10-20) or **paths to BED/BEDPE files.**. (default: '').",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/556
https://github.com/google/deepvariant/issues/557:660,availability,sli,slightly,660,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:890,availability,operat,operation,890,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:67,deployability,releas,release,67,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:145,deployability,pipelin,pipeline,145,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:109,energy efficiency,reduc,reduce,109,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:332,energy efficiency,reduc,reduce,332,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1024,energy efficiency,model,model,1024,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1095,energy efficiency,model,model,1095,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:145,integrability,pipelin,pipeline,145,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:158,modifiability,Pac,PacBio,158,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:532,performance,time,time,532,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:869,performance,perform,performs,869,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1113,performance,perform,performance,1113,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:660,reliability,sli,slightly,660,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:60,safety,except,except,60,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1024,security,model,model,1024,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1095,security,model,model,1095,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:132,testability,simpl,simplify,132,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:32,usability,document,documentation,32,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:132,usability,simpl,simplify,132,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:869,usability,perform,performs,869,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:1113,usability,perform,performance,1113,"Unfortunately we don't have any documentation on the method except release notes. The main motivation was to reduce the runtime and simplify the pipeline for PacBio data. The phasing is generated from DeepVariant proposed candidates. Proposed candidates are generated by counting alleles at each position and applying heuristics to reduce the number of proposed candidates. The main differences between one-step phasing and WhatsHap are:. * One-step phasing uses a greedy algorithm that processes intervals of 25000 bases long at a time. Using a greedy algorithm makes it inferior to WhatsHap. Although, experiments showed that final DeepVariant accuracy only slightly suffers. * Another big difference is that one-step phasing uses ""noisy"" proposed candidates when WhatsHap is run on genotyped variants produced by running DeepVariant on unphased data. The code which performs the phasing operation is in https://github.com/google/deepvariant/blob/r1.4/deepvariant/direct_phasing.cc. . Please note that our the DeepVariant model in v1.4 is able to run on candidates phased by WhatsHap, and the model has similar performance. This can be done by adding flags to the step of make_examples if run separately. If it is of interest for you to run DeepVariant v1.4 using the WhatsHap flags instead of the direct phasing, we can provide you with instructions to do so.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:23,usability,help,helpful,23,"Thank you, that's very helpful! That's just the sort of information I was looking for. It might be beneficial for other users to add that info to the docs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/557:120,usability,user,users,120,"Thank you, that's very helpful! That's just the sort of information I was looking for. It might be beneficial for other users to add that info to the docs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/557
https://github.com/google/deepvariant/issues/558:235,energy efficiency,core,cores,235,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:299,energy efficiency,CPU,CPU,299,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:303,energy efficiency,core,cores,303,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:178,modifiability,PAC,PACBIO,178,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:299,performance,CPU,CPU,299,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/558:50,usability,command,commands,50,"@MjelleLab ,. Please remove the comments from the commands. These are the comments that should be removed:. ```. **Replace this string with exactly one of the following [WGS,WES,PACBIO,HYBRID_PACBIO_ILLUMINA]**. **Optional. **How many cores the `make_examples` step uses. Change it to the number of CPU cores you have.**. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/558
https://github.com/google/deepvariant/issues/559:114,deployability,version,version,114,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:126,deployability,instal,installed,126,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:167,deployability,instal,installing,167,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:240,deployability,instal,install,240,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:288,deployability,instal,install,288,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:114,integrability,version,version,114,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:114,modifiability,version,version,114,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/559:298,usability,user,user,298,"@tahashmi,. It looks like [nucleus](https://github.com/google/nucleus) is having issues with the newer tensorflow version you installed. I'm not exactly sure why your installing tensorflow locally fixed the issue. Can you please see if you install nucleus locally, it fixes it:. ```. pip install --user google-nucleus. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/559
https://github.com/google/deepvariant/issues/560:171,integrability,Filter,Filtering,171,"@rickymagner ,. Can you please fetch one line of such VCF record? I think the issue is upstream of DeepVariant and it's happening because PEPPER allows non A/C/G/T bases. Filtering needs to happen upstream.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/560
https://github.com/google/deepvariant/issues/560:176,integrability,filter,filter,176,"@rickymagner ,. In this case the candidates are generated by PEPPER, so this call is happening because PEPPER picked this as a candidate. One quick fix on your end would be to filter the VCF for 'PASS' variants only as DeepVariant would assign RefCall to all of these candidates.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/560
https://github.com/google/deepvariant/issues/561:119,energy efficiency,model,model-case-study,119,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:112,modifiability,pac,pacbio-model-case-study,112,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:119,security,model,model-case-study,119,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:216,testability,simpl,simply,216,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:216,usability,simpl,simply,216,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:237,usability,command,commands,237,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/561:303,usability,command,commands,303,"@aalfi ,. Please follow the instructions here: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md. I see that you have `--dry_run=true` which would not run anything and would simply print out the commands:. ```. --[no]dry_run: Optional. If True, only prints out commands without executing them. (default: 'false'). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/561
https://github.com/google/deepvariant/issues/562:407,interoperability,specif,specification,407,"Hi @RaphaelSanchesUSP . It will likely be very difficult to do so regardless of the approach. However, I'd like to better understand what sort of output you would look for? Would it be to extend DeepVariant's output classes beyond REF, HET, HOM into more than diploid output, or is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:188,modifiability,exten,extend,188,"Hi @RaphaelSanchesUSP . It will likely be very difficult to do so regardless of the approach. However, I'd like to better understand what sort of output you would look for? Would it be to extend DeepVariant's output classes beyond REF, HET, HOM into more than diploid output, or is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:122,testability,understand,understand,122,"Hi @RaphaelSanchesUSP . It will likely be very difficult to do so regardless of the approach. However, I'd like to better understand what sort of output you would look for? Would it be to extend DeepVariant's output classes beyond REF, HET, HOM into more than diploid output, or is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:253,energy efficiency,predict,predictions,253,"Hi @AndrewCarroll . Thank you very much for your promptness and attention. I verified that DeepVariant has in several parts of the code, parameters for diploid organisms and two alleles. Like the small example function below:. `def most_likely_genotype(predictions, ploidy=2, n_alleles=2):`. The mentioned function is used in the post-processing process of calling variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:137,modifiability,paramet,parameters,137,"Hi @AndrewCarroll . Thank you very much for your promptness and attention. I verified that DeepVariant has in several parts of the code, parameters for diploid organisms and two alleles. Like the small example function below:. `def most_likely_genotype(predictions, ploidy=2, n_alleles=2):`. The mentioned function is used in the post-processing process of calling variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:253,safety,predict,predictions,253,"Hi @AndrewCarroll . Thank you very much for your promptness and attention. I verified that DeepVariant has in several parts of the code, parameters for diploid organisms and two alleles. Like the small example function below:. `def most_likely_genotype(predictions, ploidy=2, n_alleles=2):`. The mentioned function is used in the post-processing process of calling variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:77,testability,verif,verified,77,"Hi @AndrewCarroll . Thank you very much for your promptness and attention. I verified that DeepVariant has in several parts of the code, parameters for diploid organisms and two alleles. Like the small example function below:. `def most_likely_genotype(predictions, ploidy=2, n_alleles=2):`. The mentioned function is used in the post-processing process of calling variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:248,integrability,pub,publications,248,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:40,interoperability,specif,specific,40,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:212,interoperability,specif,specification,212,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:327,security,ident,identified,327,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:437,security,modif,modifications,437,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:294,usability,tool,tools,294,"Hi @AndrewCarroll . The most likely and specific choice would be the following:. _**is it instead to train on polyploid species and repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?**_. I analyzed some publications comparing DeepVariant with other tools in terms of results, but I identified some flaws in the DeepVariant's execution in these comparisons on human data. My reference for the modifications follows below:. [Reference](https://genome.sph.umich.edu/wiki/Relationship_between_Ploidy,_Alleles_and_Genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:565,availability,error,error,565,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:309,integrability,compon,component,309,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:141,interoperability,specif,specification,141,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:309,interoperability,compon,component,309,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:309,modifiability,compon,component,309,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:565,performance,error,error,565,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:565,safety,error,error,565,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:378,security,ident,identify,378,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/562:565,usability,error,error,565,"Hi @RaphaelSanchesUSP . Between the two approaches, this - **repurpose HET to be (some number of non-ref and non-hom alleles without further specification)?** is the one which would require much less work. Of the approaches, this might not require large changes and might be possible with training alone. One component that could be limiting for this approach is the ability to identify extremely well characterized samples that could be used as truth examples. Is there a polyploid species where the variants relative to the reference are known without almost any error, as is the case for the genome in a bottle samples for humans?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/562
https://github.com/google/deepvariant/issues/563:98,energy efficiency,model,model,98,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:215,energy efficiency,model,models,215,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:314,energy efficiency,model,model,314,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:396,energy efficiency,model,model,396,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:48,safety,input,input,48,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:83,safety,input,input,83,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:98,security,model,model,98,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:215,security,model,models,215,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:314,security,model,model,314,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:396,security,model,model,396,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:48,usability,input,input,48,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:83,usability,input,input,83,"Hi @JosephLalli . The number of channels in the input establishes the shape of the input. A given model also has a shape based on the channels that it expects to see. In v1.4, we added a new channel for WGS and WES models to represent the insert size between read pairs. This occupies the 7th channel. Our default model for v1.4 expects that channel to be there. If you want to run with the v1.4 model, you will have to use the v1.4 Docker image to make the examples. Is there a reason this would be a problem?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/563:18,usability,close,close,18,"@JosephLalli I'll close this issue because we haven't heard back from you. Please feel free to reopen , or open another issue as needed. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/563
https://github.com/google/deepvariant/issues/564:292,usability,user,user-images,292,> @yangyxt how large is the bam file you are working with? Is it possible to connect to the singularity image while it is running and run `samtools quickcheck -v`? Thank you for the response and sorry for late notice. . I tried and the samtools quickcheck returned success:. ![image](https://user-images.githubusercontent.com/40780228/190949628-5cd5e0c4-4ab1-4b97-a808-d8875cb7ed77.png).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:281,testability,understand,understand,281,"> @yangyxt how large is the bam file you are working with? Is it possible to connect to the singularity image while it is running and run `samtools quickcheck -v`? I found a thread in tensorflow github page, starting from 2017, lasting to 2021. I havent used tensorflow so I can't understand the thread. For your information only: https://github.com/tensorflow/tensorflow/issues/13463",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:46,availability,error,error,46,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:52,integrability,messag,message,52,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:52,interoperability,messag,message,52,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:46,performance,error,error,46,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:46,safety,error,error,46,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:85,safety,input,input,85,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:46,usability,error,error,46,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:85,usability,input,input,85,"@yangyxt was this resolved? From the original error message, it seems to me that the input to call_variants was truncated. Which means that your make_examples run might have not been fully succeeded. Another possible issue is: If you happen to have multiple make_examples running and overwriting the same files, you also might have corrupted output from make_examples (which will cause the call_variants step to err out.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:261,availability,operat,operations,261,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:890,deployability,contain,contain,890,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:903,deployability,contain,container,903,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:76,performance,parallel,parallel,76,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:124,performance,parallel,parallel,124,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:244,performance,parallel,parallel,244,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:142,safety,input,input,142,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:142,usability,input,input,142,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:440,usability,command,command,440,"> . @pichuan Thanks for the response. I haven't resolved this. I do use GNU parallel to run 3 deep-variant docker images in parallel. But the input/output files for each process are different from each other. The only common directory that has parallel writing operations under it is the $TMPDIR or $SINGULARITY_CACHEDIR. Should I make the TMPDIR/SINGULARITY_CACHEDIR unique for each singularity run? . Here I show the original singularity command:. `export SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"". singularity run \. -B ""/paedyl01/disk1/yangyxt,/usr/lib/locale"" \. --env LANG=""en_US.UTF-8"" \. --env LC_ALL=""C"" \. --env LANGUAGE=""en_US.UTF-8"" \. --env LC_CTYPE=""UTF-8"" \. --env TMPDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --env SINGULARITY_CACHEDIR=""/paedyl01/disk1/yangyxt/test_tmp"" \. --home ""/paedyl01/disk1/yangyxt/home:/home"" \. --workdir /paedyl01/disk1/yangyxt \. --contain \. ${container} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${model_type} \. --ref=""${ref_genome}"" \. --reads=""${bam_file}"" \. ${region_arg} \. --output_vcf=""${output_vcf}"" \. --output_gvcf=""${output_gvcf}"" \. --intermediate_results_dir ""/paedyl01/disk1/yangyxt/test_tmp"" \. --num_shards=${threads}",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:94,performance,time,times,94,"I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:62,usability,command,command,62,"I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:96,performance,time,times,96,"> I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted. Thank you. I will try and feedback to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:64,usability,command,command,64,"> I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted. Thank you. I will try and feedback to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/564:342,usability,feedback,feedback,342,"> I'm not very familiar with SINGULARITY_CACHEDIR. But, in your command, if you're running it 3 times, you should use a different --intermediate_results_dir. Output of `make_examples` will be written to that directory. So, if you use the same intermediate_results_dir, that might explain why your data is corrupted. Thank you. I will try and feedback to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/564
https://github.com/google/deepvariant/issues/565:61,performance,content,content,61,"Hi @SHuang-Broad . By default, DeepVariant only looks at the content of the QUAL field (column 11) in order to populate the quality values. DeepVariant is able to look at and read in arbitrary additional tags (e.g. we have used the HP tag for phasing in the past). We have not previously experimented with BAQ, but with the framework above it would not be hard to look at it if you have an intuition that it might help. If you think it is promising, we could either do this investigation ourselves, or we could try to give you some instructions on how to do an experimental training if you are interested. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:390,usability,intuit,intuition,390,"Hi @SHuang-Broad . By default, DeepVariant only looks at the content of the QUAL field (column 11) in order to populate the quality values. DeepVariant is able to look at and read in arbitrary additional tags (e.g. we have used the HP tag for phasing in the past). We have not previously experimented with BAQ, but with the framework above it would not be hard to look at it if you have an intuition that it might help. If you think it is promising, we could either do this investigation ourselves, or we could try to give you some instructions on how to do an experimental training if you are interested. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:414,usability,help,help,414,"Hi @SHuang-Broad . By default, DeepVariant only looks at the content of the QUAL field (column 11) in order to populate the quality values. DeepVariant is able to look at and read in arbitrary additional tags (e.g. we have used the HP tag for phasing in the past). We have not previously experimented with BAQ, but with the framework above it would not be hard to look at it if you have an intuition that it might help. If you think it is promising, we could either do this investigation ourselves, or we could try to give you some instructions on how to do an experimental training if you are interested. Thanks,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:85,interoperability,standard,standard,85,"@SHuang-Broad - Which read aligner populates the BAQ values for HiFi reads? With the standard PacBio tools, there is a PacBio `bq:i` tag output by `lima` demuliplexing that stores the quality of a barcode call. But, `BQ:Z` is not a standard output for `pbmm2`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:232,interoperability,standard,standard,232,"@SHuang-Broad - Which read aligner populates the BAQ values for HiFi reads? With the standard PacBio tools, there is a PacBio `bq:i` tag output by `lima` demuliplexing that stores the quality of a barcode call. But, `BQ:Z` is not a standard output for `pbmm2`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:94,modifiability,Pac,PacBio,94,"@SHuang-Broad - Which read aligner populates the BAQ values for HiFi reads? With the standard PacBio tools, there is a PacBio `bq:i` tag output by `lima` demuliplexing that stores the quality of a barcode call. But, `BQ:Z` is not a standard output for `pbmm2`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:119,modifiability,Pac,PacBio,119,"@SHuang-Broad - Which read aligner populates the BAQ values for HiFi reads? With the standard PacBio tools, there is a PacBio `bq:i` tag output by `lima` demuliplexing that stores the quality of a barcode call. But, `BQ:Z` is not a standard output for `pbmm2`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:101,usability,tool,tools,101,"@SHuang-Broad - Which read aligner populates the BAQ values for HiFi reads? With the standard PacBio tools, there is a PacBio `bq:i` tag output by `lima` demuliplexing that stores the quality of a barcode call. But, `BQ:Z` is not a standard output for `pbmm2`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:77,availability,operat,operations,77,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:192,deployability,pipelin,pipeline,192,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:393,deployability,pipelin,pipeline,393,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:192,integrability,pipelin,pipeline,192,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:393,integrability,pipelin,pipeline,393,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:60,performance,time,time,60,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:202,reliability,doe,doesn,202,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:143,usability,help,helpful,143,"@AndrewCarroll . Thanks for the answer. We're in a bit of a time crunch now (operations), but knowing how to run that experiment will be super helpful! @amwenger . Right, `pbmm2` (used in our pipeline) doesn't provide the `BQ:Z` tag. However, we also run `samtools calmd` on the BAM to generate the `MD:Z` tag. And `calmd` allows one to compute the BAQ by turning on the `-r` flag (off in our pipeline now). But as you can imagine, it will not be negligible compute. Hence we are interested in doing some experiments to see if DV can benefit from this tag. Steve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:388,energy efficiency,current,currently,388,"Hi @SHuang-Broad . I would like to conduct some experiments myself to investigate whether this field might help. Unfortunately, with many things going on those experiments might take some time to conclude. You mentioned you are in a time crunch. Given the uncertainty of whether this might help, I would recommend that if you need to proceed, you do so without the BAQ field (as we don't currently make use of it anyway). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:188,performance,time,time,188,"Hi @SHuang-Broad . I would like to conduct some experiments myself to investigate whether this field might help. Unfortunately, with many things going on those experiments might take some time to conclude. You mentioned you are in a time crunch. Given the uncertainty of whether this might help, I would recommend that if you need to proceed, you do so without the BAQ field (as we don't currently make use of it anyway). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:233,performance,time,time,233,"Hi @SHuang-Broad . I would like to conduct some experiments myself to investigate whether this field might help. Unfortunately, with many things going on those experiments might take some time to conclude. You mentioned you are in a time crunch. Given the uncertainty of whether this might help, I would recommend that if you need to proceed, you do so without the BAQ field (as we don't currently make use of it anyway). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:107,usability,help,help,107,"Hi @SHuang-Broad . I would like to conduct some experiments myself to investigate whether this field might help. Unfortunately, with many things going on those experiments might take some time to conclude. You mentioned you are in a time crunch. Given the uncertainty of whether this might help, I would recommend that if you need to proceed, you do so without the BAQ field (as we don't currently make use of it anyway). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:290,usability,help,help,290,"Hi @SHuang-Broad . I would like to conduct some experiments myself to investigate whether this field might help. Unfortunately, with many things going on those experiments might take some time to conclude. You mentioned you are in a time crunch. Given the uncertainty of whether this might help, I would recommend that if you need to proceed, you do so without the BAQ field (as we don't currently make use of it anyway). .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/565:121,usability,close,close,121,"Hi @SHuang-Broad ,. this issue has been around for a while. If you'd like to follow up, please let us know! For now I'll close it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/565
https://github.com/google/deepvariant/issues/566:29,usability,command,command,29,"Hi @yangyxt ,. can you try a command like:. https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:251,deployability,log,logs,251,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:392,integrability,messag,messages,392,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:392,interoperability,messag,messages,392,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:332,modifiability,variab,variable,332,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:251,safety,log,logs,251,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:251,security,log,logs,251,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:251,testability,log,logs,251,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:30,usability,command,command,30,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:182,usability,command,command,182,"> Hi @yangyxt , can you try a command like: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-quick-start.md#notes-on-singularity ? Thanks for the response. I tried a command without --env argument in the very beginning and the warning logs were still what is in the screenshot above. Then I started to alter the env variable with --env argument and still got the same warning messages.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:93,usability,confirm,confirm,93,"If i recall correctly, there might be warnings but it didn't seem to affect the run. Can you confirm whether you're actually getting unexpected results or not? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:288,deployability,depend,dependency,288,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:59,integrability,messag,messages,59,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:113,integrability,messag,message,113,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:221,integrability,messag,message,221,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:288,integrability,depend,dependency,288,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:59,interoperability,messag,messages,59,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:113,interoperability,messag,message,113,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:221,interoperability,messag,message,221,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:288,modifiability,depend,dependency,288,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:288,safety,depend,dependency,288,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:288,testability,depend,dependency,288,"> . Yes. I didn't get unexpected results when only warning messages are shown. I just wonder whether the warning message would affect the results in some hidden way that I'm not aware of. So I tried to remove the warning message and ended up finding out it's somehow due to the lack of a dependency, locale, in the docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:92,integrability,messag,messages,92,Thanks @yangyxt . Good to know that you're not seeing strange behaviors despite the warning messages. I'll close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:92,interoperability,messag,messages,92,Thanks @yangyxt . Good to know that you're not seeing strange behaviors despite the warning messages. I'll close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:62,usability,behavi,behaviors,62,Thanks @yangyxt . Good to know that you're not seeing strange behaviors despite the warning messages. I'll close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/566:107,usability,close,close,107,Thanks @yangyxt . Good to know that you're not seeing strange behaviors despite the warning messages. I'll close this issue now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/566
https://github.com/google/deepvariant/issues/567:21,energy efficiency,model,models,21,"Hi @Suke-fudan . The models used for WES and PACBIO are two different models (and different flags are used as well). You'll need to rerun, otherwise you won't get good accuracy. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:70,energy efficiency,model,models,70,"Hi @Suke-fudan . The models used for WES and PACBIO are two different models (and different flags are used as well). You'll need to rerun, otherwise you won't get good accuracy. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:45,modifiability,PAC,PACBIO,45,"Hi @Suke-fudan . The models used for WES and PACBIO are two different models (and different flags are used as well). You'll need to rerun, otherwise you won't get good accuracy. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:21,security,model,models,21,"Hi @Suke-fudan . The models used for WES and PACBIO are two different models (and different flags are used as well). You'll need to rerun, otherwise you won't get good accuracy. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/567:70,security,model,models,70,"Hi @Suke-fudan . The models used for WES and PACBIO are two different models (and different flags are used as well). You'll need to rerun, otherwise you won't get good accuracy. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/567
https://github.com/google/deepvariant/issues/568:594,deployability,updat,update-if-youre-using-our-,594,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:807,deployability,updat,update,807,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:50,energy efficiency,model,model,50,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:184,energy efficiency,frequenc,frequency,184,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:194,energy efficiency,model,model,194,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:243,energy efficiency,model,model,243,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:363,energy efficiency,model,model,363,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:649,energy efficiency,current,currently,649,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:681,energy efficiency,model,model,681,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:510,integrability,pub,public,510,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:782,performance,tune,tuned,782,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:594,safety,updat,update-if-youre-using-our-,594,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:807,safety,updat,update,807,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:50,security,model,model,50,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:194,security,model,model,194,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:243,security,model,model,243,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:363,security,model,model,363,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:594,security,updat,update-if-youre-using-our-,594,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:681,security,model,model,681,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:807,security,updat,update,807,"Hi @jkalleberg ,. Thank you for reaching out. The model ckpt you're using was older than v1.4. And you're right: in v1.4 we added an extra channel, and we haven't trained a new allele frequency model with v1.4. So we actually don't yet have a model that has both insert_size as well allele_frequency! Two things:. 1. If you want to run v1.4.0 code with the older model (which didn't have the insert_size channel), you can add `,channels=''` to the end of your make_examples_extra_args. I added a section to my public gist here:. https://gist.github.com/pichuan/64d73bc965300645470eb29a66116593#update-if-youre-using-our-v140-docker-codebase. 2. I'm currently training a new WGS AF model that will have both the insert_size channel, as well as the allele_frequency channel. So, stay tuned! I can give you an update when I have it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:788,availability,error,error,788,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:128,deployability,updat,update,128,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:214,deployability,build,building,214,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:246,deployability,contain,containing,246,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:225,energy efficiency,model,model,225,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:788,performance,error,error,788,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:128,safety,updat,update,128,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:788,safety,error,error,788,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:128,security,updat,update,128,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:225,security,model,model,225,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:159,testability,understand,understand,159,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:438,testability,understand,understand,438,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:54,usability,tip,tip,54,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:556,usability,command,command,556,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:788,usability,error,error,788,"@pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? . I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:497,availability,consist,consistent,497,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1173,availability,error,error,1173,"d correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1516,availability,error,errors,1516,"del.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1622,availability,checkpoint,checkpoint,1622,"and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequenc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1655,availability,checkpoint,checkpoint,1655,"erent examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size cha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2314,availability,error,error,2314,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:130,deployability,updat,update,130,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:222,deployability,build,building,222,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:254,deployability,contain,containing,254,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:453,deployability,stage,stage,453,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1806,deployability,depend,depends,1806,"'m trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2063,deployability,version,version,2063,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:233,energy efficiency,model,model,233,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:517,energy efficiency,model,model,517,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:563,energy efficiency,model,model,563,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1459,energy efficiency,model,model,1459,"l need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1760,energy efficiency,model,model,1760,"made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1848,energy efficiency,model,model,1848,"nnels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-ch",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1901,energy efficiency,model,model,1901,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1957,energy efficiency,model,models,1957,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2031,energy efficiency,model,model,2031,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2351,energy efficiency,model,model,2351,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2373,energy efficiency,model,model,2373,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2419,energy efficiency,model,model,2419,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2482,energy efficiency,current,current,2482,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1806,integrability,depend,depends,1806,"'m trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2063,integrability,version,version,2063,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:601,interoperability,specif,specific,601,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1535,interoperability,share,shared,1535,"ll_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1806,modifiability,depend,depends,1806,"'m trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2063,modifiability,version,version,2063,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1173,performance,error,error,1173,"d correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1516,performance,error,errors,1516,"del.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2314,performance,error,error,2314,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1622,reliability,checkpoint,checkpoint,1622,"and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequenc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1655,reliability,checkpoint,checkpoint,1655,"erent examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size cha",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2666,reliability,Doe,Does,2666,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:130,safety,updat,update,130,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1173,safety,error,error,1173,"d correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1516,safety,error,errors,1516,"del.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1806,safety,depend,depends,1806,"'m trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2314,safety,error,error,2314,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:130,security,updat,update,130,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:233,security,model,model,233,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:517,security,model,model,517,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:563,security,model,model,563,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1459,security,model,model,1459,"l need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1760,security,model,model,1760,"made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1848,security,model,model,1848,"nnels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-ch",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1901,security,model,model,1901,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1957,security,model,models,1957,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2031,security,model,model,2031,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2351,security,model,model,2351,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2373,security,model,model,2373,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2419,security,model,model,2419,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:167,testability,understand,understand,167,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:823,testability,understand,understand,823,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1806,testability,depend,depends,1806,"'m trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:56,usability,tip,tip,56,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:497,usability,consist,consistent,497,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:941,usability,command,command,941,"> @pichuan Thank you for the quick reply. That's a good tip to bypass the insert_size channel by default. Looking forward to your update, much appreciated. > . > If I understand correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-incept",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1173,usability,error,error,1173,"d correctly, each additional channel requires building a model using examples containing those channels. As a hypothetical example, to use `insert_size` + `allele_frequency` + `avg_base_quality` during variant calling would require re-training, correct? Yes. The make_examples stage will need to create examples that are consistent with the model.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1516,usability,error,errors,1516,"del.ckpt used in call_variants. Because the model.ckpt was already trained with a specific list of channels and shape. So, if you create different examples - even if it's just to remove a channel, you're suppose to retrain on examples that are made with that channel removed as well. > . > I'm trying to understand if additional channels are mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2314,usability,error,error,2314,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2490,usability,behavi,behavior,2490,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:2842,usability,custom,custom-channels,2842,"re mutually exclusive choices for the 7th channel when using the `run_deepvariant` command. My first attempt at running with both `insert_size` + `allele_frequency` seemed to work. However, it produced examples with channels `[1, 2, 3, 4, 5, 6, 19]` instead of `[1, 2, 3, 4, 5, 6, 8, 19]`. I would have expected an error, yet `call_variants` produced a vcf output despite not having an `insert_size` channel. Did `allele_frequency` replace the 7th channel correctly? Or did it somehow encode `allele_frequency` data as `insert_size,` if that makes sense? If you made examples with 8 channels, but the model has 7 channels, the call_variants step should have errors like you've shared in your original post:. ```. ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 7 channels while the examples have 8. ```. If you make examples with 7 channels, but your model.ckpt has different 7 channels - then it depends. Starting from v1.4.0, we keep a `model.ckpt.example_info.json` file together with the model. For example:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. If the customized_model you're using has this file, and if the examples you're making ends up having 7 channels but different ones, then it should still give you an error. But, if you're using an older model (such as the AF model you're using), and if it didn't have a `model.ckpt.example_info.json` file with it, then I believe the current behavior is that it will try to use the 7 channels directly. Which will cause the issue that it might use the weights for allele_frequency channel for the insert_size channel. Does that make sense? By the way, in case you haven't seen it, we have a nice blog post that talks about channels: https://google.github.io/deepvariant/posts/2022-06-09-adding-custom-channels/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:353,availability,Avail,Available,353,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:850,availability,checkpoint,checkpoints,850,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:869,availability,avail,available,869,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:227,energy efficiency,model,model,227,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:580,energy efficiency,cloud,cloud,580,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:625,energy efficiency,model,models,625,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:53,reliability,doe,does,53,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:353,reliability,Availab,Available,353,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:850,reliability,checkpoint,checkpoints,850,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:869,reliability,availab,available,869,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:353,safety,Avail,Available,353,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:869,safety,avail,available,869,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:227,security,model,model,227,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:353,security,Availab,Available,353,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:411,security,ident,identity,411,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:625,security,model,models,625,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:869,security,availab,available,869,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:784,usability,confirm,confirm,784,"@pichuan thank you for the discussion. And yes, that does make sense. That was my expectation, but I hadn't seen that blog post yet, so again, thanks! Final question: besides `insert_size,` do any of these channels listed have model.ckpt files on GCP, like the old PopVCF one I used? . ```. --channels: Comma-delimited list of optional channels to add. Available Channels: read_mapping_percent,avg_base_quality,identity,gap_compressed_identity,gc_content,is_homopolymer,homopolymer_weighted,blank,insert_size. ```. I assume they do not, or they'd be listed [here](https://console.cloud.google.com/storage/browser/deepvariant/models/DeepVariant/1.4.0?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false), correct? I want to confirm I'm keeping an eye out in the right place if/when any new checkpoints become available.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:10,availability,checkpoint,checkpoints,10,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:42,deployability,releas,releases,42,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:321,deployability,version,version,321,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:909,deployability,releas,release,909,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1192,deployability,build,building,1192,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1229,deployability,releas,release,1229,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1310,deployability,releas,release,1310,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4,energy efficiency,model,model,4,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:82,energy efficiency,model,models,82,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:215,energy efficiency,model,models,215,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:289,energy efficiency,model,model,289,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:633,energy efficiency,model,model,633,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:867,energy efficiency,frequenc,frequency,867,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:877,energy efficiency,model,model,877,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:321,integrability,version,version,321,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:940,integrability,pub,public,940,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:321,modifiability,version,version,321,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1292,performance,overhead,overhead,1292,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:10,reliability,checkpoint,checkpoints,10,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:4,security,model,model,4,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:82,security,model,models,82,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:215,security,model,models,215,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:289,security,model,model,289,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:633,security,model,model,633,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:877,security,model,model,877,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1050,usability,user,users,1050,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:1267,usability,support,supports,1267,"New model checkpoints associated with new releases will be under gs://deepvariant/models/DeepVariant as you noticed. I mentioned that starting from v1.4.0, you can see this file:. ```. $ gsutil cat gs://deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-wgs_standard/model.ckpt.example_info.json. {""version"": ""1.4.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]} . ```. The ""channels"" values are enums. You can look them up in this proto:. https://github.com/google/deepvariant/blob/r1.4/deepvariant/protos/deepvariant.proto#L1048. From the example above, it's saying that DeepVariant v1.4.0 WGS model has 7 channels, and they are:. ```. CH_READ_BASE = 1;. CH_BASE_QUALITY = 2;. CH_MAPPING_QUALITY = 3;. CH_STRAND = 4;. CH_READ_SUPPORTS_VARIANT = 5;. CH_BASE_DIFFERS_FROM_REF = 6;. CH_INSERT_SIZE = 19;. ```. Note that the allele frequency model isn't part of our regular release process yet. It's made public as part of our preprint https://doi.org/10.1101/2021.01.06.425550. Right now, we're retraining it when users request it. We're certainly hoping to see more uses cases (thank you for letting us know!). If it's become more mature, we can consider building it into part of our regular release process. (Adding more regular supports also means more overhead for each release, so we need to balance this carefully.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:105,usability,close,close,105,"Hi @jkalleberg ,. please see See: https://gist.github.com/pichuan/7ad09bf1fa8f519facf6806eca835ea6. I'll close this issue for now. Feel free to open more issues if you have any questions or feedback for us.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/568:190,usability,feedback,feedback,190,"Hi @jkalleberg ,. please see See: https://gist.github.com/pichuan/7ad09bf1fa8f519facf6806eca835ea6. I'll close this issue for now. Feel free to open more issues if you have any questions or feedback for us.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/568
https://github.com/google/deepvariant/issues/569:225,availability,sli,slight,225,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:544,availability,consist,consistently,544,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:570,availability,sli,slight,570,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:115,deployability,observ,observe,115,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:210,deployability,observ,observe,210,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:484,deployability,observ,observe,484,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:822,deployability,observ,observe,822,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:126,energy efficiency,measur,measurable,126,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:577,energy efficiency,reduc,reduction,577,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:836,energy efficiency,reduc,reductions,836,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:922,integrability,filter,filter,922,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:1078,interoperability,specif,specificity,1078,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:225,reliability,sli,slight,225,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:291,reliability,pra,practices,291,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:570,reliability,sli,slight,570,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:115,testability,observ,observe,115,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:151,testability,coverag,coverages,151,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:181,testability,coverag,coverages,181,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:210,testability,observ,observe,210,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:484,testability,observ,observe,484,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:822,testability,observ,observe,822,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:400,usability,indicat,indicate,400,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:544,usability,consist,consistently,544,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/569:639,usability,learn,learned,639,"Hi @guandailu . We have investigated the use of the MarkDuplicates step. In WGS and exome samples we looked at, we observe no measurable difference at coverages 30x and higher. For coverages lower than 30x, we observe a very slight advantage for MarkDuplicates. For this reason in our [best practices recommendation](https://github.com/google/deepvariant/blob/r1.4/docs/trio-merge-case-study.md), we indicate duplicate marking as optional. . In terms of other preprocessing steps, we observe that running Base Quality Score Recalibrator (BQSR) consistently results in a slight reduction of accuracy (likely because DeepVariant has already learned how to use the underlying concept to recalibrate qualities as it considers calling). We have a strong recommendation NOT to run Variant Score Quality Recalibration (VQSR). We observe large reductions in accuracy, particularly in recall of rare variants. If you would like to filter for higher precision than the default calls, we recommend using the Genotype Quality (GQ) field, setting a higher threshold based on your desire for specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/569
https://github.com/google/deepvariant/issues/570:103,safety,input,input,103,Every where I have seen deepvariant example with .bam files. is there any way I can use fastq files as input?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:103,usability,input,input,103,Every where I have seen deepvariant example with .bam files. is there any way I can use fastq files as input?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:240,modifiability,Pac,PacBio,240,"Hi @Rvvijays . DeepVariant always takes either BAM or CRAM files as input. It won't take FASTQ directly as input, so you will need to map your FASTQ reads to a reference genome with a method like BWA for Illumina data or pbmm2/minimap2 for PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:68,safety,input,input,68,"Hi @Rvvijays . DeepVariant always takes either BAM or CRAM files as input. It won't take FASTQ directly as input, so you will need to map your FASTQ reads to a reference genome with a method like BWA for Illumina data or pbmm2/minimap2 for PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:107,safety,input,input,107,"Hi @Rvvijays . DeepVariant always takes either BAM or CRAM files as input. It won't take FASTQ directly as input, so you will need to map your FASTQ reads to a reference genome with a method like BWA for Illumina data or pbmm2/minimap2 for PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:68,usability,input,input,68,"Hi @Rvvijays . DeepVariant always takes either BAM or CRAM files as input. It won't take FASTQ directly as input, so you will need to map your FASTQ reads to a reference genome with a method like BWA for Illumina data or pbmm2/minimap2 for PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:107,usability,input,input,107,"Hi @Rvvijays . DeepVariant always takes either BAM or CRAM files as input. It won't take FASTQ directly as input, so you will need to map your FASTQ reads to a reference genome with a method like BWA for Illumina data or pbmm2/minimap2 for PacBio data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:75,usability,close,close,75,"Hi @Rvvijays ,. thanks for your question. With Andrew's answer above, I'll close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:103,interoperability,convers,conversation,103,"Will anyone help me with the whole process to convert fastq files to vcf using deepvariant, along with conversation of fastq to bam,. please i will be grateful",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/570:12,usability,help,help,12,"Will anyone help me with the whole process to convert fastq files to vcf using deepvariant, along with conversation of fastq to bam,. please i will be grateful",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/570
https://github.com/google/deepvariant/issues/571:85,deployability,updat,update,85,"Hello,. I created a tracking bug to add this feature to DeepVariant. We will post an update once we finalize the plan for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:131,deployability,releas,release,131,"Hello,. I created a tracking bug to add this feature to DeepVariant. We will post an update once we finalize the plan for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:85,safety,updat,update,85,"Hello,. I created a tracking bug to add this feature to DeepVariant. We will post an update once we finalize the plan for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:85,security,updat,update,85,"Hello,. I created a tracking bug to add this feature to DeepVariant. We will post an update once we finalize the plan for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:113,testability,plan,plan,113,"Hello,. I created a tracking bug to add this feature to DeepVariant. We will post an update once we finalize the plan for the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:593,availability,replic,replicate,593,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:691,availability,slo,slower,691,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,deployability,depend,depend,47,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:898,deployability,modul,modules,898,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,integrability,depend,depend,47,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:449,integrability,Protocol,Protocol,449,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:350,interoperability,format,format,350,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:380,interoperability,Convers,Conversion,380,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:449,interoperability,Protocol,Protocol,449,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:730,interoperability,specif,specific,730,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,modifiability,depend,depend,47,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:898,modifiability,modul,modules,898,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:268,performance,perform,performed,268,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:691,reliability,slo,slower,691,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,safety,depend,depend,47,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:898,safety,modul,modules,898,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,testability,depend,depend,47,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:268,usability,perform,performed,268,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:579,usability,prefer,preference,579,"Hi @mdriller . My answer to your question will depend on what exactly you will need from Plink and what sort of cohort approach you have. . If you just want to be able to run Plink on the joint genotype results, I wonder if you can try following the process which was performed for UKBiobank to convert their DeepVariant exome joint calls into PLINK format. That is the section **Conversion of pVCF to PLINK and BGEN files** [from the UKBiobank WES Protocol](https://biobank.ctsu.ox.ac.uk/crystal/ukb/docs/UKB_WES_Protocol.pdf). I hope this will work, as it is not generally our preference to replicate the functionality of -ERC BP_RESOLUTION, and this is likely to make writing output much slower. If, instead, you want calls at specific sites (similar to a genotyping chip approach but with NGS data), I would say that is is possible to force genotyping at a given set of alleles with one of the modules of DeepVariant (VCF candidate importer). I suspect this isn't what you want though. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:50,testability,understand,understand,50,"Hi @mdriller ,. It'll be great if you can help us understand your use case a bit more (see @AndrewCarroll 's reply above) so we can follow up with you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:42,usability,help,help,42,"Hi @mdriller ,. It'll be great if you can help us understand your use case a bit more (see @AndrewCarroll 's reply above) so we can follow up with you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:68,integrability,Protocol,Protocol,68,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:394,integrability,FILTER,FILTER,394,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:68,interoperability,Protocol,Protocol,68,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:406,interoperability,FORMAT,FORMAT,406,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:349,modifiability,variab,variable,349,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:117,reliability,doe,does,117,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:42,safety,test,testing,42,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:177,security,ident,identify,177,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:42,testability,test,testing,42,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:778,usability,help,help,778,"Hi all,. sorry about the late reply I was testing the UKBiobank WES Protocol provided by Andrew but unfortunately it does not seem fix our problem. The general issue is that to identify runs of homozygosity(ROH) with plink you can also just provide a vcf file but this vcf file needs a base resolution e.g. an entry for each position, whether it is variable or not:. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT PacBio_CCS. SUPER_1 1 . C . . . DP=49 GT:AD:DP:RGQ 0/0:49:49:99. SUPER_1 2 . C . . . DP=50 GT:AD:DP:RGQ 0/0:50:50:99. SUPER_1 3 . T . . . DP=54 GT:AD:DP:RGQ 0/0:54:54:99. SUPER_1 4 . A . . . DP=61 GT:AD:DP:RGQ 0/0:61:61:99. ... And we were just wondering if there is a possibility to generate such a vcf file using DeepVariant. Thanks again for all the replies and help. best regards,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:34,reliability,doe,does,34,"Hi @mdriller . DeepVariant itself does not have this option. . However, as I understand you really just want to convert a single sample gVCF to a reference expanded VCF. bcftools may allow you to efficiently do this with the option:. `bcftools convert --gvcf2vcf ${VCF} --fasta-ref ${REF}`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:77,testability,understand,understand,77,"Hi @mdriller . DeepVariant itself does not have this option. . However, as I understand you really just want to convert a single sample gVCF to a reference expanded VCF. bcftools may allow you to efficiently do this with the option:. `bcftools convert --gvcf2vcf ${VCF} --fasta-ref ${REF}`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:196,usability,efficien,efficiently,196,"Hi @mdriller . DeepVariant itself does not have this option. . However, as I understand you really just want to convert a single sample gVCF to a reference expanded VCF. bcftools may allow you to efficiently do this with the option:. `bcftools convert --gvcf2vcf ${VCF} --fasta-ref ${REF}`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:96,testability,coverag,coverage,96,"Hi @AndrewCarroll,. thank you very much this solves the issue. DeepVariant is using the minimum coverage/depth for the ""summed up"" homozygous regions in the gvcf right? thanks again for all the help,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:88,usability,minim,minimum,88,"Hi @AndrewCarroll,. thank you very much this solves the issue. DeepVariant is using the minimum coverage/depth for the ""summed up"" homozygous regions in the gvcf right? thanks again for all the help,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:194,usability,help,help,194,"Hi @AndrewCarroll,. thank you very much this solves the issue. DeepVariant is using the minimum coverage/depth for the ""summed up"" homozygous regions in the gvcf right? thanks again for all the help,. Max",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:94,testability,coverag,coverage,94,"@mdriller . Yes, I believe that is correct. The reference blocks of the GVCF have the minimum coverage over the span of the reference block.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:86,usability,minim,minimum,86,"@mdriller . Yes, I believe that is correct. The reference blocks of the GVCF have the minimum coverage over the span of the reference block.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:195,deployability,build,build,195,"Hi @mdriller ,. I'm closing this issue now. My understanding is that your issue is resolved by @AndrewCarroll 's suggestion. So we'll also close the internal tracking issue, and we won't plan to build this directly into DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:47,testability,understand,understanding,47,"Hi @mdriller ,. I'm closing this issue now. My understanding is that your issue is resolved by @AndrewCarroll 's suggestion. So we'll also close the internal tracking issue, and we won't plan to build this directly into DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:187,testability,plan,plan,187,"Hi @mdriller ,. I'm closing this issue now. My understanding is that your issue is resolved by @AndrewCarroll 's suggestion. So we'll also close the internal tracking issue, and we won't plan to build this directly into DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/571:139,usability,close,close,139,"Hi @mdriller ,. I'm closing this issue now. My understanding is that your issue is resolved by @AndrewCarroll 's suggestion. So we'll also close the internal tracking issue, and we won't plan to build this directly into DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/571
https://github.com/google/deepvariant/issues/572:98,availability,ping,ping,98,@FarmOmics we are planning on a release very soon that will enable RNA-seq variant calling. I can ping you on this issue once that release is out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:32,deployability,releas,release,32,@FarmOmics we are planning on a release very soon that will enable RNA-seq variant calling. I can ping you on this issue once that release is out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:131,deployability,releas,release,131,@FarmOmics we are planning on a release very soon that will enable RNA-seq variant calling. I can ping you on this issue once that release is out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:18,testability,plan,planning,18,@FarmOmics we are planning on a release very soon that will enable RNA-seq variant calling. I can ping you on this issue once that release is out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:19,deployability,releas,released,19,@FarmOmics we have released an RNA-seq model and case study. Let me know if you have any questions. https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:39,energy efficiency,model,model,39,@FarmOmics we have released an RNA-seq model and case study. Let me know if you have any questions. https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:39,security,model,model,39,@FarmOmics we have released an RNA-seq model and case study. Let me know if you have any questions. https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:27,energy efficiency,model,model,27,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:115,energy efficiency,model,model,115,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:199,reliability,pra,practice,199,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:27,security,model,model,27,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:115,security,model,model,115,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:8,usability,document,documentation,8,"In your documentation, the model option ""--model_type=WES"" is WES. Whether this means RNASeq SNP calling uses same model with WES data? What preprocessing of RNASeq data should be done? In GATK best practice, SplitNCigarReads is required, should it also be done? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:688,energy efficiency,model,model,688,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:725,energy efficiency,model,model,725,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:731,energy efficiency,model,model,731,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:865,energy efficiency,model,model,865,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:76,integrability,wrap,wrapper,76,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:542,integrability,wrap,wrapper,542,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:55,interoperability,specif,specifically,55,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:76,interoperability,wrapper,wrapper,76,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:113,interoperability,Specif,Specifically,113,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:542,interoperability,wrapper,wrapper,542,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:688,security,model,model,688,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:725,security,model,model,725,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:731,security,model,model,731,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:865,security,model,model,865,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:1079,usability,help,help,1079,"Hi @FarmOmics ,. The `--model_type=WES` is a shorthand specifically for the wrapper script ""run_deepvariant.py"". Specifically here. https://github.com/google/deepvariant/blob/r1.4/scripts/run_deepvariant.py#L236-L239. In https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md , you'll see that the RNAseq run actually overwrites these arguments:. with:. ```. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. ```. which basically means: If you run `make_examples` on your own (without using the wrapper script ""run_deepvariant.py""), you'll want to provide `--split_skip_reads=true`, but not providing `channels`. And we also provided RNAseq model with:. ```. --customized_model=model/model.ckpt \. ```. So, https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md isn't actually using WES model at all. (In the future we'll think about how to make this less confusing.). In terms of preprocessing for RNAseq data, the important flag to add is `--split_skip_reads` to make_examples. Let me know if I can help clarifying with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:22,usability,close,close,22,"Hi @FarmOmics ,. I'll close this issue. We would love to hear your feedback about the RNAseq caller. Please don't hesitate to reach out again if you have more questions or feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:67,usability,feedback,feedback,67,"Hi @FarmOmics ,. I'll close this issue. We would love to hear your feedback about the RNAseq caller. Please don't hesitate to reach out again if you have more questions or feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:172,usability,feedback,feedback,172,"Hi @FarmOmics ,. I'll close this issue. We would love to hear your feedback about the RNAseq caller. Please don't hesitate to reach out again if you have more questions or feedback.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:19,deployability,manag,manage,19,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:19,energy efficiency,manag,manage,19,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:118,interoperability,share,share,118,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:19,safety,manag,manage,19,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:65,security,team,team,65,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:129,usability,experien,experience,129,@FarmOmics did you manage to run the case study here? Because my team is having problems that seem unresolved. Kindly share your experience in running it,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:15,interoperability,share,share,15,"@ne1al Can you share what issues your team is having? Feel free to open another issue. Or, if the issue is the same as here, we can reopen this one too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/572:38,security,team,team,38,"@ne1al Can you share what issues your team is having? Feel free to open another issue. Or, if the issue is the same as here, we can reopen this one too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/572
https://github.com/google/deepvariant/issues/573:342,energy efficiency,model,model-case-study,342,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:36,modifiability,pac,package,36,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:96,modifiability,maintain,maintained,96,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:335,modifiability,pac,pacbio-model-case-study,335,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:96,safety,maintain,maintained,96,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:135,security,team,team,135,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/573:342,security,model,model-case-study,342,"Hi akiss-me,. The conda-deepvariant package is a community contribution by @chapmanb and is not maintained directly by the DeepVariant team -- we are not experts on Conda, unfortunately. You may try to run using [Singularity](https://sylabs.io/docs/). See [Quick Start](https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-pacbio-model-case-study.md)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/573
https://github.com/google/deepvariant/issues/574:133,availability,error,error,133,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:139,integrability,messag,messages,139,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:139,interoperability,messag,messages,139,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:247,interoperability,convers,conversation,247,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:133,performance,error,error,133,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:133,safety,error,error,133,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:104,usability,command,command,104,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:133,usability,error,error,133,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:222,usability,user,users,222,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:232,usability,learn,learn,232,"Hi @ankurc17 . Can you tell us more about what the issues are? For example, what OS are you using, what command did you run and what error messages you've seen. It'll be great if we can assist you here, because then other users can learn from our conversation too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:84,deployability,Resourc,Resources,84,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:800,deployability,log,log,800,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:84,energy efficiency,Resourc,Resources,84,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:828,interoperability,share,share,828,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:84,performance,Resourc,Resources,84,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:44,safety,input,input,44,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:84,safety,Resourc,Resources,84,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:270,safety,input,input,270,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:311,safety,input,input,311,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:350,safety,input,input,350,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:800,safety,log,log,800,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:800,security,log,log,800,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:84,testability,Resourc,Resources,84,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:800,testability,log,log,800,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:0,usability,Command,Command,0,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:44,usability,input,input,44,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:270,usability,input,input,270,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:311,usability,input,input,311,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:350,usability,input,input,350,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:870,usability,user,user-images,870,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:983,usability,user,user-images,983,"Command Used: sudo docker run -v ""${PWD}"":""/input"" -v ""${PWD}/output"":""/output"" -v /Resources/:/Res deeptrio_gpu:latest /opt/deepvariant/bin/deeptrio/run_deeptrio --model_type WGS --call_variants_extra_args=""use_openvino=true"" --ref=/Res/Hg19_chr/hg19.fa --reads_child /input/41420446-BABY.bam --reads_parent1 /input/41420446-FB.bam --reads_parent2 /input/41420446-MB.bam --output_vcf_child /output/Baby.deeptrio.vcf.gz --output_vcf_parent1 /output/Fb.deeptrio.vcf.gz --output_vcf_parent2 /output/Mb.deeptrio.vcf.gz --sample_name_child 'Baby' --sample_name_parent1 'Fb' --sample_name_parent2 'Mb' --num_shards=38 --output_gvcf_child /output/Baby.deeptrio.g.vcf.gz --output_gvcf_parent1 /output/Fb.deeptrio.g.vcf.gz --output_gvcf_parent2 /output/Mb.deeptrio.g.vcf.gz. I have captured the outputs in a log file. Do suggest how to share the same with you? ![image](https://user-images.githubusercontent.com/27851922/195591985-6c022925-816b-4bce-af50-8d31377b84d9.png). ![image](https://user-images.githubusercontent.com/27851922/195592082-e7e60d2d-92d6-431e-b4a2-a35c22314417.png).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:151,availability,error,error,151,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:104,energy efficiency,current,currently,104,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:151,performance,error,error,151,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:151,safety,error,error,151,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:114,usability,support,supported,114,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:151,usability,error,error,151,"This is probably causing the issues `--call_variants_extra_args=""use_openvino=true""` as openvino is not currently supported (#541) and throws the same error you see here. Running without that extra arg should then work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:101,reliability,doe,doesn,101,"Hi @ankurc17 ,. @ASLeonard 's answer above is likely the issue. I'll close this bug, but if it still doesn't work, please feel free to re-open, or open a new issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/574:69,usability,close,close,69,"Hi @ankurc17 ,. @ASLeonard 's answer above is likely the issue. I'll close this bug, but if it still doesn't work, please feel free to re-open, or open a new issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/574
https://github.com/google/deepvariant/issues/575:147,usability,help,helpful,147,"Hi @amy-houseman ,. Can you take a look at https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-vcf-stats-report.md and see if this is helpful for you? As @kishwarshafin said, we don't have tools that run on multiple VCFs. But it is possible to just run the analysis tool on existing VCF file. (If that's what you're looking for)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/575
https://github.com/google/deepvariant/issues/575:202,usability,tool,tools,202,"Hi @amy-houseman ,. Can you take a look at https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-vcf-stats-report.md and see if this is helpful for you? As @kishwarshafin said, we don't have tools that run on multiple VCFs. But it is possible to just run the analysis tool on existing VCF file. (If that's what you're looking for)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/575
https://github.com/google/deepvariant/issues/575:279,usability,tool,tool,279,"Hi @amy-houseman ,. Can you take a look at https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-vcf-stats-report.md and see if this is helpful for you? As @kishwarshafin said, we don't have tools that run on multiple VCFs. But it is possible to just run the analysis tool on existing VCF file. (If that's what you're looking for)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/575
https://github.com/google/deepvariant/issues/577:57,deployability,contain,contain,57,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:150,deployability,contain,container,150,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:285,deployability,contain,container,285,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:95,interoperability,Bind,Binding,95,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:209,interoperability,Bind,Binds,209,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:233,interoperability,specif,specify,233,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:95,modifiability,Bind,Binding,95,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:209,modifiability,Bind,Binds,209,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:82,safety,input,input,82,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:82,usability,input,input,82,$INPUT_DIR should exist on your local machine. It should contain all the expected input files. Binding your local directories to directories inside a container is done through -v option:. ```. -v / --volume - Binds a volume. You can specify a path and a corresponding path inside your container. . ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:141,availability,error,error,141,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:192,integrability,messag,message,192,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:192,interoperability,messag,message,192,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:141,performance,error,error,141,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:155,reliability,doe,doesn,155,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:141,safety,error,error,141,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:141,usability,error,error,141,"@akolesnikov . Thank you for the answer. All paths (both directories and fiels) that I included in my script do exist. Still, it shows me an error as file doesn't exist as I wrote in my first message above.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:80,energy efficiency,gpu,gpus,80,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:499,energy efficiency,gpu,gpus,499,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:210,integrability,Pub,PublicData,210,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:629,integrability,Pub,PublicData,629,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:80,performance,gpu,gpus,80,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:499,performance,gpu,gpus,499,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:382,testability,understand,understand,382,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:374,usability,help,help,374,"@imdanique . If you run something like:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam. ```. Can you see the file? This will help us understand whether the docker filesystem can actually see the file. Or, try:. ```. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:74,energy efficiency,gpu,gpus,74,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:204,integrability,Pub,PublicData,204,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:74,performance,gpu,gpus,74,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:906,safety,permiss,permissions,906,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:389,security,access,access,389,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:501,security,access,access,501,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:630,security,access,access,630,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:813,security,access,access,813,"@pichuan . I tried to run. . ```. bash. BIN_VERSION=""1.4.0"". docker run --gpus all \. -v ""${INPUT_DIR}"":""/data/deepvariant/test_bam"" \. -v ""${OUTPUT_DIR}"":""/data/deepvariant/output"" \. -v ""${REF}"":""/data/PublicData/hg38"" \. google/deepvariant:""${BIN_VERSION}"" \. ls /data/deepvariant/test_bam/*bam*. ```. Strangely, it showed that I have 3 files matching the wildcard. ```bash. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.du': No such file or directory. ls: cannot access '/data/deepvariant/test_bam/DP8400014945BR_L01_541.picard_MD.bam.220427_094718.md5': No such file or directory. ```. Then I tried to ls directory itself:. ```bash . ls: cannot access '/data/deepvariant/test_bam/': No such file or directory. ```. I also checked all the permissions and rw perrmissions are granted recursively",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:15,availability,echo,echo,15,"Can you . ```. echo ${INPUT_DIR}. ```. to confirm that the value is what you expected? And, just to be sure:. ```. ls ${INPUT_DIR}. ```. to make sure there are files there?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:42,usability,confirm,confirm,42,"Can you . ```. echo ${INPUT_DIR}. ```. to confirm that the value is what you expected? And, just to be sure:. ```. ls ${INPUT_DIR}. ```. to make sure there are files there?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:22,availability,echo,echo,22,"@pichuan . When I run echo, the output is empty. . When I run. ```bash. ls ${INPUT_DIR}. ```. it shows a list of files of pwd, but not /data/deepvariant/test_bam/. If I run the script from /data/deepvariant directory, then it shows me files in /data/deepvariant, and if I run it from /data, then it shows me ls of /data",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:32,deployability,updat,update,32,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:354,modifiability,variab,variables,354,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:247,reliability,Doe,Does,247,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:272,reliability,diagno,diagnose,272,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:32,safety,updat,update,32,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:32,security,updat,update,32,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:272,testability,diagno,diagnose,272,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:300,testability,simpl,simplifying,300,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:96,usability,command,command,96,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:149,usability,command,command,149,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:300,usability,simpl,simplifying,300,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:370,usability,help,help,370,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:472,usability,help,helpful,472,"Hi @imdanique ,. Thanks for the update. Can try to get to a point where when you run the docker command, your ls can see the file? Because if the ls command can't list the file, that means deepvariant binary would have no chance to find the file. Does that make sense? To diagnose the problem, maybe simplifying the script or script to remove the use of variables could help too, in case they were not set correctly. https://docs.docker.com/storage/volumes/ might also be helpful to read.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:862,availability,error,error,862,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:190,deployability,version,version,190,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:907,deployability,Fail,Failed,907,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1158,deployability,modul,module,1158,"annot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2806,deployability,fail,failed,2806,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:190,integrability,version,version,190,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:298,interoperability,share,share,298,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:351,interoperability,share,share,351,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:498,interoperability,share,share,498,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:564,interoperability,share,share,564,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:632,interoperability,share,share,632,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:698,interoperability,share,share,698,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:779,interoperability,share,share,779,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:935,interoperability,share,share,935,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2741,interoperability,share,share,2741,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2878,interoperability,share,share,2878,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2941,interoperability,share,share,2941,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3004,interoperability,share,share,3004,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3124,interoperability,share,share,3124,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:190,modifiability,version,version,190,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1158,modifiability,modul,module,1158,"annot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:862,performance,error,error,862,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2787,performance,parallel,parallel,2787,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:907,reliability,Fail,Failed,907,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2806,reliability,fail,failed,2806,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:321,safety,input,input,321,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:330,safety,input,input,330,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:521,safety,input,input,521,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:587,safety,input,input,587,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:862,safety,error,error,862,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:958,safety,input,input,958,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1158,safety,modul,module,1158,"annot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2764,safety,input,input,2764,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2901,safety,input,input,2901,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2964,safety,input,input,2964,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1010,testability,Trace,Traceback,1010," encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:252,usability,command,command,252,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:321,usability,input,input,321,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:330,usability,input,input,330,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:521,usability,input,input,521,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:587,usability,input,input,587,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:862,usability,error,error,862,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:958,usability,input,input,958,"Hello, . I have encountered the same problem as mentioned in this issue. . And I have also tried the solutions provided above, but the deepvariant binary still cannot see the bam files. The version I'm using is: google/deepvariant:""1.5.0"". Here is the command i run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta \. --reads=/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam \. --output_vcf=/data2/share/home/liyi/TEs/dv/output/C111.vcf.gz \. --output_gvcf=/data2/share/home/liyi/TEs/dv/output/C111.g.vcf.gz \. --intermediate_results_dir /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir \. --num_shards=5. ```. The error output is: . ```. [E::hts_open_format] Failed to open file ""/data2/share/home/liyi/TEs/dv/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2764,usability,input,input,2764,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2901,usability,input,input,2901,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2964,usability,input,input,2964,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3223,usability,user,user,3223,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:3304,usability,help,help,3304,"files_3_jead3w/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_3_jead3w/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /data2/share/home/liyi/TEs/dv/input/C162-2_final.fasta --reads /data2/share/home/liyi/TEs/dv/input/C111_mapped.bam --examples /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /data2/share/home/liyi/TEs/dv/output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 0. real	0m3.521s. user	0m3.689s. sys	0m3.908s. ```. Is there any other solutions, Could you please help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:598,availability,avail,available,598,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:626,deployability,contain,container,626,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:107,interoperability,share,share,107,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:160,interoperability,share,share,160,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:541,interoperability,share,share,541,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:598,reliability,availab,available,598,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:130,safety,input,input,130,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:139,safety,input,input,139,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:301,safety,input,input,301,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:338,safety,input,input,338,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:564,safety,input,input,564,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:573,safety,input,input,573,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:598,safety,avail,available,598,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:641,safety,input,input,641,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:598,security,availab,available,598,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:130,usability,input,input,130,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:139,usability,input,input,139,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:301,usability,input,input,301,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:338,usability,input,input,338,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:564,usability,input,input,564,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:573,usability,input,input,573,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:641,usability,input,input,641,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:690,usability,help,helps,690,"Hi @LiYi0604,. Just change your script to the following, and it should run:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/dv/input"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Basically `""/data2/share/home/liyi/TEs/dv/input"":""/input""` makes the folder available inside the docker container as `/input`, so you don't need the long name. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:78,availability,error,error,78,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:111,deployability,Fail,Failed,111,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:333,deployability,modul,module,333,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1952,deployability,fail,failed,1952,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:333,modifiability,modul,module,333,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:78,performance,error,error,78,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1933,performance,parallel,parallel,1933,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:111,reliability,Fail,Failed,111,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1952,reliability,fail,failed,1952,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:78,safety,error,error,78,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:133,safety,input,input,133,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:333,safety,modul,module,333,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1910,safety,input,input,1910,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2018,safety,input,input,2018,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2052,safety,input,input,2052,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:185,testability,Trace,Traceback,185,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:49,usability,command,command,49,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:78,usability,error,error,78,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:133,usability,input,input,133,"@pgrosu . Thanks for the answer. I've tried this command, and it got the same error. ```. [E::hts_open_format] Failed to open file ""/input/C111_mapped.bam"" : No such file or directory. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:1910,usability,input,input,1910,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2018,usability,input,input,2018,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2052,usability,input,input,2052,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:2253,usability,user,user,2253,"nt/deepvariant/make_examples.py"", line 196, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 182, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 133, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 88, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 147, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_g1m5s08g/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 227, in __init__. self._reader = sam_reader.SamReader.from_file(. ValueError: NOT_FOUND: Could not open /input/C111_mapped.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/C162-2_final.fasta --reads /input/C111_mapped.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@5.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@5.gz --task 1. real	0m3.507s. user	0m3.304s. sys	0m2.638s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:409,availability,operat,operating,409,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:227,interoperability,bind,bind,227,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:247,interoperability,share,share,247,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:227,modifiability,bind,bind,227,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:270,safety,input,input,270,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:286,safety,input,input,286,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:330,safety,input,input,330,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:23,usability,user,user,23,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:270,usability,input,input,270,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:286,usability,input,input,286,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:330,usability,input,input,330,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:366,usability,behavi,behavior,366,"Hi @LiYi0604,. Another user is having a similar issue as well (https://github.com/google/deepvariant/issues/184#issuecomment-1700285417). Could you try this instead to see if you see the files:. ```. docker run \. --mount type=bind,source=""/data2/share/home/liyi/TEs/dv/input"",target=""/input"" \. google/deepvariant:""1.5.0"" ls -l /input. ```. It's an interesting new behavior that shouldn't be happening. What operating system are your running this on? Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:66,availability,reboot,rebooting,66,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:449,deployability,version,version,449,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:572,deployability,version,version,572,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:592,deployability,build,build,592,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:449,integrability,version,version,449,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:572,integrability,version,version,572,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:183,interoperability,share,share,183,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:312,interoperability,share,share,312,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:449,modifiability,version,version,449,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:572,modifiability,version,version,572,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:56,safety,compl,completed,56,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:56,security,compl,completed,56,"Hi Paul,. Sorry for the late reply, the server has just completed rebooting. I ran the code, and the output is:. ```. lrwxrwxrwx 1 1010 1010 66 Aug 31 02:25 C111_mapped.bam -> /data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111/C111_mapped.bam. lrwxrwxrwx 1 1010 1010 58 Aug 31 02:25 C162-2_final.fasta -> /data2/share/home/liyi/TEs/Genome/fasta/C162-2_final.fasta. ```. Looks the docker knows where the file is. And this is my Linux info and docker version:. ```. Linux mgr 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. Docker version 18.03.1-ce, build 9ee9f40. ```. I'm new to Linux, hoping this can provide useful information. Thanks, . LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:272,deployability,updat,updated,272,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:115,interoperability,share,share,115,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:341,interoperability,share,share,341,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:409,interoperability,share,share,409,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:464,interoperability,share,share,464,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:138,safety,input,input,138,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:272,safety,updat,updated,272,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:388,safety,input,input,388,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:644,safety,input,input,644,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:66,security,sign,sign,66,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:272,security,updat,updated,272,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:39,usability,help,helpful,39,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:138,usability,input,input,138,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:388,usability,input,input,388,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:644,usability,input,input,644,"Hi LiYi,. No worries, and this is very helpful! So this is a good sign, but here's the issue. The files in `/data2/share/home/liyi/TEs/dv/input` actually point to other directories that are not connected to Docker. It is best to just refer to them directly. For that I've updated your script to the following:. ```. docker run \. -v ""/data2/share/home/liyi/TEs/Pan-genome/Giraffe/C111"":""/input"" \. -v ""/data2/share/home/liyi/TEs/dv/output"":""/output"" \. -v ""/data2/share/home/liyi/TEs/Genome/fasta"":""/fasta"" \. google/deepvariant:""1.5.0"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/fasta/C162-2_final.fasta \. --reads=/input/C111_mapped.bam \. --output_vcf=/output/C111.vcf.gz \. --output_gvcf=/output/C111.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=5. ```. Let me know if this works for you. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:73,availability,error,error,73,"Hi Paul, . Thank you for the answer, it works! Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again! LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:89,interoperability,format,format,89,"Hi Paul, . Thank you for the answer, it works! Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again! LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:73,performance,error,error,73,"Hi Paul, . Thank you for the answer, it works! Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again! LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:73,safety,error,error,73,"Hi Paul, . Thank you for the answer, it works! Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again! LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/577:73,usability,error,error,73,"Hi Paul, . Thank you for the answer, it works! Although I still got some error about the format of BAM file, I can try if I can resolve it on my own. Thanks again! LiYi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/577
https://github.com/google/deepvariant/issues/578:77,availability,error,error-rate,77,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:29,deployability,log,log,29,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:77,performance,error,error-rate,77,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:29,safety,log,log,29,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:77,safety,error,error-rate,77,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:29,security,log,log,29,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:29,testability,log,log,29,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:156,testability,context,context,156,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:77,usability,error,error-rate,77,"@olechnwin ,. Looking at the log, it is generating a lot of examples. Is the error-rate of the `scaffolds_FINAL.fasta` too high? Can you give a little more context on what type of genome you are running this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:68,availability,error,error,68,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:244,interoperability,mismatch,mismatches,244,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:68,performance,error,error,68,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:279,reliability,doe,does,279,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:68,safety,error,error,68,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:68,usability,error,error,68,"@kishwarshafin,. Thank you so much for your reply. How do I get the error rate of the genome assembly? This is a human cancer cell line. I ran quast on the assembly comparing it with hg19 and the number of misassemblies ~2000 and the number of mismatches per 100kb is 124.3. Why does it generate a lot of examples?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:199,deployability,observ,observed,199,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:421,deployability,observ,observed,421,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:505,energy efficiency,measur,measured,505,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:188,interoperability,mismatch,mismatches,188,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:410,interoperability,mismatch,mismatches,410,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:199,testability,observ,observed,199,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:421,testability,observ,observed,421,"@olechnwin ,. So the reference you are using ""scaffolds_FINAL.fasta"" can be a low quality reference/assembly in which case when you align the reads to that assembly there will be a lot of mismatches observed in the read compared to the assembly. One thing you can do is to inspect your `hybrid_hifi_Kapa_combined.bam` a bit manually on IGV to see if your alignments look generally decent. If you have too many mismatches observed in the reads, it will generate a lot of examples. . DeepVariant runtime is measured against higher quality human genomes (i.e. GRCh38/T2T-CHM13). If you are using a low quality assembly, then your runtime would increase.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:262,reliability,Doe,Does,262,"@kishwarshafin ,. I am actually trying to polish the assembly using DeepVariant and increase the quality of the assembly. Do you have any suggestions on how to speed it up? Is there additional step I should do to increase the quality before running DeepVariant? Does increasing number of shards help? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:295,usability,help,help,295,"@kishwarshafin ,. I am actually trying to polish the assembly using DeepVariant and increase the quality of the assembly. Do you have any suggestions on how to speed it up? Is there additional step I should do to increase the quality before running DeepVariant? Does increasing number of shards help? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:213,energy efficiency,frequenc,frequency,213,"@olechnwin ,. In that case you need to increase the SNP and indel finding thresholds using `--make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""` parameter. Here 0.2 means the allele frequency should be 20% to be a candidate. You can set this to a threshold of your choice.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:176,modifiability,paramet,parameter,176,"@olechnwin ,. In that case you need to increase the SNP and indel finding thresholds using `--make_examples_extra_args=""vsc_min_fraction_snps=0.2,vsc_min_fraction_indels=0.2""` parameter. Here 0.2 means the allele frequency should be 20% to be a candidate. You can set this to a threshold of your choice.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:148,usability,document,documentation,148,"@kishwarshafin,. Thank you! I'll try to change the threshold. Can you please elaborate more on how to choose this threshold? Is there a more detail documentation on what to increase the SNP threshold for polishing the genome? Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:272,energy efficiency,adapt,adapt,272,"Hi @olechnwin ,. The thresholds are usually chosen empirically. Based on what tasks we're trying to achieve, we choose it to find the best tradeoff between sensitivity and the amount of noises we bring in. This is more a research problem, especially that you're trying to adapt DeepVariant code to a different problem. So we won't be able to easily share a recipe here for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:272,integrability,adapt,adapt,272,"Hi @olechnwin ,. The thresholds are usually chosen empirically. Based on what tasks we're trying to achieve, we choose it to find the best tradeoff between sensitivity and the amount of noises we bring in. This is more a research problem, especially that you're trying to adapt DeepVariant code to a different problem. So we won't be able to easily share a recipe here for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:272,interoperability,adapt,adapt,272,"Hi @olechnwin ,. The thresholds are usually chosen empirically. Based on what tasks we're trying to achieve, we choose it to find the best tradeoff between sensitivity and the amount of noises we bring in. This is more a research problem, especially that you're trying to adapt DeepVariant code to a different problem. So we won't be able to easily share a recipe here for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:349,interoperability,share,share,349,"Hi @olechnwin ,. The thresholds are usually chosen empirically. Based on what tasks we're trying to achieve, we choose it to find the best tradeoff between sensitivity and the amount of noises we bring in. This is more a research problem, especially that you're trying to adapt DeepVariant code to a different problem. So we won't be able to easily share a recipe here for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/578:272,modifiability,adapt,adapt,272,"Hi @olechnwin ,. The thresholds are usually chosen empirically. Based on what tasks we're trying to achieve, we choose it to find the best tradeoff between sensitivity and the amount of noises we bring in. This is more a research problem, especially that you're trying to adapt DeepVariant code to a different problem. So we won't be able to easily share a recipe here for you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/578
https://github.com/google/deepvariant/issues/579:26,availability,error,error,26,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:118,deployability,instal,install,118,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:32,integrability,messag,message,32,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:32,interoperability,messag,message,32,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:26,performance,error,error,26,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:26,safety,error,error,26,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:26,usability,error,error,26,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:54,usability,command,command,54,"Hello, as you can see the error message is ""samtools: command not found"". Can you please see if there's a way you can install samtools for your environment?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:72,deployability,instal,installed,72,> . Thanks for answering. I forgot to say that the samtools are already installed.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:151,availability,error,error,151,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:133,interoperability,platform,platform-specific,133,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:151,performance,error,error,151,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:151,safety,error,error,151,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:56,usability,help,help,56,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:96,usability,help,help,96,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/579:151,usability,error,error,151,"@moyarod ,. In that case, it would be ideal if you seek help from the galaxy community: https://help.galaxyproject.org/ as this is a platform-specific error and we can't reproduce this on our end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/579
https://github.com/google/deepvariant/issues/580:33,deployability,instal,install,33,@weilu1998 you shouldn't have to install any additional software if you are using singularity. Can you try running singularity using the `--cleanenv` flag? This will prevent locally installed libraries from being used (which can cause conflicts).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:182,deployability,instal,installed,182,@weilu1998 you shouldn't have to install any additional software if you are using singularity. Can you try running singularity using the `--cleanenv` flag? This will prevent locally installed libraries from being used (which can cause conflicts).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:235,interoperability,conflict,conflicts,235,@weilu1998 you shouldn't have to install any additional software if you are using singularity. Can you try running singularity using the `--cleanenv` flag? This will prevent locally installed libraries from being used (which can cause conflicts).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:166,safety,prevent,prevent,166,@weilu1998 you shouldn't have to install any additional software if you are using singularity. Can you try running singularity using the `--cleanenv` flag? This will prevent locally installed libraries from being used (which can cause conflicts).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:166,security,preven,prevent,166,@weilu1998 you shouldn't have to install any additional software if you are using singularity. Can you try running singularity using the `--cleanenv` flag? This will prevent locally installed libraries from being used (which can cause conflicts).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:91,availability,error,error,91,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:349,energy efficiency,gpu,gpu,349,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:91,performance,error,error,91,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:349,performance,gpu,gpu,349,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:91,safety,error,error,91,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:457,testability,unit,unittest,457,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:91,usability,error,error,91,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:141,usability,command,command,141,"Hi @danielecook ,. Thanks for the reply. I retried adding --cleanenv flag and get the same error. I also cleanup the tmp folder. Here is the command I tried. ```. SINGULARITY_TMPDIR=/scratch/midway3/weilu1/tmp SINGULARITY_CACHEDIR=/scratch/midway3/weilu1/tmp singularity run --cleanenv --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant_1.4.0-gpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. --reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. --num_shards=1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:69,deployability,instal,installed,69,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:128,deployability,contain,container,128,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,integrability,messag,message,9,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,interoperability,messag,message,9,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:0,reliability,Doe,Does,0,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:33,usability,indicat,indicate,33,Does the message still appear to indicate that it is using libraries installed on your machine rather than those present in the container?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,availability,error,error,9,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:15,deployability,log,log,15,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:387,deployability,modul,module,387,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:504,deployability,modul,module,504,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:668,deployability,modul,module,668,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:817,deployability,modul,module,817,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:979,deployability,modul,module,979,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1142,deployability,modul,module,1142,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1325,deployability,modul,module,1325,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:842,energy efficiency,core,core,842,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:934,energy efficiency,core,core,934,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:277,interoperability,bind,bind,277,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:277,modifiability,bind,bind,277,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:387,modifiability,modul,module,387,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:457,modifiability,pac,packages,457,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:504,modifiability,modul,module,504,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:614,modifiability,pac,packages,614,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:668,modifiability,modul,module,668,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:758,modifiability,pac,packages,758,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:817,modifiability,modul,module,817,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:914,modifiability,pac,packages,914,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:979,modifiability,modul,module,979,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1088,modifiability,pac,packages,1088,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1142,modifiability,modul,module,1142,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1253,modifiability,pac,packages,1253,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1325,modifiability,modul,module,1325,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,performance,error,error,9,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,safety,error,error,9,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:15,safety,log,log,15,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:106,safety,prevent,prevent,106,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:387,safety,modul,module,387,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:504,safety,modul,module,504,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:668,safety,modul,module,668,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:817,safety,modul,module,817,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:979,safety,modul,module,979,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1142,safety,modul,module,1142,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:1325,safety,modul,module,1325,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:15,security,log,log,15,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:106,security,preven,prevent,106,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:197,security,sandbox,sandbox,197,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:15,testability,log,log,15,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:290,testability,Trace,Traceback,290,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:713,testability,context,context,713,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:791,testability,context,context,791,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:9,usability,error,error,9,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:87,usability,command,command,87,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:536,usability,tool,tools,536,"Yes, the error log is the same. I also added `unset PYTHONPATH` before the singularity command. How can I prevent it from . using the local libraries? . ```. INFO: Converting SIF file to temporary sandbox... WARNING: underlay of /usr/bin/nvidia-smi required more than 50 (469) bind mounts. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 48, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 41, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 41, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 33, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/descriptor.py"", line 40, in <module>. from google.protobuf.internal import api_implementation. File ""/home/weilu1/.local/lib/python3.8/site-packages/google/protobuf/internal/api_implementation.py"", line 104, in <module>. from google.protobuf.pyext import _message. TypeError: bases must be types. INFO: Cleaning up image... ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:184,deployability,contain,containers,184,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:352,deployability,version,version,352,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:117,energy efficiency,gpu,gpu,117,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:162,energy efficiency,GPU,GPUs,162,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:352,integrability,version,version,352,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:352,modifiability,version,version,352,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:117,performance,gpu,gpu,117,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:162,performance,GPU,GPUs,162,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:234,performance,content,content,234,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:95,usability,guid,guides,95,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:106,usability,user,user-guide,106,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:202,usability,guid,guide,202,"I am guessing it could be related to the use of the `--nv` flag ([docs](https://docs.sylabs.io/guides/3.5/user-guide/gpu.html)), but I am not familiar with using GPUs with singularity containers. This [guide](https://modinst.lu.lv/wp-content/uploads/2021/03/Singularity_seminars_Aleksandrs_Gutcaits.pdf) suggests unsetting the `LD_LIBRARY_PATH`. Which version of singularity are you using? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/580:93,reliability,doe,doesn,93,"Thanks for the reply! @danielecook I used singularity 3.7.1, adding the `LD_LIBRARY_PATH=""""` doesn't change the output.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/580
https://github.com/google/deepvariant/issues/581:40,availability,error,error,40,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:334,availability,error,error,334,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:71,deployability,Fail,Failed,71,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:40,performance,error,error,40,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:334,performance,error,error,334,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:71,reliability,Fail,Failed,71,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:40,safety,error,error,40,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:334,safety,error,error,334,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:469,safety,compl,complete,469,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:469,security,compl,complete,469,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:487,testability,verif,verify,487,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:40,usability,error,error,40,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:180,usability,statu,statusor,180,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:203,usability,statu,status,203,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:219,usability,statu,status,219,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:334,usability,error,error,334,"@Rofidagamal it looks like this is your error:. ```. [E::fai_retrieve] Failed to retrieve block: unexpected end of file. 2022-10-29 09:19:04.525670: F ./third_party/nucleus/vendor/statusor.h:231] Non-OK-status: status_ status: INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chr20"" start: 278310 end: 278449. Fatal Python error: Aborted. ```. Which suggests that the reference may be incomplete or truncated. Can you double check that the reference file is complete? Can you verify that all the contigs are present?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:72,availability,down,download,72,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:115,availability,error,error,115,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:286,availability,error,errors,286,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:715,availability,Down,Downloads,715,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:688,energy efficiency,model,model,688,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:694,energy efficiency,model,model,694,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:115,performance,error,error,115,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:286,performance,error,errors,286,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:115,safety,error,error,115,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:286,safety,error,errors,286,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:688,security,model,model,688,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:694,security,model,model,694,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:115,usability,error,error,115,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:286,usability,error,errors,286,"Thanks for replying @danielecook . But it still has a problem, I try to download the ref genome again. This is the error. 1103 22:00:13.799613 140256758277952 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. I1103 22:00:13.818571 139829647341376 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. **and this is my code What is the problem please ?**. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Downloads/ref/Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5,availability,error,error,5,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,availability,error,errors,104,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:172,availability,Down,Downloads,172,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5,performance,error,error,5,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,performance,error,errors,104,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5,safety,error,error,5,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,safety,error,errors,104,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:5,usability,error,error,5,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,usability,error,errors,104,This error suggests you didn't properly pass the ref flag: . ```. E1103 22:00:13.965888 140256758277952 errors.py:61] ref argument is required. ```. One potential reason: `Downloads` is not being mounted within the image. The `-v` and `-w` flags do not mount the entire filesystem. Try moving Homo_sapiens.GRCh38.dna.alt.fa to your working directory.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:22,availability,error,error,22,@danielecook The same error after I put the reference in the working directory,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:22,performance,error,error,22,@danielecook The same error after I put the reference in the working directory,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:22,safety,error,error,22,@danielecook The same error after I put the reference in the working directory,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:22,usability,error,error,22,@danielecook The same error after I put the reference in the working directory,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:50,availability,error,error,50,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20,deployability,updat,updated,20,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:178,deployability,contain,container,178,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:50,performance,error,error,50,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20,safety,updat,updated,20,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:50,safety,error,error,50,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:20,security,updat,updated,20,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:208,testability,verif,verify,208,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:28,usability,command,command,28,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:50,usability,error,error,50,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:149,usability,help,helpful,149,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:188,usability,interact,interactively,188,"Can you provide the updated command you used? The error is telling you that you have not provided a reference genome (`--ref`) argument. . It may be helpful to launch the docker container interactively, then verify that all the expected files are present. You can try:. ```bash. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. /bin/bash. ```. This will put you in a terminal where you can do `ls`. Make sure the reference is present in the expected location.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:616,availability,error,error,616,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1127,availability,error,errors,1127,"do docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1332,availability,error,errors,1332,"a\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1537,availability,error,errors,1537,"nels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1742,availability,error,errors,1742,"ode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1947,availability,error,errors,1947,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2152,availability,error,errors,2152,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2357,availability,error,errors,2357,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2562,availability,error,errors,2562,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2635,availability,echo,echo,2635,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:78,deployability,updat,updated,78,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:279,energy efficiency,model,model,279,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:285,energy efficiency,model,model,285,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:700,integrability,buffer,buffer,700,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:616,performance,error,error,616,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:657,performance,time,time,657,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:672,performance,parallel,parallel,672,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1127,performance,error,errors,1127,"do docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1332,performance,error,errors,1332,"a\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1537,performance,error,errors,1537,"nels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1742,performance,error,errors,1742,"ode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1947,performance,error,errors,1947,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2152,performance,error,errors,2152,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2357,performance,error,errors,2357,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2562,performance,error,errors,2562,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:78,safety,updat,updated,78,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:616,safety,error,error,616,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1127,safety,error,errors,1127,"do docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1332,safety,error,errors,1332,"a\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1537,safety,error,errors,1537,"nels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1742,safety,error,errors,1742,"ode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1947,safety,error,errors,1947,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2152,safety,error,errors,2152,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2357,safety,error,errors,2357,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2562,safety,error,errors,2562,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:78,security,updat,updated,78,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:279,security,model,model,279,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:285,security,model,model,285,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:29,usability,command,command,29,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:86,usability,command,command,86,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:616,usability,error,error,616,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:642,usability,command,command,642,"@danielecook . Ok. I try the command that you write it runs successfully. the updated command is. BIN_VERSION=""1.4.0"". nproc=8. sudo docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1127,usability,error,errors,1127,"do docker run \. -v ""$(pwd):$(pwd)"" \. -w $(pwd) \. google/deepvariant:""${BIN_VERSION}"" \. run_deepvariant \. --model_type=WES \. --customized_model=model/model.ckpt \. --ref= Homo_sapiens.GRCh38.dna.alt.fa\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1332,usability,error,errors,1332,"a\. --reads=data/hg005_gm26107.mrna.grch38.bam\. --output_vcf=output/HG005.output.vcf.gz \. --num_shards=$(nproc) \. --regions=data/chr20_CDS_3x.bed\. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1537,usability,error,errors,1537,"nels=''"" \. --intermediate_results_dir output/intermediate_results_dir. the error . ***** Running the command:*****. time seq 0 7 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1742,usability,error,errors,1742,"ode calling --ref """" --reads ""data/hg005_gm26107.mrna.grch38.bam"" --examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:1947,usability,error,errors,1947,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2152,usability,error,errors,2152,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2357,usability,error,errors,2357,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2562,usability,error,errors,2562,"examples ""output/intermediate_results_dir/make_examples.tfrecord@8.gz"" --channels '' --regions ""data/chr20_CDS_3x.bed"" --split_skip_reads --task {}. I1104 15:05:38.471258 140090698385216 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:38.490578 140090698385216 errors.py:61] ref argument is required. I1104 15:05:52.866427 139657534048064 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:52.881974 139657534048064 errors.py:61] ref argument is required. I1104 15:05:55.227194 140033931474752 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.231749 140033931474752 errors.py:61] ref argument is required. I1104 15:05:55.349858 140679315765056 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.355002 140679315765056 errors.py:61] ref argument is required. I1104 15:05:55.350152 140625211275072 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.364406 140625211275072 errors.py:61] ref argument is required. I1104 15:05:55.213266 139684413855552 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:55.217037 139684413855552 errors.py:61] ref argument is required. I1104 15:05:56.714641 140108024964928 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:56.718800 140108024964928 errors.py:61] ref argument is required. I1104 15:05:58.405512 140044150212416 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. E1104 15:05:58.408862 140044150212416 errors.py:61] ref argument is required. **(newenv) fci@fci-V530-15ICR:~$ echo $(pwd). /home/fci**. and I will attach screen of my home that ref file is found . **https://drive.google.com/file/d/1ztB19IhHsgxeUMBVzWhgjVwuPYZhvulV/view?usp=sharing**. > .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,availability,error,error,104,You have a space after the --ref flag. Be sure that is removed when you try running. That will cause an error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,performance,error,error,104,You have a space after the --ref flag. Be sure that is removed when you try running. That will cause an error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,safety,error,error,104,You have a space after the --ref flag. Be sure that is removed when you try running. That will cause an error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:104,usability,error,error,104,You have a space after the --ref flag. Be sure that is removed when you try running. That will cause an error.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:677,deployability,modul,module,677,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3000,deployability,fail,failed,3000,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:677,modifiability,modul,module,677,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:2981,performance,parallel,parallel,2981,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3000,reliability,fail,failed,3000,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:85,safety,input,inputs,85,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:677,safety,modul,module,677,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3361,safety,test,test,3361,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:529,testability,Trace,Traceback,529,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3361,testability,test,test,3361,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:85,usability,input,inputs,85,"I1104 15:21:43.035146 140195496982336 make_examples_core.py:243] Task 6/8: Preparing inputs. I1104 15:21:43.120648 140195496982336 genomics_reader.py:222] Reading data/hg005_gm26107.mrna.grch38.bam with NativeSamReader. I1104 15:21:43.168509 140195496982336 make_examples_core.py:243] Task 6/8: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 180, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 170, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1746, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1679, in processing_regions_from_options. calling_regions = build_calling_regions(ref_contigs, options.calling_regions,. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:3302,usability,user,user,3302,"_deepvariant/deepvariant/make_examples_core.py"", line 472, in build_calling_regions. ranges.RangeSet.from_regions(regions_to_include, contig_dict)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 161, in from_regions. return cls(ranges=from_regions(regions, contig_map=contig_map)). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 113, in __init__. for i, range_ in enumerate(ranges):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 493, in from_regions. for elt in reader(region):. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 458, in bed_parser. with bed.BedReader(filename) as fin:. File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 127, in _native_reader. return NativeBedReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_43f_hbd8/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 104, in __init__. self._reader = bed_reader.BedReader.from_file(bed_path, options). ValueError: OUT_OF_RANGE: EOF. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref GRCh38_no_alt_analysis_set.fasta --reads data/hg005_gm26107.mrna.grch38.bam --examples output/intermediate_results_dir/make_examples.tfrecord@8.gz --channels '' --regions data/chr20_CDS_3x.bed --split_skip_reads --task 3. real	0m9.092s. user	0m3.463s. sys	0m0.757s. I use the case study with all test files(https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-rnaseq-case-study.md) put in it and now I remove the space that you tell me about this , what is the problem ? @danielecook.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:36,availability,error,error,36,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:409,availability,avail,avail,409,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:397,energy efficiency,alloc,allocated,397,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:36,performance,error,error,36,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:36,safety,error,error,36,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:409,safety,avail,avail,409,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:204,security,sign,sign,204,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:36,usability,error,error,36,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:165,usability,close,closer,165,"@Rofidagamal I'm a bit stumped. The error suggests there is an issue with the bed file provided. ```. ValueError: OUT_OF_RANGE: EOF. ```. Maybe we can look a little closer at that and see if there is any sign of an issue there. Can you run:. ```. cut -f 1 data/chr20_CDS_3x.bed | wc. cut -f 1 data/chr20_CDS_3x.bed | uniq -c. ```. I wonder if it could also be related to the amount of space being allocated / avail. Can you also provide the output from the following:. ```. sudo docker run. -v ""$(pwd):$(pwd)"". -w $(pwd). google/deepvariant:""${BIN_VERSION}"" /bin/bash. # Once the image is running, run:. df -h. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:29,performance,time,time,29,"@danielecook Thanks for your time and trying to solve the issue with me . @pichuan Yes it works , the last problem it was with the memory of device that i run on it , when I change it , it works",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:131,performance,memor,memory,131,"@danielecook Thanks for your time and trying to solve the issue with me . @pichuan Yes it works , the last problem it was with the memory of device that i run on it , when I change it , it works",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:131,usability,memor,memory,131,"@danielecook Thanks for your time and trying to solve the issue with me . @pichuan Yes it works , the last problem it was with the memory of device that i run on it , when I change it , it works",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:75,usability,feedback,feedback,75,"Great! Thank you for letting us know! If you're interested in sharing more feedback to us, that will be great too. :). I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/581:124,usability,close,close,124,"Great! Thank you for letting us know! If you're interested in sharing more feedback to us, that will be great too. :). I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/581
https://github.com/google/deepvariant/issues/582:1309,availability,state,states,1309,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:497,deployability,observ,observed,497,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:749,deployability,scale,scaled,749,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:876,deployability,observ,observed,876,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1215,deployability,scale,scaled,1215,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1647,deployability,observ,observe,1647,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:749,energy efficiency,scale,scaled,749,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1215,energy efficiency,scale,scaled,1215,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1264,energy efficiency,model,model,1264,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1595,energy efficiency,model,model,1595,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1309,integrability,state,states,1309,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:142,interoperability,FORMAT,FORMAT,142,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:223,interoperability,FORMAT,FORMAT,223,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:285,interoperability,FORMAT,FORMAT,285,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:368,interoperability,FORMAT,FORMAT,368,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:433,interoperability,FORMAT,FORMAT,433,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:534,interoperability,FORMAT,FORMAT,534,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:615,interoperability,FORMAT,FORMAT,615,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:694,interoperability,FORMAT,FORMAT,694,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:813,interoperability,FORMAT,FORMAT,813,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1455,interoperability,distribut,distribution,1455,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:749,modifiability,scal,scaled,749,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1215,modifiability,scal,scaled,1215,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:749,performance,scale,scaled,749,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1215,performance,scale,scaled,1215,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1758,performance,content,content,1758,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1634,reliability,pra,practice,1634,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1264,security,model,model,1264,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1595,security,model,model,1595,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:497,testability,observ,observed,497,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:876,testability,observ,observed,876,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1647,testability,observ,observe,1647,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:486,usability,Minim,Minimum,486,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:792,usability,close,closest,792,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:969,usability,hint,hint,969,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1022,usability,support,support,1022,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1071,usability,support,support,1071,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1158,usability,support,support,1158,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/582:1354,usability,indicat,indicate,1354,"Hi @amy-houseman . Here is an example refcall:. ```. chr20 64096963 . G C 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:61:15:11,3:0.2:0,65,63. ```. The FORMAT fields are `GT:GQ:DP:AD:VAF:PL`. These are defined in the header:. ```. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##FORMAT=<ID=MED_DP,Number=1,Type=Integer,Description=""Median DP observed within the GVCF block rounded to the nearest integer."">. ```. * `AD` (11,3) gives a hint as to why this is probably a ref call. 11 reads support the reference allele (G), whereas only 3 support the ALT allele (C). . * `VAF` - Similarly, the VAF is 0.2, so there is limited support for the ALT allele. * `PL` (0,65,63) - The phred-scaled genotype likelihoods are derived from the model outputs for the three possible diploid states (HOM-REF, HET, HOM-ALT). Lower values indicate a greater likelihood for a given genotype. . One thing you might consider is looking at the distribution of PL values. If you suspect a refcall might be incorrect, you can examine PL values to get a sense of how much confidence our model has for a given variant call. In practice, we observe that these values are well calibrated. See Figure 2 of the [DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6.full.pdf) for further details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/582
https://github.com/google/deepvariant/issues/583:66,energy efficiency,model,model,66,"Hello Amy,. We haven't tested DeepVariant with HaloPlex data. WES model would be the best fit for this kind of data but there is no guaranty. Please let us know if you have any further questions. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/583:23,safety,test,tested,23,"Hello Amy,. We haven't tested DeepVariant with HaloPlex data. WES model would be the best fit for this kind of data but there is no guaranty. Please let us know if you have any further questions. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/583:66,security,model,model,66,"Hello Amy,. We haven't tested DeepVariant with HaloPlex data. WES model would be the best fit for this kind of data but there is no guaranty. Please let us know if you have any further questions. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/583:23,testability,test,tested,23,"Hello Amy,. We haven't tested DeepVariant with HaloPlex data. WES model would be the best fit for this kind of data but there is no guaranty. Please let us know if you have any further questions. . Thanks. Alex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/583
https://github.com/google/deepvariant/issues/584:481,deployability,observ,observe,481,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:611,deployability,depend,depending,611,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:190,energy efficiency,model,model,190,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:363,energy efficiency,model,model,363,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:764,energy efficiency,reduc,reduce,764,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1035,energy efficiency,model,model,1035,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1094,energy efficiency,model,model,1094,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:172,integrability,pub,published,172,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:595,integrability,filter,filter,595,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:611,integrability,depend,depending,611,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:656,integrability,filter,filtering,656,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:703,integrability,filter,filtering,703,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:781,integrability,discover,discovery,781,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:827,integrability,filter,filtering,827,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:781,interoperability,discover,discovery,781,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:611,modifiability,depend,depending,611,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:74,performance,content,content,74,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1161,performance,perform,performance,1161,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:611,safety,depend,depending,611,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:190,security,model,model,190,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:363,security,model,model,363,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1035,security,model,model,1035,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1094,security,model,model,1094,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:481,testability,observ,observe,481,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:611,testability,depend,depending,611,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:263,usability,user,user-images,263,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:582,usability,User,Users,582,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:781,usability,discov,discovery,781,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:901,usability,user,user-images,901,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:1161,usability,perform,performance,1161,"Hi @ASLeonard here is a table from the [preprint](https://www.biorxiv.org/content/10.1101/2022.10.16.512451v1). We stratify the F1-score across different region types. The published RNA-seq model is `DV RNA-seq [GTEx]`:. <img width=""795"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200906677-4b6e2f11-8b29-44e3-871e-299f46d1cd64.png"">. The model has no problem running genome wide, but accuracy will vary by region type due to the nature of RNA-seq data. We observe the highest accuracy in CDS regions which is why the case study is limited to these regions. Users should filter variants depending on their use case. This might mean filtering by region, but you can also consider filtering by genotype quality (or both). We show how you can reduce the false-discovery rate in figure 5 of the preprint by filtering on genotype quality:. <img width=""648"" alt=""image"" src=""https://user-images.githubusercontent.com/1536935/200907763-1d21cc44-daff-47d2-87c6-e7917ea62a32.png"">. > Is that applicable with the RNA-seq model, or is that primarily trained on CDS/exome only? The model is trained on exonic regions. We found this to give the best performance in our evaluations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/584:114,integrability,event,events,114,"Oh my, I missed that pre-print! So that _more_ than answers most of my questions. . Also just heard about the A>I events earlier this week, so that will be an exciting direction if to have all-in-one if vcf can handle that cleanly.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/584
https://github.com/google/deepvariant/issues/585:59,interoperability,bind,bind,59,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:193,interoperability,bind,bind,193,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:59,modifiability,bind,bind,59,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:193,modifiability,bind,bind,193,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:40,reliability,doe,does,40,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:123,safety,compl,complains,123,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:156,safety,input,inputs,156,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:123,security,compl,complains,123,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:156,usability,input,inputs,156,"Not a deepvariant dev, but maybe Docker does not like your bind path (since it includes a blank in your name). At least it complains about not finding your inputs, which would suggest that the bind path is not working (assuming your files are otherwise where they should be). Maybe you can move the files to another location on your system and try again.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:28,usability,help,helping,28,"Thank you @marchoeppner for helping here! @543090lee it'll be great if you can check if you have the file chr19_new.fa under C:\Users\Seungmo Lee\Desktop\researchProj , and to check wither Docker can see it (like @marchoeppner suggested). My answer in this other issue might also be useful: https://github.com/google/deepvariant/issues/577#issuecomment-1285622624",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/585:128,usability,User,Users,128,"Thank you @marchoeppner for helping here! @543090lee it'll be great if you can check if you have the file chr19_new.fa under C:\Users\Seungmo Lee\Desktop\researchProj , and to check wither Docker can see it (like @marchoeppner suggested). My answer in this other issue might also be useful: https://github.com/google/deepvariant/issues/577#issuecomment-1285622624",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/585
https://github.com/google/deepvariant/issues/586:468,deployability,releas,releases,468,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:39,energy efficiency,model,model,39,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:118,energy efficiency,model,model,118,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:772,energy efficiency,model,model,772,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:39,security,model,model,39,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:118,security,model,model,118,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:772,security,model,model,772,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:860,security,team,team,860,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:329,usability,document,documentations,329,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:632,usability,document,document,632,"Hi @JakeHagen , . My guess is that our model isn't as confident, because 100bp reads is not the main type of data our model is trained on. Glad to hear that the number of calls are expected though. Certainly interesting to see that the VCF report here. (Side note: Maybe we should consider attaching these reports as part of our documentations like [metrics.md](https://github.com/google/deepvariant/blob/r1.4/docs/metrics.md). I'll take a note to consider for future releases!). By the way, In the past (starting v1.2), we did try augmenting the training data by creating 100bp and 125bp reads, but we did so by trimming. See this document: https://github.com/google/deepvariant/blob/r1.4/docs/deepvariant-details-training-data.md#vfootnote12. But it's possible that our model still didn't feel confident enough with your datatype. I'll also ask around on my team to see if anyone else has other thoughts. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1127,energy efficiency,model,model,1127,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:559,integrability,compon,component,559,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:141,interoperability,distribut,distribution,141,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:424,interoperability,distribut,distributions,424,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:559,interoperability,compon,component,559,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:584,interoperability,distribut,distribution,584,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:802,interoperability,distribut,distribution,802,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:848,interoperability,Specif,Specifically,848,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:230,modifiability,scal,scalable,230,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:559,modifiability,compon,component,559,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
https://github.com/google/deepvariant/issues/586:1321,modifiability,variab,variability,1321,"Hi @JakeHagen . Thank you for the report, and for including the quality readout from the HTML file. One thing I want to mention is that this distribution is something that we have seen in some samples - see Figure 1 of [Accurate, scalable cohort variant calls using DeepVariant and GLnexus](https://academic.oup.com/bioinformatics/article/36/24/5582/6064144). In this figure, some of the analyzed cohorts do have bimodal GQ distributions for DeepVariant calls, while others (e.g. GIAB) do not. Supplementary Figure 3 of that paper indicates that a reasonable component of the bimodal distribution relates to sequence depth, at lower sample sequence depths, GIAB becomes more bimodal. I believe that we internally stratified calls and (though my memory is hazy) found that another factor in the bimodal distribution is whether a site is HET or HOM. Specifically, HET sites with lower depth have lower GQs, and I believe the explanation for this is that as coverage drops, it can become difficult to tell a HET site from either a REF or HOM, while HOM sites have more effective signal for them as non-REF. I don't think that the model is likely to be less confident in 100bp reads because they are not as much of the training data, but I expect the fact that 100bp reads are harder to uniquely map and will results in more variability in the coverage of high-MAPQ reads would indirectly contribute. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/586
